{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. íƒì§€ ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ\n",
    "\n",
    "**ë‹´ë‹¹**: Claude Opus  \n",
    "**ì‘ì„±ì¼**: 2025-10-24  \n",
    "**ëª©ì **: YOLO11 íƒì§€ ê²°ê³¼ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- SQLite ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ê²°ê³¼ ì €ì¥\n",
    "- JSON/CSV íŒŒì¼ ë‚´ë³´ë‚´ê¸°\n",
    "- ì´ë¯¸ì§€ ì–´ë…¸í…Œì´ì…˜ ì €ì¥\n",
    "- ê²°ê³¼ ê²€ìƒ‰ ë° í•„í„°ë§\n",
    "- ë²„ì „ ê´€ë¦¬ ë° ë°±ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python-headless pillow numpy sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Text, ForeignKey, Boolean\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship, Session\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple, Any, Union\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from enum import Enum\n",
    "import hashlib\n",
    "import shutil\n",
    "import zipfile\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import uuid\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# SQLAlchemy Base\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionSession(Base):\n",
    "    \"\"\"íƒì§€ ì„¸ì…˜ ëª¨ë¸\"\"\"\n",
    "    __tablename__ = 'detection_sessions'\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n",
    "    name = Column(String, nullable=False)\n",
    "    description = Column(Text)\n",
    "    created_at = Column(DateTime, default=datetime.now)\n",
    "    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)\n",
    "    model_name = Column(String)\n",
    "    model_version = Column(String)\n",
    "    total_images = Column(Integer, default=0)\n",
    "    total_detections = Column(Integer, default=0)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    images = relationship(\"DetectionImage\", back_populates=\"session\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "class DetectionImage(Base):\n",
    "    \"\"\"íƒì§€ ì´ë¯¸ì§€ ëª¨ë¸\"\"\"\n",
    "    __tablename__ = 'detection_images'\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n",
    "    session_id = Column(String, ForeignKey('detection_sessions.id'))\n",
    "    file_path = Column(String, nullable=False)\n",
    "    file_hash = Column(String, unique=True)\n",
    "    width = Column(Integer)\n",
    "    height = Column(Integer)\n",
    "    processed_at = Column(DateTime, default=datetime.now)\n",
    "    processing_time = Column(Float)\n",
    "    \n",
    "    # GPS ë©”íƒ€ë°ì´í„°\n",
    "    gps_latitude = Column(Float)\n",
    "    gps_longitude = Column(Float)\n",
    "    altitude = Column(Float)\n",
    "    \n",
    "    # ë“œë¡  ë©”íƒ€ë°ì´í„°\n",
    "    drone_model = Column(String)\n",
    "    camera_model = Column(String)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    session = relationship(\"DetectionSession\", back_populates=\"images\")\n",
    "    detections = relationship(\"Detection\", back_populates=\"image\", cascade=\"all, delete-orphan\")\n",
    "\n",
    "class Detection(Base):\n",
    "    \"\"\"ê°œë³„ íƒì§€ ê²°ê³¼ ëª¨ë¸\"\"\"\n",
    "    __tablename__ = 'detections'\n",
    "    \n",
    "    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))\n",
    "    image_id = Column(String, ForeignKey('detection_images.id'))\n",
    "    class_name = Column(String, nullable=False)\n",
    "    class_id = Column(Integer)\n",
    "    confidence = Column(Float, nullable=False)\n",
    "    \n",
    "    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n",
    "    x1 = Column(Float, nullable=False)\n",
    "    y1 = Column(Float, nullable=False)\n",
    "    x2 = Column(Float, nullable=False)\n",
    "    y2 = Column(Float, nullable=False)\n",
    "    \n",
    "    # ì¶”ê°€ ì •ë³´\n",
    "    area = Column(Float)\n",
    "    center_x = Column(Float)\n",
    "    center_y = Column(Float)\n",
    "    \n",
    "    # ê´€ê³„\n",
    "    image = relationship(\"DetectionImage\", back_populates=\"detections\")\n",
    "\n",
    "class CropClass(Base):\n",
    "    \"\"\"ì‘ë¬¼ í´ë˜ìŠ¤ ì •ì˜\"\"\"\n",
    "    __tablename__ = 'crop_classes'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String, unique=True, nullable=False)\n",
    "    korean_name = Column(String)\n",
    "    description = Column(Text)\n",
    "    color_rgb = Column(String)  # \"255,0,0\" í˜•ì‹\n",
    "    created_at = Column(DateTime, default=datetime.now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseManager:\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"detection_results.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.engine = create_engine(f'sqlite:///{db_path}', echo=False)\n",
    "        Base.metadata.create_all(self.engine)\n",
    "        self.SessionLocal = sessionmaker(bind=self.engine)\n",
    "        \n",
    "        # ê¸°ë³¸ ì‘ë¬¼ í´ë˜ìŠ¤ ì´ˆê¸°í™”\n",
    "        self._initialize_crop_classes()\n",
    "        \n",
    "        logger.info(f\"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”: {db_path}\")\n",
    "    \n",
    "    def _initialize_crop_classes(self):\n",
    "        \"\"\"ê¸°ë³¸ ì‘ë¬¼ í´ë˜ìŠ¤ ì´ˆê¸°í™”\"\"\"\n",
    "        default_classes = [\n",
    "            {\"id\": 0, \"name\": \"wheat\", \"korean_name\": \"ë°€\", \"color_rgb\": \"255,215,0\"},\n",
    "            {\"id\": 1, \"name\": \"corn\", \"korean_name\": \"ì˜¥ìˆ˜ìˆ˜\", \"color_rgb\": \"255,255,0\"},\n",
    "            {\"id\": 2, \"name\": \"rice\", \"korean_name\": \"ë²¼\", \"color_rgb\": \"0,255,0\"},\n",
    "            {\"id\": 3, \"name\": \"soybean\", \"korean_name\": \"ì½©\", \"color_rgb\": \"139,69,19\"},\n",
    "            {\"id\": 4, \"name\": \"potato\", \"korean_name\": \"ê°ì\", \"color_rgb\": \"165,42,42\"},\n",
    "            {\"id\": 5, \"name\": \"tomato\", \"korean_name\": \"í† ë§ˆí† \", \"color_rgb\": \"255,0,0\"},\n",
    "            {\"id\": 6, \"name\": \"pepper\", \"korean_name\": \"ê³ ì¶”\", \"color_rgb\": \"255,69,0\"},\n",
    "            {\"id\": 7, \"name\": \"cabbage\", \"korean_name\": \"ë°°ì¶”\", \"color_rgb\": \"144,238,144\"},\n",
    "            {\"id\": 8, \"name\": \"disease\", \"korean_name\": \"ë³‘í•´\", \"color_rgb\": \"128,0,128\"},\n",
    "            {\"id\": 9, \"name\": \"pest\", \"korean_name\": \"ì¶©í•´\", \"color_rgb\": \"64,64,64\"}\n",
    "        ]\n",
    "        \n",
    "        with self.SessionLocal() as session:\n",
    "            for cls in default_classes:\n",
    "                existing = session.query(CropClass).filter_by(id=cls[\"id\"]).first()\n",
    "                if not existing:\n",
    "                    crop_class = CropClass(**cls)\n",
    "                    session.add(crop_class)\n",
    "            session.commit()\n",
    "    \n",
    "    def create_session(self, name: str, description: str = \"\", \n",
    "                      model_name: str = \"YOLO11\", model_version: str = \"1.0\") -> str:\n",
    "        \"\"\"ìƒˆ íƒì§€ ì„¸ì…˜ ìƒì„±\"\"\"\n",
    "        with self.SessionLocal() as session:\n",
    "            detection_session = DetectionSession(\n",
    "                name=name,\n",
    "                description=description,\n",
    "                model_name=model_name,\n",
    "                model_version=model_version\n",
    "            )\n",
    "            session.add(detection_session)\n",
    "            session.commit()\n",
    "            session_id = detection_session.id\n",
    "            \n",
    "        logger.info(f\"ìƒˆ ì„¸ì…˜ ìƒì„±: {name} (ID: {session_id})\")\n",
    "        return session_id\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict]:\n",
    "        \"\"\"ì„¸ì…˜ ì •ë³´ ì¡°íšŒ\"\"\"\n",
    "        with self.SessionLocal() as session:\n",
    "            detection_session = session.query(DetectionSession).filter_by(id=session_id).first()\n",
    "            if detection_session:\n",
    "                return {\n",
    "                    'id': detection_session.id,\n",
    "                    'name': detection_session.name,\n",
    "                    'description': detection_session.description,\n",
    "                    'created_at': detection_session.created_at,\n",
    "                    'total_images': detection_session.total_images,\n",
    "                    'total_detections': detection_session.total_detections\n",
    "                }\n",
    "        return None\n",
    "    \n",
    "    def list_sessions(self) -> List[Dict]:\n",
    "        \"\"\"ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ\"\"\"\n",
    "        with self.SessionLocal() as session:\n",
    "            sessions = session.query(DetectionSession).all()\n",
    "            return [{\n",
    "                'id': s.id,\n",
    "                'name': s.name,\n",
    "                'created_at': s.created_at,\n",
    "                'total_images': s.total_images,\n",
    "                'total_detections': s.total_detections\n",
    "            } for s in sessions]\n",
    "    \n",
    "    def backup_database(self, backup_dir: str = \"backups\"):\n",
    "        \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…\"\"\"\n",
    "        Path(backup_dir).mkdir(exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        backup_path = Path(backup_dir) / f\"backup_{timestamp}.db\"\n",
    "        shutil.copy2(self.db_path, backup_path)\n",
    "        logger.info(f\"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì™„ë£Œ: {backup_path}\")\n",
    "        return str(backup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ê²°ê³¼ ì €ì¥ ë§¤ë‹ˆì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DetectionResult:\n",
    "    \"\"\"íƒì§€ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    image_path: str\n",
    "    detections: List[Dict]\n",
    "    processing_time: float\n",
    "    image_shape: Tuple[int, int, int]\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class ResultStorageManager:\n",
    "    \"\"\"ê²°ê³¼ ì €ì¥ ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, db_manager: DatabaseManager, storage_dir: str = \"detection_results\"):\n",
    "        self.db_manager = db_manager\n",
    "        self.storage_dir = Path(storage_dir)\n",
    "        self.storage_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        self.images_dir = self.storage_dir / \"images\"\n",
    "        self.annotations_dir = self.storage_dir / \"annotations\"\n",
    "        self.exports_dir = self.storage_dir / \"exports\"\n",
    "        \n",
    "        for dir_path in [self.images_dir, self.annotations_dir, self.exports_dir]:\n",
    "            dir_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬: {storage_dir}\")\n",
    "    \n",
    "    def save_detection_result(self, session_id: str, result: DetectionResult) -> str:\n",
    "        \"\"\"íƒì§€ ê²°ê³¼ ì €ì¥\"\"\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            # ì„¸ì…˜ í™•ì¸\n",
    "            detection_session = session.query(DetectionSession).filter_by(id=session_id).first()\n",
    "            if not detection_session:\n",
    "                raise ValueError(f\"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {session_id}\")\n",
    "            \n",
    "            # ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚°\n",
    "            file_hash = self._calculate_file_hash(result.image_path)\n",
    "            \n",
    "            # ì¤‘ë³µ ì²´í¬\n",
    "            existing_image = session.query(DetectionImage).filter_by(file_hash=file_hash).first()\n",
    "            if existing_image:\n",
    "                logger.warning(f\"ì´ë¯¸ì§€ ì´ë¯¸ ì²˜ë¦¬ë¨: {result.image_path}\")\n",
    "                return existing_image.id\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ë ˆì½”ë“œ ìƒì„±\n",
    "            detection_image = DetectionImage(\n",
    "                session_id=session_id,\n",
    "                file_path=result.image_path,\n",
    "                file_hash=file_hash,\n",
    "                width=result.image_shape[1],\n",
    "                height=result.image_shape[0],\n",
    "                processing_time=result.processing_time,\n",
    "                gps_latitude=result.metadata.get('gps_latitude'),\n",
    "                gps_longitude=result.metadata.get('gps_longitude'),\n",
    "                altitude=result.metadata.get('altitude'),\n",
    "                drone_model=result.metadata.get('drone_model'),\n",
    "                camera_model=result.metadata.get('camera_model')\n",
    "            )\n",
    "            session.add(detection_image)\n",
    "            \n",
    "            # íƒì§€ ê²°ê³¼ ì €ì¥\n",
    "            for det in result.detections:\n",
    "                detection = Detection(\n",
    "                    image_id=detection_image.id,\n",
    "                    class_name=det['class'],\n",
    "                    class_id=det.get('class_id'),\n",
    "                    confidence=det['confidence'],\n",
    "                    x1=det['bbox'][0],\n",
    "                    y1=det['bbox'][1],\n",
    "                    x2=det['bbox'][2],\n",
    "                    y2=det['bbox'][3],\n",
    "                    area=(det['bbox'][2] - det['bbox'][0]) * (det['bbox'][3] - det['bbox'][1]),\n",
    "                    center_x=(det['bbox'][0] + det['bbox'][2]) / 2,\n",
    "                    center_y=(det['bbox'][1] + det['bbox'][3]) / 2\n",
    "                )\n",
    "                session.add(detection)\n",
    "            \n",
    "            # ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸\n",
    "            detection_session.total_images += 1\n",
    "            detection_session.total_detections += len(result.detections)\n",
    "            detection_session.updated_at = datetime.now()\n",
    "            \n",
    "            session.commit()\n",
    "            image_id = detection_image.id\n",
    "            \n",
    "        logger.info(f\"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result.image_path} ({len(result.detections)}ê°œ íƒì§€)\")\n",
    "        return image_id\n",
    "    \n",
    "    def save_annotated_image(self, image_id: str, image: np.ndarray, \n",
    "                            draw_labels: bool = True, draw_confidence: bool = True) -> str:\n",
    "        \"\"\"ì–´ë…¸í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ì €ì¥\"\"\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            detection_image = session.query(DetectionImage).filter_by(id=image_id).first()\n",
    "            if not detection_image:\n",
    "                raise ValueError(f\"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {image_id}\")\n",
    "            \n",
    "            # íƒì§€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "            detections = session.query(Detection).filter_by(image_id=image_id).all()\n",
    "            \n",
    "            # ì´ë¯¸ì§€ì— ì–´ë…¸í…Œì´ì…˜ ê·¸ë¦¬ê¸°\n",
    "            annotated = self._draw_annotations(\n",
    "                image, detections, draw_labels, draw_confidence\n",
    "            )\n",
    "            \n",
    "            # ì €ì¥\n",
    "            filename = f\"annotated_{image_id}.jpg\"\n",
    "            save_path = self.annotations_dir / filename\n",
    "            cv2.imwrite(str(save_path), cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "        logger.info(f\"ì–´ë…¸í…Œì´ì…˜ ì´ë¯¸ì§€ ì €ì¥: {save_path}\")\n",
    "        return str(save_path)\n",
    "    \n",
    "    def _draw_annotations(self, image: np.ndarray, detections: List[Detection],\n",
    "                         draw_labels: bool, draw_confidence: bool) -> np.ndarray:\n",
    "        \"\"\"ì´ë¯¸ì§€ì— ì–´ë…¸í…Œì´ì…˜ ê·¸ë¦¬ê¸°\"\"\"\n",
    "        annotated = image.copy()\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸°\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            crop_classes = {c.name: c.color_rgb for c in session.query(CropClass).all()}\n",
    "        \n",
    "        for det in detections:\n",
    "            # ìƒ‰ìƒ ê²°ì •\n",
    "            color_str = crop_classes.get(det.class_name, \"0,255,0\")\n",
    "            color = tuple(map(int, color_str.split(',')))\n",
    "            \n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "            x1, y1, x2, y2 = int(det.x1), int(det.y1), int(det.x2), int(det.y2)\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # ë ˆì´ë¸” ê·¸ë¦¬ê¸°\n",
    "            if draw_labels or draw_confidence:\n",
    "                label = det.class_name\n",
    "                if draw_confidence:\n",
    "                    label += f\" {det.confidence:.2f}\"\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸ ë°°ê²½\n",
    "                (text_width, text_height), _ = cv2.getTextSize(\n",
    "                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1\n",
    "                )\n",
    "                cv2.rectangle(\n",
    "                    annotated, \n",
    "                    (x1, y1 - text_height - 4),\n",
    "                    (x1 + text_width, y1),\n",
    "                    color, -1\n",
    "                )\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸\n",
    "                cv2.putText(\n",
    "                    annotated, label,\n",
    "                    (x1, y1 - 2),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 1\n",
    "                )\n",
    "        \n",
    "        return annotated\n",
    "    \n",
    "    def _calculate_file_hash(self, file_path: str) -> str:\n",
    "        \"\"\"íŒŒì¼ í•´ì‹œ ê³„ì‚°\"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ê²°ê³¼ ì¡°íšŒ ë° í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultQueryManager:\n",
    "    \"\"\"ê²°ê³¼ ì¡°íšŒ ë° í•„í„°ë§ ê´€ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, db_manager: DatabaseManager):\n",
    "        self.db_manager = db_manager\n",
    "    \n",
    "    def query_detections(self, \n",
    "                        session_id: Optional[str] = None,\n",
    "                        class_name: Optional[str] = None,\n",
    "                        min_confidence: float = 0.0,\n",
    "                        date_from: Optional[datetime] = None,\n",
    "                        date_to: Optional[datetime] = None,\n",
    "                        limit: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"íƒì§€ ê²°ê³¼ ì¡°íšŒ\"\"\"\n",
    "        \n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            query = session.query(Detection).join(DetectionImage)\n",
    "            \n",
    "            # í•„í„° ì ìš©\n",
    "            if session_id:\n",
    "                query = query.filter(DetectionImage.session_id == session_id)\n",
    "            \n",
    "            if class_name:\n",
    "                query = query.filter(Detection.class_name == class_name)\n",
    "            \n",
    "            if min_confidence > 0:\n",
    "                query = query.filter(Detection.confidence >= min_confidence)\n",
    "            \n",
    "            if date_from:\n",
    "                query = query.filter(DetectionImage.processed_at >= date_from)\n",
    "            \n",
    "            if date_to:\n",
    "                query = query.filter(DetectionImage.processed_at <= date_to)\n",
    "            \n",
    "            if limit:\n",
    "                query = query.limit(limit)\n",
    "            \n",
    "            # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "            results = []\n",
    "            for det in query.all():\n",
    "                results.append({\n",
    "                    'detection_id': det.id,\n",
    "                    'image_id': det.image_id,\n",
    "                    'image_path': det.image.file_path,\n",
    "                    'class_name': det.class_name,\n",
    "                    'confidence': det.confidence,\n",
    "                    'x1': det.x1,\n",
    "                    'y1': det.y1,\n",
    "                    'x2': det.x2,\n",
    "                    'y2': det.y2,\n",
    "                    'area': det.area,\n",
    "                    'processed_at': det.image.processed_at,\n",
    "                    'gps_latitude': det.image.gps_latitude,\n",
    "                    'gps_longitude': det.image.gps_longitude\n",
    "                })\n",
    "            \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def get_statistics(self, session_id: str) -> Dict:\n",
    "        \"\"\"ì„¸ì…˜ í†µê³„ ì¡°íšŒ\"\"\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            # ê¸°ë³¸ í†µê³„\n",
    "            detection_session = session.query(DetectionSession).filter_by(id=session_id).first()\n",
    "            if not detection_session:\n",
    "                return {}\n",
    "            \n",
    "            # í´ë˜ìŠ¤ë³„ í†µê³„\n",
    "            class_stats = session.query(\n",
    "                Detection.class_name,\n",
    "                func.count(Detection.id).label('count'),\n",
    "                func.avg(Detection.confidence).label('avg_confidence')\n",
    "            ).join(DetectionImage).filter(\n",
    "                DetectionImage.session_id == session_id\n",
    "            ).group_by(Detection.class_name).all()\n",
    "            \n",
    "            # ì‹œê°„ë³„ í†µê³„\n",
    "            time_stats = session.query(\n",
    "                func.date(DetectionImage.processed_at).label('date'),\n",
    "                func.count(DetectionImage.id).label('images'),\n",
    "                func.count(Detection.id).label('detections')\n",
    "            ).join(Detection).filter(\n",
    "                DetectionImage.session_id == session_id\n",
    "            ).group_by(func.date(DetectionImage.processed_at)).all()\n",
    "            \n",
    "        return {\n",
    "            'session_name': detection_session.name,\n",
    "            'total_images': detection_session.total_images,\n",
    "            'total_detections': detection_session.total_detections,\n",
    "            'class_distribution': {stat.class_name: {\n",
    "                'count': stat.count,\n",
    "                'avg_confidence': float(stat.avg_confidence)\n",
    "            } for stat in class_stats},\n",
    "            'daily_stats': [{  \n",
    "                'date': stat.date.isoformat() if stat.date else None,\n",
    "                'images': stat.images,\n",
    "                'detections': stat.detections\n",
    "            } for stat in time_stats]\n",
    "        }\n",
    "    \n",
    "    def find_similar_detections(self, detection_id: str, threshold: float = 0.8) -> List[Dict]:\n",
    "        \"\"\"ìœ ì‚¬í•œ íƒì§€ ê²°ê³¼ ì°¾ê¸°\"\"\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            # ê¸°ì¤€ íƒì§€ ê²°ê³¼\n",
    "            base_detection = session.query(Detection).filter_by(id=detection_id).first()\n",
    "            if not base_detection:\n",
    "                return []\n",
    "            \n",
    "            # ê°™ì€ í´ë˜ìŠ¤ì˜ íƒì§€ ê²°ê³¼ ê²€ìƒ‰\n",
    "            similar = session.query(Detection).filter(\n",
    "                Detection.class_name == base_detection.class_name,\n",
    "                Detection.confidence >= base_detection.confidence * threshold,\n",
    "                Detection.id != detection_id\n",
    "            ).limit(10).all()\n",
    "            \n",
    "            results = []\n",
    "            for det in similar:\n",
    "                # IoU ê³„ì‚° (ê°„ë‹¨í•œ ìœ ì‚¬ë„)\n",
    "                iou = self._calculate_iou_similarity(\n",
    "                    (base_detection.x1, base_detection.y1, base_detection.x2, base_detection.y2),\n",
    "                    (det.x1, det.y1, det.x2, det.y2)\n",
    "                )\n",
    "                \n",
    "                if iou > 0.3:  # IoU ì„ê³„ê°’\n",
    "                    results.append({\n",
    "                        'detection_id': det.id,\n",
    "                        'image_path': det.image.file_path,\n",
    "                        'confidence': det.confidence,\n",
    "                        'similarity': iou\n",
    "                    })\n",
    "            \n",
    "        return sorted(results, key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    def _calculate_iou_similarity(self, box1: Tuple, box2: Tuple) -> float:\n",
    "        \"\"\"IoU ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "        # ë©´ì  ë¹„ìœ¨ë¡œ ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        if area1 == 0 or area2 == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        ratio = min(area1, area2) / max(area1, area2)\n",
    "        return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportManager:\n",
    "    \"\"\"ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ê´€ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, db_manager: DatabaseManager, storage_manager: ResultStorageManager):\n",
    "        self.db_manager = db_manager\n",
    "        self.storage_manager = storage_manager\n",
    "    \n",
    "    def export_to_coco(self, session_id: str, output_path: str):\n",
    "        \"\"\"COCO í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            # ì„¸ì…˜ ì •ë³´\n",
    "            detection_session = session.query(DetectionSession).filter_by(id=session_id).first()\n",
    "            if not detection_session:\n",
    "                raise ValueError(f\"ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {session_id}\")\n",
    "            \n",
    "            # COCO í˜•ì‹ ë°ì´í„° êµ¬ì¡°\n",
    "            coco_data = {\n",
    "                \"info\": {\n",
    "                    \"description\": detection_session.description,\n",
    "                    \"version\": \"1.0\",\n",
    "                    \"year\": datetime.now().year,\n",
    "                    \"date_created\": datetime.now().isoformat()\n",
    "                },\n",
    "                \"images\": [],\n",
    "                \"annotations\": [],\n",
    "                \"categories\": []\n",
    "            }\n",
    "            \n",
    "            # ì¹´í…Œê³ ë¦¬ ì¶”ê°€\n",
    "            crop_classes = session.query(CropClass).all()\n",
    "            for cls in crop_classes:\n",
    "                coco_data[\"categories\"].append({\n",
    "                    \"id\": cls.id,\n",
    "                    \"name\": cls.name,\n",
    "                    \"supercategory\": \"crop\"\n",
    "                })\n",
    "            \n",
    "            # ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€\n",
    "            images = session.query(DetectionImage).filter_by(session_id=session_id).all()\n",
    "            annotation_id = 1\n",
    "            \n",
    "            for idx, img in enumerate(images, 1):\n",
    "                # ì´ë¯¸ì§€ ì •ë³´\n",
    "                coco_data[\"images\"].append({\n",
    "                    \"id\": idx,\n",
    "                    \"file_name\": Path(img.file_path).name,\n",
    "                    \"width\": img.width,\n",
    "                    \"height\": img.height,\n",
    "                    \"date_captured\": img.processed_at.isoformat()\n",
    "                })\n",
    "                \n",
    "                # íƒì§€ ê²°ê³¼\n",
    "                for det in img.detections:\n",
    "                    width = det.x2 - det.x1\n",
    "                    height = det.y2 - det.y1\n",
    "                    \n",
    "                    coco_data[\"annotations\"].append({\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": idx,\n",
    "                        \"category_id\": det.class_id or 0,\n",
    "                        \"bbox\": [det.x1, det.y1, width, height],\n",
    "                        \"area\": float(det.area),\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"score\": float(det.confidence)\n",
    "                    })\n",
    "                    annotation_id += 1\n",
    "        \n",
    "        # JSON ì €ì¥\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(coco_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"COCO í˜•ì‹ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def export_to_yolo(self, session_id: str, output_dir: str):\n",
    "        \"\"\"YOLO í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        labels_dir = output_path / \"labels\"\n",
    "        labels_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            images = session.query(DetectionImage).filter_by(session_id=session_id).all()\n",
    "            \n",
    "            for img in images:\n",
    "                label_file = labels_dir / f\"{Path(img.file_path).stem}.txt\"\n",
    "                \n",
    "                with open(label_file, 'w') as f:\n",
    "                    for det in img.detections:\n",
    "                        # YOLO í˜•ì‹: class_id x_center y_center width height (ì •ê·œí™”)\n",
    "                        x_center = (det.x1 + det.x2) / 2 / img.width\n",
    "                        y_center = (det.y1 + det.y2) / 2 / img.height\n",
    "                        width = (det.x2 - det.x1) / img.width\n",
    "                        height = (det.y2 - det.y1) / img.height\n",
    "                        \n",
    "                        f.write(f\"{det.class_id or 0} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "        \n",
    "        # í´ë˜ìŠ¤ íŒŒì¼ ìƒì„±\n",
    "        classes_file = output_path / \"classes.txt\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            crop_classes = session.query(CropClass).order_by(CropClass.id).all()\n",
    "            with open(classes_file, 'w') as f:\n",
    "                for cls in crop_classes:\n",
    "                    f.write(f\"{cls.name}\\n\")\n",
    "        \n",
    "        logger.info(f\"YOLO í˜•ì‹ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_dir}\")\n",
    "    \n",
    "    def export_to_csv(self, session_id: str, output_path: str):\n",
    "        \"\"\"CSV í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        query_manager = ResultQueryManager(self.db_manager)\n",
    "        df = query_manager.query_detections(session_id=session_id)\n",
    "        \n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        logger.info(f\"CSV ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_path} ({len(df)}ê°œ ë ˆì½”ë“œ)\")\n",
    "    \n",
    "    def create_report(self, session_id: str, output_path: str):\n",
    "        \"\"\"ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
    "        query_manager = ResultQueryManager(self.db_manager)\n",
    "        stats = query_manager.get_statistics(session_id)\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(f\"ë“œë¡  ì‘ë¬¼ íƒì§€ ë¶„ì„ ë¦¬í¬íŠ¸\")\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(f\"\\nì„¸ì…˜: {stats.get('session_name', 'Unknown')}\")\n",
    "        report.append(f\"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(f\"\\n[ìš”ì•½ í†µê³„]\")\n",
    "        report.append(f\"- ì´ ì²˜ë¦¬ ì´ë¯¸ì§€: {stats.get('total_images', 0)}ê°œ\")\n",
    "        report.append(f\"- ì´ íƒì§€ ê°ì²´: {stats.get('total_detections', 0)}ê°œ\")\n",
    "        report.append(f\"- í‰ê·  íƒì§€/ì´ë¯¸ì§€: {stats.get('total_detections', 0) / max(1, stats.get('total_images', 1)):.2f}ê°œ\")\n",
    "        \n",
    "        report.append(f\"\\n[í´ë˜ìŠ¤ë³„ ë¶„í¬]\")\n",
    "        class_dist = stats.get('class_distribution', {})\n",
    "        for class_name, class_stats in sorted(class_dist.items(), key=lambda x: x[1]['count'], reverse=True):\n",
    "            report.append(f\"- {class_name}: {class_stats['count']}ê°œ (í‰ê·  ì‹ ë¢°ë„: {class_stats['avg_confidence']:.2%})\")\n",
    "        \n",
    "        report.append(f\"\\n[ì¼ë³„ ì²˜ë¦¬ í˜„í™©]\")\n",
    "        for day_stat in stats.get('daily_stats', []):\n",
    "            if day_stat['date']:\n",
    "                report.append(f\"- {day_stat['date']}: {day_stat['images']}ê°œ ì´ë¯¸ì§€, {day_stat['detections']}ê°œ íƒì§€\")\n",
    "        \n",
    "        # íŒŒì¼ë¡œ ì €ì¥\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(report))\n",
    "        \n",
    "        logger.info(f\"ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
    "        return \"\\n\".join(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í†µí•© ì‚¬ìš© ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í†µí•© ì˜ˆì œ: ì „ì²´ ì›Œí¬í”Œë¡œìš°\n",
    "def demo_complete_workflow():\n",
    "    \"\"\"ì™„ì „í•œ ê²°ê³¼ ì €ì¥/ê´€ë¦¬ ì›Œí¬í”Œë¡œìš° ë°ëª¨\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ íƒì§€ ê²°ê³¼ ì €ì¥/ê´€ë¦¬ ì‹œìŠ¤í…œ ë°ëª¨\\n\")\n",
    "    \n",
    "    # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    print(\"[1/6] ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "    db_manager = DatabaseManager(\"demo_detection.db\")\n",
    "    storage_manager = ResultStorageManager(db_manager, \"demo_results\")\n",
    "    query_manager = ResultQueryManager(db_manager)\n",
    "    export_manager = ExportManager(db_manager, storage_manager)\n",
    "    \n",
    "    # 2. ìƒˆ ì„¸ì…˜ ìƒì„±\n",
    "    print(\"[2/6] íƒì§€ ì„¸ì…˜ ìƒì„±...\")\n",
    "    session_id = db_manager.create_session(\n",
    "        name=\"ë“œë¡  ì‘ë¬¼ ëª¨ë‹ˆí„°ë§ 2025-10-24\",\n",
    "        description=\"í…ŒìŠ¤íŠ¸ ë†ì¥ ì‘ë¬¼ ìƒíƒœ ì ê²€\",\n",
    "        model_name=\"YOLO11\",\n",
    "        model_version=\"1.0\"\n",
    "    )\n",
    "    print(f\"  ì„¸ì…˜ ID: {session_id}\")\n",
    "    \n",
    "    # 3. íƒì§€ ê²°ê³¼ ì €ì¥ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "    print(\"[3/6] íƒì§€ ê²°ê³¼ ì €ì¥...\")\n",
    "    \n",
    "    # ê°€ì§œ íƒì§€ ê²°ê³¼ ìƒì„±\n",
    "    for i in range(5):\n",
    "        result = DetectionResult(\n",
    "            image_path=f\"test_image_{i}.jpg\",\n",
    "            detections=[\n",
    "                {\n",
    "                    \"class\": np.random.choice([\"wheat\", \"corn\", \"rice\"]),\n",
    "                    \"class_id\": np.random.randint(0, 3),\n",
    "                    \"confidence\": np.random.uniform(0.7, 0.99),\n",
    "                    \"bbox\": [np.random.randint(0, 500) for _ in range(4)]\n",
    "                }\n",
    "                for _ in range(np.random.randint(1, 4))\n",
    "            ],\n",
    "            processing_time=np.random.uniform(0.1, 0.5),\n",
    "            image_shape=(640, 640, 3),\n",
    "            metadata={\n",
    "                \"gps_latitude\": 37.5 + np.random.uniform(-0.01, 0.01),\n",
    "                \"gps_longitude\": 127.0 + np.random.uniform(-0.01, 0.01),\n",
    "                \"altitude\": 100 + np.random.uniform(-20, 20),\n",
    "                \"drone_model\": \"DJI Mavic 3\",\n",
    "                \"camera_model\": \"Hasselblad L2D-20c\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        image_id = storage_manager.save_detection_result(session_id, result)\n",
    "        print(f\"  ì´ë¯¸ì§€ {i+1}/5 ì €ì¥ ì™„ë£Œ\")\n",
    "    \n",
    "    # 4. ê²°ê³¼ ì¡°íšŒ\n",
    "    print(\"\\n[4/6] ê²°ê³¼ ì¡°íšŒ ë° í†µê³„...\")\n",
    "    \n",
    "    # ì „ì²´ í†µê³„\n",
    "    stats = query_manager.get_statistics(session_id)\n",
    "    print(f\"  ì´ ì´ë¯¸ì§€: {stats['total_images']}\")\n",
    "    print(f\"  ì´ íƒì§€: {stats['total_detections']}\")\n",
    "    print(f\"  í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "    for class_name, class_stat in stats['class_distribution'].items():\n",
    "        print(f\"    - {class_name}: {class_stat['count']}ê°œ\")\n",
    "    \n",
    "    # 5. ë‚´ë³´ë‚´ê¸°\n",
    "    print(\"\\n[5/6] ê²°ê³¼ ë‚´ë³´ë‚´ê¸°...\")\n",
    "    \n",
    "    # CSV ë‚´ë³´ë‚´ê¸°\n",
    "    export_manager.export_to_csv(session_id, \"demo_results/export.csv\")\n",
    "    print(\"  âœ“ CSV ë‚´ë³´ë‚´ê¸° ì™„ë£Œ\")\n",
    "    \n",
    "    # ë¦¬í¬íŠ¸ ìƒì„±\n",
    "    report = export_manager.create_report(session_id, \"demo_results/report.txt\")\n",
    "    print(\"  âœ“ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    # 6. ë°±ì—…\n",
    "    print(\"\\n[6/6] ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…...\")\n",
    "    backup_path = db_manager.backup_database(\"demo_results/backups\")\n",
    "    print(f\"  âœ“ ë°±ì—… ì™„ë£Œ: {backup_path}\")\n",
    "    \n",
    "    print(\"\\nâœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!\")\n",
    "    \n",
    "    return session_id\n",
    "\n",
    "# ë°ëª¨ ì‹¤í–‰\n",
    "demo_session_id = demo_complete_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê³ ê¸‰ ê¸°ëŠ¥: ì§€ë¦¬ê³µê°„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialAnalyzer:\n",
    "    \"\"\"GPS ê¸°ë°˜ ì§€ë¦¬ê³µê°„ ë¶„ì„\"\"\"\n",
    "    \n",
    "    def __init__(self, db_manager: DatabaseManager):\n",
    "        self.db_manager = db_manager\n",
    "    \n",
    "    def get_detection_heatmap_data(self, session_id: str, class_name: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"íƒì§€ íˆíŠ¸ë§µ ë°ì´í„° ìƒì„±\"\"\"\n",
    "        with self.db_manager.SessionLocal() as session:\n",
    "            query = session.query(\n",
    "                DetectionImage.gps_latitude,\n",
    "                DetectionImage.gps_longitude,\n",
    "                func.count(Detection.id).label('detection_count')\n",
    "            ).join(Detection).filter(\n",
    "                DetectionImage.session_id == session_id,\n",
    "                DetectionImage.gps_latitude.isnot(None),\n",
    "                DetectionImage.gps_longitude.isnot(None)\n",
    "            )\n",
    "            \n",
    "            if class_name:\n",
    "                query = query.filter(Detection.class_name == class_name)\n",
    "            \n",
    "            results = query.group_by(\n",
    "                DetectionImage.gps_latitude,\n",
    "                DetectionImage.gps_longitude\n",
    "            ).all()\n",
    "            \n",
    "        return [{\n",
    "            'lat': float(r.gps_latitude),\n",
    "            'lon': float(r.gps_longitude),\n",
    "            'count': r.detection_count\n",
    "        } for r in results]\n",
    "    \n",
    "    def find_clusters(self, session_id: str, class_name: str, radius_meters: float = 50) -> List[Dict]:\n",
    "        \"\"\"íŠ¹ì • í´ë˜ìŠ¤ì˜ êµ°ì§‘ ì°¾ê¸°\"\"\"\n",
    "        # ê°„ë‹¨í•œ ê±°ë¦¬ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§\n",
    "        data = self.get_detection_heatmap_data(session_id, class_name)\n",
    "        \n",
    "        clusters = []\n",
    "        visited = set()\n",
    "        \n",
    "        for i, point in enumerate(data):\n",
    "            if i in visited:\n",
    "                continue\n",
    "            \n",
    "            cluster = [point]\n",
    "            visited.add(i)\n",
    "            \n",
    "            for j, other in enumerate(data):\n",
    "                if j in visited:\n",
    "                    continue\n",
    "                \n",
    "                # í•˜ë²„ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚° (ê°„ëµí™”)\n",
    "                distance = self._haversine_distance(\n",
    "                    point['lat'], point['lon'],\n",
    "                    other['lat'], other['lon']\n",
    "                )\n",
    "                \n",
    "                if distance <= radius_meters:\n",
    "                    cluster.append(other)\n",
    "                    visited.add(j)\n",
    "            \n",
    "            if len(cluster) > 1:\n",
    "                clusters.append({\n",
    "                    'center_lat': np.mean([p['lat'] for p in cluster]),\n",
    "                    'center_lon': np.mean([p['lon'] for p in cluster]),\n",
    "                    'size': len(cluster),\n",
    "                    'total_detections': sum(p['count'] for p in cluster)\n",
    "                })\n",
    "        \n",
    "        return sorted(clusters, key=lambda x: x['total_detections'], reverse=True)\n",
    "    \n",
    "    def _haversine_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:\n",
    "        \"\"\"ë‘ GPS ì¢Œí‘œ ê°„ ê±°ë¦¬ ê³„ì‚° (ë¯¸í„°)\"\"\"\n",
    "        from math import radians, sin, cos, sqrt, atan2\n",
    "        \n",
    "        R = 6371000  # ì§€êµ¬ ë°˜ê²½ (ë¯¸í„°)\n",
    "        \n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "        \n",
    "        return R * c\n",
    "\n",
    "# ì§€ë¦¬ê³µê°„ ë¶„ì„ ì˜ˆì œ\n",
    "print(\"\\nğŸ—ºï¸ ì§€ë¦¬ê³µê°„ ë¶„ì„ ê¸°ëŠ¥\")\n",
    "\n",
    "if 'demo_session_id' in locals():\n",
    "    geo_analyzer = GeoSpatialAnalyzer(db_manager)\n",
    "    \n",
    "    # íˆíŠ¸ë§µ ë°ì´í„°\n",
    "    heatmap_data = geo_analyzer.get_detection_heatmap_data(demo_session_id)\n",
    "    print(f\"\\níˆíŠ¸ë§µ ë°ì´í„° í¬ì¸íŠ¸: {len(heatmap_data)}ê°œ\")\n",
    "    \n",
    "    # í´ëŸ¬ìŠ¤í„° ì°¾ê¸°\n",
    "    # clusters = geo_analyzer.find_clusters(demo_session_id, \"wheat\", radius_meters=100)\n",
    "    # print(f\"ë°œê²¬ëœ í´ëŸ¬ìŠ¤í„°: {len(clusters)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì„±ëŠ¥ ìµœì í™” íŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ\\n\")\n",
    "\n",
    "print(\"1. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”:\")\n",
    "print(\"   - ì¸ë±ìŠ¤ ìƒì„±ìœ¼ë¡œ ì¡°íšŒ ì†ë„ í–¥ìƒ\")\n",
    "print(\"   - ì •ê¸°ì  VACUUM ì‹¤í–‰\")\n",
    "print(\"   - ë°°ì¹˜ ì‚½ì… ì‚¬ìš©\")\n",
    "\n",
    "print(\"\\n2. ìŠ¤í† ë¦¬ì§€ ìµœì í™”:\")\n",
    "print(\"   - ì´ë¯¸ì§€ ì••ì¶• ì‚¬ìš©\")\n",
    "print(\"   - ì¸ë„¤ì¼ ìƒì„± ë° ìºì‹±\")\n",
    "print(\"   - ì˜¤ë˜ëœ ë°ì´í„° ì•„ì¹´ì´ë¹™\")\n",
    "\n",
    "print(\"\\n3. ë©”ëª¨ë¦¬ ìµœì í™”:\")\n",
    "print(\"   - ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬\")\n",
    "print(\"   - ì¿¼ë¦¬ ê²°ê³¼ í˜ì´ì§•\")\n",
    "print(\"   - ì„¸ì…˜ í’€ ì‚¬ìš©\")\n",
    "\n",
    "print(\"\\nâœ… ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ë‹¤ìŒ ëª¨ë“ˆ ì—°ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”— ë‹¤ìŒ ëª¨ë“ˆ ì—°ë™ ì •ë³´\\n\")\n",
    "\n",
    "print(\"ê²°ê³¼ ì €ì¥/ê´€ë¦¬ ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\\n\")\n",
    "\n",
    "print(\"ì´ ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ì´ ì—°ë™ë©ë‹ˆë‹¤:\\n\")\n",
    "\n",
    "print(\"1. â† Todo 5 (ë°°ì¹˜ ì²˜ë¦¬):\")\n",
    "print(\"   - BatchResultë¥¼ DetectionResultë¡œ ë³€í™˜\")\n",
    "print(\"   - ì„¸ì…˜ë³„ë¡œ ê²°ê³¼ ì €ì¥\")\n",
    "\n",
    "print(\"\\n2. â†’ Todo 7 (ìŠ¤ì¼€ì¤„ë§):\")\n",
    "print(\"   - ì •ê¸°ì  ë°±ì—… ìŠ¤ì¼€ì¤„ë§\")\n",
    "print(\"   - ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬\")\n",
    "\n",
    "print(\"\\n3. â†’ Todo 8 (ì‹œê°í™”):\")\n",
    "print(\"   - ì €ì¥ëœ ë°ì´í„° ê¸°ë°˜ ì°¨íŠ¸ ìƒì„±\")\n",
    "print(\"   - ì§€ë¦¬ê³µê°„ ì‹œê°í™”\")\n",
    "\n",
    "print(\"\\nì£¼ìš” íŠ¹ì§•:\")\n",
    "print(\"âœ“ SQLite ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜\")\n",
    "print(\"âœ“ ë‹¤ì–‘í•œ í˜•ì‹ ë‚´ë³´ë‚´ê¸°\")\n",
    "print(\"âœ“ GPS ê¸°ë°˜ ì§€ë¦¬ê³µê°„ ë¶„ì„\")\n",
    "print(\"âœ“ ë²„ì „ ê´€ë¦¬ ë° ë°±ì—…\")\n",
    "print(\"âœ“ íš¨ìœ¨ì  ì¿¼ë¦¬ ë° í•„í„°ë§\")\n",
    "\n",
    "print(\"\\níƒì§€ ê²°ê³¼ ì €ì¥/ê´€ë¦¬ ì‹œìŠ¤í…œ ê°œë°œ ì™„ë£Œ! âœ¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}