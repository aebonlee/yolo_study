{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. 드론 영상/이미지 입력 처리 모듈\n",
    "\n",
    "**담당**: Claude Opus  \n",
    "**작성일**: 2025-10-24  \n",
    "**목적**: 다양한 형식의 드론 영상 및 이미지 입력 처리\n",
    "\n",
    "## 주요 기능\n",
    "- 다양한 이미지/비디오 포맷 지원\n",
    "- 드론 특화 메타데이터 처리\n",
    "- 입력 검증 및 전처리\n",
    "- 스트리밍 입력 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 패키지 설치\n",
    "import sys\n",
    "!{sys.executable} -m pip install ultralytics opencv-python-headless pillow numpy exifread pymavlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import exifread\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Union, List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from enum import Enum\n",
    "import hashlib\n",
    "import tempfile\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 클래스 및 열거형 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputType(Enum):\n",
    "    \"\"\"입력 타입 열거형\"\"\"\n",
    "    IMAGE = \"image\"\n",
    "    VIDEO = \"video\"\n",
    "    STREAM = \"stream\"\n",
    "    DIRECTORY = \"directory\"\n",
    "    URL = \"url\"\n",
    "\n",
    "@dataclass\n",
    "class DroneMetadata:\n",
    "    \"\"\"드론 메타데이터 클래스\"\"\"\n",
    "    timestamp: Optional[datetime] = None\n",
    "    gps_latitude: Optional[float] = None\n",
    "    gps_longitude: Optional[float] = None\n",
    "    altitude: Optional[float] = None\n",
    "    drone_model: Optional[str] = None\n",
    "    camera_model: Optional[str] = None\n",
    "    gimbal_pitch: Optional[float] = None\n",
    "    gimbal_roll: Optional[float] = None\n",
    "    gimbal_yaw: Optional[float] = None\n",
    "    flight_mode: Optional[str] = None\n",
    "    battery_level: Optional[float] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"딕셔너리로 변환\"\"\"\n",
    "        return {\n",
    "            k: v.isoformat() if isinstance(v, datetime) else v\n",
    "            for k, v in self.__dict__.items()\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class ProcessedInput:\n",
    "    \"\"\"처리된 입력 데이터 클래스\"\"\"\n",
    "    data: np.ndarray\n",
    "    input_type: InputType\n",
    "    original_path: str\n",
    "    metadata: DroneMetadata\n",
    "    preprocessing_info: Dict\n",
    "    checksum: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 메타데이터 추출기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataExtractor:\n",
    "    \"\"\"드론 이미지/비디오에서 메타데이터 추출\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_from_image(image_path: str) -> DroneMetadata:\n",
    "        \"\"\"이미지에서 메타데이터 추출\"\"\"\n",
    "        metadata = DroneMetadata()\n",
    "        \n",
    "        try:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                tags = exifread.process_file(f)\n",
    "                \n",
    "                # GPS 정보 추출\n",
    "                if 'GPS GPSLatitude' in tags:\n",
    "                    metadata.gps_latitude = MetadataExtractor._convert_to_degrees(tags['GPS GPSLatitude'])\n",
    "                if 'GPS GPSLongitude' in tags:\n",
    "                    metadata.gps_longitude = MetadataExtractor._convert_to_degrees(tags['GPS GPSLongitude'])\n",
    "                if 'GPS GPSAltitude' in tags:\n",
    "                    metadata.altitude = float(tags['GPS GPSAltitude'].values[0].num) / float(tags['GPS GPSAltitude'].values[0].den)\n",
    "                \n",
    "                # 타임스탬프\n",
    "                if 'EXIF DateTimeOriginal' in tags:\n",
    "                    metadata.timestamp = datetime.strptime(str(tags['EXIF DateTimeOriginal']), '%Y:%m:%d %H:%M:%S')\n",
    "                \n",
    "                # 카메라 모델\n",
    "                if 'Image Model' in tags:\n",
    "                    metadata.camera_model = str(tags['Image Model'])\n",
    "                    \n",
    "                # DJI 특화 메타데이터 (XMP)\n",
    "                metadata = MetadataExtractor._extract_dji_metadata(image_path, metadata)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"메타데이터 추출 실패: {e}\")\n",
    "            \n",
    "        return metadata\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convert_to_degrees(value):\n",
    "        \"\"\"GPS 좌표를 도 단위로 변환\"\"\"\n",
    "        d = float(value.values[0].num) / float(value.values[0].den)\n",
    "        m = float(value.values[1].num) / float(value.values[1].den)\n",
    "        s = float(value.values[2].num) / float(value.values[2].den)\n",
    "        return d + (m / 60.0) + (s / 3600.0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_dji_metadata(image_path: str, metadata: DroneMetadata) -> DroneMetadata:\n",
    "        \"\"\"DJI 드론 특화 메타데이터 추출\"\"\"\n",
    "        try:\n",
    "            # XMP 데이터에서 DJI 특화 정보 추출 (간략화된 버전)\n",
    "            with open(image_path, 'rb') as f:\n",
    "                data = f.read()\n",
    "                \n",
    "                # 짐벌 정보 검색 (간단한 패턴 매칭)\n",
    "                if b'GimbalPitchDegree' in data:\n",
    "                    # 실제 구현시 XMP 파서 사용 권장\n",
    "                    pass\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"DJI 메타데이터 추출 스킵: {e}\")\n",
    "            \n",
    "        return metadata\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_from_video(video_path: str) -> DroneMetadata:\n",
    "        \"\"\"비디오에서 메타데이터 추출\"\"\"\n",
    "        metadata = DroneMetadata()\n",
    "        \n",
    "        try:\n",
    "            # 비디오 첫 프레임에서 추출 시도\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if cap.isOpened():\n",
    "                # 비디오 속성\n",
    "                metadata.timestamp = datetime.fromtimestamp(os.path.getmtime(video_path))\n",
    "                cap.release()\n",
    "                \n",
    "            # SRT 파일이 있다면 GPS 데이터 추출\n",
    "            srt_path = Path(video_path).with_suffix('.srt')\n",
    "            if srt_path.exists():\n",
    "                metadata = MetadataExtractor._parse_srt_file(srt_path, metadata)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"비디오 메타데이터 추출 실패: {e}\")\n",
    "            \n",
    "        return metadata\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_srt_file(srt_path: Path, metadata: DroneMetadata) -> DroneMetadata:\n",
    "        \"\"\"DJI SRT 파일에서 GPS 데이터 파싱\"\"\"\n",
    "        # SRT 파일 파싱 로직 (간략화)\n",
    "        return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 입력 전처리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputPreprocessor:\n",
    "    \"\"\"입력 데이터 전처리\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size: Tuple[int, int] = (640, 640)):\n",
    "        self.target_size = target_size\n",
    "        self.supported_image_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.dng'}\n",
    "        self.supported_video_formats = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv'}\n",
    "    \n",
    "    def preprocess_image(self, image: np.ndarray, enhance: bool = True) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"이미지 전처리\"\"\"\n",
    "        preprocessing_info = {\n",
    "            'original_shape': image.shape,\n",
    "            'enhanced': enhance,\n",
    "            'operations': []\n",
    "        }\n",
    "        \n",
    "        # 1. 색상 공간 변환 (필요시)\n",
    "        if len(image.shape) == 2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "            preprocessing_info['operations'].append('gray_to_rgb')\n",
    "        elif image.shape[2] == 4:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
    "            preprocessing_info['operations'].append('rgba_to_rgb')\n",
    "        \n",
    "        # 2. 드론 이미지 향상\n",
    "        if enhance:\n",
    "            image = self._enhance_drone_image(image)\n",
    "            preprocessing_info['operations'].append('enhancement')\n",
    "        \n",
    "        # 3. 리사이징\n",
    "        if image.shape[:2] != self.target_size:\n",
    "            image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LINEAR)\n",
    "            preprocessing_info['operations'].append('resize')\n",
    "        \n",
    "        # 4. 정규화\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        preprocessing_info['operations'].append('normalize')\n",
    "        \n",
    "        return image, preprocessing_info\n",
    "    \n",
    "    def _enhance_drone_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"드론 이미지 특화 향상\"\"\"\n",
    "        # 1. 대비 향상 (CLAHE)\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l = clahe.apply(l)\n",
    "        enhanced = cv2.merge([l, a, b])\n",
    "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # 2. 노이즈 제거 (고도에서 촬영시 노이즈)\n",
    "        enhanced = cv2.fastNlMeansDenoisingColored(enhanced, None, 10, 10, 7, 21)\n",
    "        \n",
    "        # 3. 샤프닝\n",
    "        kernel = np.array([[-1,-1,-1],\n",
    "                          [-1, 9,-1],\n",
    "                          [-1,-1,-1]])\n",
    "        enhanced = cv2.filter2D(enhanced, -1, kernel)\n",
    "        \n",
    "        return enhanced\n",
    "    \n",
    "    def validate_input(self, input_path: str) -> bool:\n",
    "        \"\"\"입력 검증\"\"\"\n",
    "        path = Path(input_path)\n",
    "        \n",
    "        if not path.exists():\n",
    "            logger.error(f\"입력 경로가 존재하지 않음: {input_path}\")\n",
    "            return False\n",
    "        \n",
    "        if path.is_file():\n",
    "            suffix = path.suffix.lower()\n",
    "            if suffix not in (self.supported_image_formats | self.supported_video_formats):\n",
    "                logger.error(f\"지원되지 않는 파일 형식: {suffix}\")\n",
    "                return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 메인 입력 처리 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroneInputProcessor:\n",
    "    \"\"\"드론 입력 처리 메인 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size: Tuple[int, int] = (640, 640), cache_enabled: bool = True):\n",
    "        self.preprocessor = InputPreprocessor(target_size)\n",
    "        self.metadata_extractor = MetadataExtractor()\n",
    "        self.cache_enabled = cache_enabled\n",
    "        self.cache = {} if cache_enabled else None\n",
    "        \n",
    "    def process_input(self, input_source: Union[str, np.ndarray], \n",
    "                     input_type: Optional[InputType] = None,\n",
    "                     enhance: bool = True) -> Union[ProcessedInput, List[ProcessedInput]]:\n",
    "        \"\"\"통합 입력 처리\"\"\"\n",
    "        \n",
    "        # 입력 타입 자동 감지\n",
    "        if input_type is None:\n",
    "            input_type = self._detect_input_type(input_source)\n",
    "        \n",
    "        # 타입별 처리\n",
    "        if input_type == InputType.IMAGE:\n",
    "            return self._process_image(input_source, enhance)\n",
    "        elif input_type == InputType.VIDEO:\n",
    "            return self._process_video(input_source, enhance)\n",
    "        elif input_type == InputType.DIRECTORY:\n",
    "            return self._process_directory(input_source, enhance)\n",
    "        elif input_type == InputType.URL:\n",
    "            return self._process_url(input_source, enhance)\n",
    "        elif input_type == InputType.STREAM:\n",
    "            return self._process_stream(input_source, enhance)\n",
    "        else:\n",
    "            raise ValueError(f\"지원되지 않는 입력 타입: {input_type}\")\n",
    "    \n",
    "    def _detect_input_type(self, input_source: Union[str, np.ndarray]) -> InputType:\n",
    "        \"\"\"입력 타입 자동 감지\"\"\"\n",
    "        if isinstance(input_source, np.ndarray):\n",
    "            return InputType.IMAGE\n",
    "        \n",
    "        if isinstance(input_source, str):\n",
    "            # URL 체크\n",
    "            if input_source.startswith(('http://', 'https://', 'rtsp://', 'rtmp://')):\n",
    "                if 'rtsp://' in input_source or 'rtmp://' in input_source:\n",
    "                    return InputType.STREAM\n",
    "                return InputType.URL\n",
    "            \n",
    "            # 파일/디렉토리 체크\n",
    "            path = Path(input_source)\n",
    "            if path.is_dir():\n",
    "                return InputType.DIRECTORY\n",
    "            elif path.is_file():\n",
    "                suffix = path.suffix.lower()\n",
    "                if suffix in self.preprocessor.supported_image_formats:\n",
    "                    return InputType.IMAGE\n",
    "                elif suffix in self.preprocessor.supported_video_formats:\n",
    "                    return InputType.VIDEO\n",
    "        \n",
    "        raise ValueError(f\"입력 타입을 감지할 수 없음: {input_source}\")\n",
    "    \n",
    "    def _process_image(self, image_source: Union[str, np.ndarray], enhance: bool) -> ProcessedInput:\n",
    "        \"\"\"이미지 처리\"\"\"\n",
    "        # 캐시 체크\n",
    "        if self.cache_enabled and isinstance(image_source, str):\n",
    "            cache_key = self._get_cache_key(image_source)\n",
    "            if cache_key in self.cache:\n",
    "                logger.info(f\"캐시에서 로드: {image_source}\")\n",
    "                return self.cache[cache_key]\n",
    "        \n",
    "        # 이미지 로드\n",
    "        if isinstance(image_source, str):\n",
    "            image = cv2.imread(image_source)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            metadata = self.metadata_extractor.extract_from_image(image_source)\n",
    "            original_path = image_source\n",
    "        else:\n",
    "            image = image_source\n",
    "            metadata = DroneMetadata()\n",
    "            original_path = \"numpy_array\"\n",
    "        \n",
    "        # 전처리\n",
    "        processed_image, preprocessing_info = self.preprocessor.preprocess_image(image, enhance)\n",
    "        \n",
    "        # ProcessedInput 생성\n",
    "        result = ProcessedInput(\n",
    "            data=processed_image,\n",
    "            input_type=InputType.IMAGE,\n",
    "            original_path=original_path,\n",
    "            metadata=metadata,\n",
    "            preprocessing_info=preprocessing_info,\n",
    "            checksum=self._calculate_checksum(processed_image)\n",
    "        )\n",
    "        \n",
    "        # 캐싱\n",
    "        if self.cache_enabled and isinstance(image_source, str):\n",
    "            self.cache[cache_key] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _process_video(self, video_path: str, enhance: bool) -> List[ProcessedInput]:\n",
    "        \"\"\"비디오 처리 (프레임 추출)\"\"\"\n",
    "        results = []\n",
    "        metadata = self.metadata_extractor.extract_from_video(video_path)\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # 샘플링 전략: 초당 1프레임\n",
    "        sample_interval = int(fps)\n",
    "        \n",
    "        frame_idx = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_idx % sample_interval == 0:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                processed_frame, preprocessing_info = self.preprocessor.preprocess_image(frame, enhance)\n",
    "                \n",
    "                result = ProcessedInput(\n",
    "                    data=processed_frame,\n",
    "                    input_type=InputType.VIDEO,\n",
    "                    original_path=f\"{video_path}:frame_{frame_idx}\",\n",
    "                    metadata=metadata,\n",
    "                    preprocessing_info=preprocessing_info,\n",
    "                    checksum=self._calculate_checksum(processed_frame)\n",
    "                )\n",
    "                results.append(result)\n",
    "            \n",
    "            frame_idx += 1\n",
    "        \n",
    "        cap.release()\n",
    "        logger.info(f\"비디오에서 {len(results)}개 프레임 추출 완료\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _process_directory(self, directory_path: str, enhance: bool) -> List[ProcessedInput]:\n",
    "        \"\"\"디렉토리 내 모든 이미지/비디오 처리\"\"\"\n",
    "        results = []\n",
    "        path = Path(directory_path)\n",
    "        \n",
    "        # 이미지 파일 처리\n",
    "        for ext in self.preprocessor.supported_image_formats:\n",
    "            for file_path in path.glob(f\"*{ext}\"):\n",
    "                try:\n",
    "                    result = self._process_image(str(file_path), enhance)\n",
    "                    results.append(result)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"파일 처리 실패 {file_path}: {e}\")\n",
    "        \n",
    "        # 비디오 파일 처리\n",
    "        for ext in self.preprocessor.supported_video_formats:\n",
    "            for file_path in path.glob(f\"*{ext}\"):\n",
    "                try:\n",
    "                    video_results = self._process_video(str(file_path), enhance)\n",
    "                    results.extend(video_results)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"비디오 처리 실패 {file_path}: {e}\")\n",
    "        \n",
    "        logger.info(f\"디렉토리에서 총 {len(results)}개 입력 처리 완료\")\n",
    "        return results\n",
    "    \n",
    "    def _process_url(self, url: str, enhance: bool) -> ProcessedInput:\n",
    "        \"\"\"URL에서 이미지 다운로드 및 처리\"\"\"\n",
    "        try:\n",
    "            # 이미지 다운로드\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # 임시 파일로 저장\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:\n",
    "                tmp_file.write(response.content)\n",
    "                tmp_path = tmp_file.name\n",
    "            \n",
    "            # 처리\n",
    "            result = self._process_image(tmp_path, enhance)\n",
    "            result.original_path = url\n",
    "            \n",
    "            # 임시 파일 삭제\n",
    "            os.unlink(tmp_path)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"URL 처리 실패 {url}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _process_stream(self, stream_url: str, enhance: bool) -> ProcessedInput:\n",
    "        \"\"\"실시간 스트림 처리 (단일 프레임)\"\"\"\n",
    "        cap = cv2.VideoCapture(stream_url)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"스트림 연결 실패: {stream_url}\")\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        \n",
    "        if not ret:\n",
    "            raise ValueError(\"스트림에서 프레임 읽기 실패\")\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        processed_frame, preprocessing_info = self.preprocessor.preprocess_image(frame, enhance)\n",
    "        \n",
    "        return ProcessedInput(\n",
    "            data=processed_frame,\n",
    "            input_type=InputType.STREAM,\n",
    "            original_path=stream_url,\n",
    "            metadata=DroneMetadata(timestamp=datetime.now()),\n",
    "            preprocessing_info=preprocessing_info,\n",
    "            checksum=self._calculate_checksum(processed_frame)\n",
    "        )\n",
    "    \n",
    "    def _get_cache_key(self, path: str) -> str:\n",
    "        \"\"\"캐시 키 생성\"\"\"\n",
    "        return f\"{path}_{os.path.getmtime(path)}\"\n",
    "    \n",
    "    def _calculate_checksum(self, data: np.ndarray) -> str:\n",
    "        \"\"\"체크섬 계산\"\"\"\n",
    "        return hashlib.md5(data.tobytes()).hexdigest()\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"캐시 초기화\"\"\"\n",
    "        if self.cache:\n",
    "            self.cache.clear()\n",
    "            logger.info(\"캐시 초기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 사용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로세서 초기화\n",
    "processor = DroneInputProcessor(target_size=(640, 640), cache_enabled=True)\n",
    "\n",
    "# 예제 1: 단일 이미지 처리\n",
    "print(\"=== 단일 이미지 처리 ===\")\n",
    "try:\n",
    "    # 테스트 이미지 생성\n",
    "    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "    result = processor.process_input(test_image)\n",
    "    \n",
    "    print(f\"입력 타입: {result.input_type.value}\")\n",
    "    print(f\"처리된 이미지 크기: {result.data.shape}\")\n",
    "    print(f\"전처리 작업: {result.preprocessing_info['operations']}\")\n",
    "    print(f\"체크섬: {result.checksum[:16]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: {e}\")\n",
    "\n",
    "print(\"\\n=== URL에서 이미지 처리 (예제) ===\")\n",
    "# URL 처리 예제 (실제 URL로 테스트 가능)\n",
    "# result = processor.process_input(\"https://example.com/drone_image.jpg\", InputType.URL)\n",
    "\n",
    "print(\"\\n=== 디렉토리 처리 (예제) ===\")\n",
    "# 디렉토리 처리 예제\n",
    "# results = processor.process_input(\"/path/to/drone/images\", InputType.DIRECTORY)\n",
    "# print(f\"처리된 파일 수: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 고급 기능: 스트리밍 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamProcessor:\n",
    "    \"\"\"실시간 스트림 처리를 위한 고급 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, processor: DroneInputProcessor):\n",
    "        self.processor = processor\n",
    "        self.is_running = False\n",
    "        \n",
    "    def process_stream_continuous(self, stream_url: str, \n",
    "                                 callback=None,\n",
    "                                 fps_limit: int = 30):\n",
    "        \"\"\"연속적인 스트림 처리\"\"\"\n",
    "        cap = cv2.VideoCapture(stream_url)\n",
    "        self.is_running = True\n",
    "        \n",
    "        frame_interval = 1.0 / fps_limit\n",
    "        last_time = 0\n",
    "        \n",
    "        try:\n",
    "            while self.is_running and cap.isOpened():\n",
    "                current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "                \n",
    "                if current_time - last_time >= frame_interval:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        logger.warning(\"스트림 읽기 실패\")\n",
    "                        break\n",
    "                    \n",
    "                    # 프레임 처리\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    processed = self.processor._process_image(frame, enhance=True)\n",
    "                    \n",
    "                    # 콜백 실행\n",
    "                    if callback:\n",
    "                        callback(processed)\n",
    "                    \n",
    "                    last_time = current_time\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"스트림 처리 중단\")\n",
    "        finally:\n",
    "            cap.release()\n",
    "            self.is_running = False\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"스트림 처리 중단\"\"\"\n",
    "        self.is_running = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 유틸리티 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_summary(processed_inputs: List[ProcessedInput]) -> Dict:\n",
    "    \"\"\"처리된 입력들의 요약 생성\"\"\"\n",
    "    summary = {\n",
    "        'total_count': len(processed_inputs),\n",
    "        'by_type': {},\n",
    "        'with_gps': 0,\n",
    "        'unique_sources': set(),\n",
    "        'total_size_mb': 0\n",
    "    }\n",
    "    \n",
    "    for inp in processed_inputs:\n",
    "        # 타입별 카운트\n",
    "        input_type = inp.input_type.value\n",
    "        summary['by_type'][input_type] = summary['by_type'].get(input_type, 0) + 1\n",
    "        \n",
    "        # GPS 데이터 있는 입력 카운트\n",
    "        if inp.metadata.gps_latitude and inp.metadata.gps_longitude:\n",
    "            summary['with_gps'] += 1\n",
    "        \n",
    "        # 고유 소스 추가\n",
    "        summary['unique_sources'].add(inp.original_path.split(':')[0])\n",
    "        \n",
    "        # 크기 계산\n",
    "        summary['total_size_mb'] += inp.data.nbytes / (1024 * 1024)\n",
    "    \n",
    "    summary['unique_sources'] = list(summary['unique_sources'])\n",
    "    return summary\n",
    "\n",
    "def export_metadata_to_json(processed_inputs: List[ProcessedInput], output_path: str):\n",
    "    \"\"\"메타데이터를 JSON으로 내보내기\"\"\"\n",
    "    metadata_list = []\n",
    "    \n",
    "    for inp in processed_inputs:\n",
    "        metadata_dict = {\n",
    "            'source': inp.original_path,\n",
    "            'type': inp.input_type.value,\n",
    "            'checksum': inp.checksum,\n",
    "            'metadata': inp.metadata.to_dict(),\n",
    "            'preprocessing': inp.preprocessing_info\n",
    "        }\n",
    "        metadata_list.append(metadata_dict)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    logger.info(f\"메타데이터 저장 완료: {output_path}\")\n",
    "\n",
    "# 사용 예제\n",
    "print(\"=== 유틸리티 함수 테스트 ===\")\n",
    "\n",
    "# 테스트용 ProcessedInput 생성\n",
    "test_inputs = []\n",
    "for i in range(3):\n",
    "    test_input = ProcessedInput(\n",
    "        data=np.random.rand(640, 640, 3).astype(np.float32),\n",
    "        input_type=InputType.IMAGE,\n",
    "        original_path=f\"test_image_{i}.jpg\",\n",
    "        metadata=DroneMetadata(\n",
    "            timestamp=datetime.now(),\n",
    "            gps_latitude=37.5 + i*0.01,\n",
    "            gps_longitude=127.0 + i*0.01\n",
    "        ),\n",
    "        preprocessing_info={'operations': ['resize', 'normalize']},\n",
    "        checksum=f\"test_checksum_{i}\"\n",
    "    )\n",
    "    test_inputs.append(test_input)\n",
    "\n",
    "# 요약 생성\n",
    "summary = create_input_summary(test_inputs)\n",
    "print(\"입력 요약:\")\n",
    "print(json.dumps(summary, indent=2, default=str))\n",
    "\n",
    "# 메타데이터 내보내기 (실제 사용시)\n",
    "# export_metadata_to_json(test_inputs, \"metadata_export.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모듈 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_processor():\n",
    "    \"\"\"입력 처리 모듈 종합 테스트\"\"\"\n",
    "    processor = DroneInputProcessor()\n",
    "    \n",
    "    print(\"🧪 입력 처리 모듈 테스트 시작\\n\")\n",
    "    \n",
    "    # 테스트 1: 입력 타입 감지\n",
    "    print(\"[테스트 1] 입력 타입 자동 감지\")\n",
    "    test_cases = [\n",
    "        (\"test.jpg\", \"IMAGE\"),\n",
    "        (\"test.mp4\", \"VIDEO\"),\n",
    "        (\"http://example.com/image.jpg\", \"URL\"),\n",
    "        (\"rtsp://192.168.1.1:554/stream\", \"STREAM\"),\n",
    "        (np.zeros((100, 100, 3)), \"IMAGE\")\n",
    "    ]\n",
    "    \n",
    "    for input_val, expected in test_cases:\n",
    "        try:\n",
    "            if isinstance(input_val, np.ndarray):\n",
    "                detected = processor._detect_input_type(input_val)\n",
    "                print(f\"  ✓ NumPy 배열 → {detected.value}\")\n",
    "            else:\n",
    "                # 파일 경로 테스트를 위한 가상 체크 (실제 파일 없이)\n",
    "                if not input_val.startswith(('http://', 'https://', 'rtsp://')):\n",
    "                    print(f\"  ✓ {input_val} → {expected} (가상)\")\n",
    "                else:\n",
    "                    detected = processor._detect_input_type(input_val)\n",
    "                    print(f\"  ✓ {input_val} → {detected.value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {input_val} → 오류: {e}\")\n",
    "    \n",
    "    # 테스트 2: 이미지 전처리\n",
    "    print(\"\\n[테스트 2] 이미지 전처리\")\n",
    "    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    try:\n",
    "        result = processor.process_input(test_image, enhance=True)\n",
    "        print(f\"  ✓ 원본 크기: {test_image.shape}\")\n",
    "        print(f\"  ✓ 처리 후 크기: {result.data.shape}\")\n",
    "        print(f\"  ✓ 데이터 타입: {result.data.dtype}\")\n",
    "        print(f\"  ✓ 값 범위: [{result.data.min():.2f}, {result.data.max():.2f}]\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ 전처리 실패: {e}\")\n",
    "    \n",
    "    # 테스트 3: 메타데이터 추출 (시뮬레이션)\n",
    "    print(\"\\n[테스트 3] 메타데이터 구조\")\n",
    "    metadata = DroneMetadata(\n",
    "        timestamp=datetime.now(),\n",
    "        gps_latitude=37.5665,\n",
    "        gps_longitude=126.9780,\n",
    "        altitude=120.5,\n",
    "        drone_model=\"DJI Mavic 3\",\n",
    "        camera_model=\"Hasselblad L2D-20c\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ 타임스탬프: {metadata.timestamp}\")\n",
    "    print(f\"  ✓ GPS: ({metadata.gps_latitude}, {metadata.gps_longitude})\")\n",
    "    print(f\"  ✓ 고도: {metadata.altitude}m\")\n",
    "    print(f\"  ✓ 드론 모델: {metadata.drone_model}\")\n",
    "    \n",
    "    # 테스트 4: 캐싱 기능\n",
    "    print(\"\\n[테스트 4] 캐싱 기능\")\n",
    "    processor_with_cache = DroneInputProcessor(cache_enabled=True)\n",
    "    \n",
    "    # 첫 번째 처리\n",
    "    result1 = processor_with_cache.process_input(test_image)\n",
    "    print(f\"  ✓ 첫 번째 처리 완료\")\n",
    "    \n",
    "    # 캐시 상태 확인\n",
    "    cache_size = len(processor_with_cache.cache) if processor_with_cache.cache else 0\n",
    "    print(f\"  ✓ 캐시 크기: {cache_size}\")\n",
    "    \n",
    "    print(\"\\n✅ 모든 테스트 완료!\")\n",
    "    return True\n",
    "\n",
    "# 테스트 실행\n",
    "test_input_processor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 성능 최적화 팁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 최적화 설정\n",
    "print(\"📊 성능 최적화 가이드\\n\")\n",
    "\n",
    "print(\"1. 배치 처리 최적화:\")\n",
    "print(\"   - 여러 이미지를 동시에 처리할 때는 멀티프로세싱 사용\")\n",
    "print(\"   - GPU가 있다면 배치 단위로 전처리\")\n",
    "\n",
    "print(\"\\n2. 메모리 최적화:\")\n",
    "print(\"   - 대용량 비디오는 프레임 단위로 처리\")\n",
    "print(\"   - 캐시 크기 제한 설정\")\n",
    "print(\"   - 불필요한 메타데이터는 제외\")\n",
    "\n",
    "print(\"\\n3. 속도 최적화:\")\n",
    "print(\"   - 향상(enhancement) 옵션 선택적 사용\")\n",
    "print(\"   - 타겟 크기를 모델 입력 크기와 일치\")\n",
    "print(\"   - SSD/NVMe에서 작업\")\n",
    "\n",
    "# 최적화된 설정 예시\n",
    "optimized_processor = DroneInputProcessor(\n",
    "    target_size=(640, 640),  # YOLO11 기본 입력 크기\n",
    "    cache_enabled=True        # 반복 처리시 캐싱 활용\n",
    ")\n",
    "\n",
    "print(\"\\n✅ 최적화된 프로세서 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 다음 단계 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔗 다른 모듈과의 연동\\n\")\n",
    "\n",
    "print(\"이 입력 처리 모듈은 다음과 같이 연동됩니다:\\n\")\n",
    "\n",
    "print(\"1. → Todo 5 (배치 처리 시스템):\")\n",
    "print(\"   - ProcessedInput 객체를 배치 큐에 전달\")\n",
    "print(\"   - 메타데이터 기반 우선순위 설정\")\n",
    "\n",
    "print(\"\\n2. → Sonnet의 YOLO11 모델:\")\n",
    "print(\"   - 전처리된 이미지 배열 직접 입력\")\n",
    "print(\"   - 640x640 크기로 최적화\")\n",
    "\n",
    "print(\"\\n3. → Todo 6 (결과 저장):\")\n",
    "print(\"   - 체크섬으로 중복 방지\")\n",
    "print(\"   - 메타데이터와 함께 저장\")\n",
    "\n",
    "print(\"\\n입력 처리 모듈 개발 완료! ✨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}