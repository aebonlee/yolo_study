{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ\n",
    "\n",
    "**ë‹´ë‹¹**: Claude Opus  \n",
    "**ì‘ì„±ì¼**: 2025-10-24  \n",
    "**ëª©ì **: ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‹œ ë¶„ì„í•˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- ë©€í‹°í”„ë¡œì„¸ì‹±/ë©€í‹°ìŠ¤ë ˆë”© ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬\n",
    "- ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •\n",
    "- ìš°ì„ ìˆœìœ„ ê¸°ë°˜ í ê´€ë¦¬\n",
    "- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬\n",
    "- ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "import sys\n",
    "!{sys.executable} -m pip install ultralytics opencv-python-headless numpy tqdm psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Optional, Tuple, Any, Union, Callable\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from enum import Enum\n",
    "import queue\n",
    "import threading\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import hashlib\n",
    "from collections import deque, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°°ì¹˜ ì²˜ë¦¬ ë°ì´í„° í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingStatus(Enum):\n",
    "    \"\"\"ì²˜ë¦¬ ìƒíƒœ ì—´ê±°í˜•\"\"\"\n",
    "    PENDING = \"pending\"\n",
    "    PROCESSING = \"processing\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    CANCELLED = \"cancelled\"\n",
    "\n",
    "class Priority(Enum):\n",
    "    \"\"\"ìš°ì„ ìˆœìœ„ ë ˆë²¨\"\"\"\n",
    "    LOW = 3\n",
    "    NORMAL = 2\n",
    "    HIGH = 1\n",
    "    URGENT = 0\n",
    "\n",
    "@dataclass\n",
    "class BatchItem:\n",
    "    \"\"\"ë°°ì¹˜ ì²˜ë¦¬ í•­ëª©\"\"\"\n",
    "    id: str\n",
    "    image_path: str\n",
    "    image_data: Optional[np.ndarray] = None\n",
    "    priority: Priority = Priority.NORMAL\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "    status: ProcessingStatus = ProcessingStatus.PENDING\n",
    "    result: Optional[Any] = None\n",
    "    error: Optional[str] = None\n",
    "    processing_time: Optional[float] = None\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        \"\"\"ìš°ì„ ìˆœìœ„ ë¹„êµë¥¼ ìœ„í•œ ë©”ì„œë“œ\"\"\"\n",
    "        return self.priority.value < other.priority.value\n",
    "\n",
    "@dataclass\n",
    "class BatchResult:\n",
    "    \"\"\"ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼\"\"\"\n",
    "    batch_id: str\n",
    "    total_items: int\n",
    "    successful: int\n",
    "    failed: int\n",
    "    total_time: float\n",
    "    average_time: float\n",
    "    items: List[BatchItem]\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"ë”•ì…”ë„ˆë¦¬ ë³€í™˜\"\"\"\n",
    "        return {\n",
    "            'batch_id': self.batch_id,\n",
    "            'total_items': self.total_items,\n",
    "            'successful': self.successful,\n",
    "            'failed': self.failed,\n",
    "            'total_time': self.total_time,\n",
    "            'average_time': self.average_time,\n",
    "            'timestamp': self.timestamp.isoformat()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceMonitor:\n",
    "    \"\"\"ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cpu_threshold = 90  # CPU ì‚¬ìš©ë¥  ì„ê³„ê°’ (%)\n",
    "        self.memory_threshold = 85  # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì„ê³„ê°’ (%)\n",
    "        self.is_monitoring = False\n",
    "        self.stats_history = deque(maxlen=100)\n",
    "        \n",
    "    def get_current_stats(self) -> Dict:\n",
    "        \"\"\"í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ\"\"\"\n",
    "        return {\n",
    "            'cpu_percent': psutil.cpu_percent(interval=0.1),\n",
    "            'memory_percent': psutil.virtual_memory().percent,\n",
    "            'memory_available_gb': psutil.virtual_memory().available / (1024**3),\n",
    "            'disk_usage_percent': psutil.disk_usage('/').percent,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "    \n",
    "    def is_resource_available(self) -> bool:\n",
    "        \"\"\"ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\"\"\"\n",
    "        stats = self.get_current_stats()\n",
    "        return (\n",
    "            stats['cpu_percent'] < self.cpu_threshold and\n",
    "            stats['memory_percent'] < self.memory_threshold\n",
    "        )\n",
    "    \n",
    "    def get_optimal_batch_size(self, base_size: int = 32) -> int:\n",
    "        \"\"\"í˜„ì¬ ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°\"\"\"\n",
    "        stats = self.get_current_stats()\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¡°ì •\n",
    "        memory_factor = (100 - stats['memory_percent']) / 100\n",
    "        \n",
    "        # CPU ê¸°ë°˜ ì¡°ì •\n",
    "        cpu_factor = (100 - stats['cpu_percent']) / 100\n",
    "        \n",
    "        # ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°\n",
    "        optimal_size = int(base_size * min(memory_factor, cpu_factor))\n",
    "        \n",
    "        return max(1, min(optimal_size, base_size))\n",
    "    \n",
    "    def get_optimal_workers(self) -> int:\n",
    "        \"\"\"ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        cpu_count = mp.cpu_count()\n",
    "        stats = self.get_current_stats()\n",
    "        \n",
    "        # CPU ì‚¬ìš©ë¥ ì— ë”°ë¼ ì›Œì»¤ ìˆ˜ ì¡°ì •\n",
    "        if stats['cpu_percent'] > 80:\n",
    "            return max(1, cpu_count // 2)\n",
    "        elif stats['cpu_percent'] > 60:\n",
    "            return max(2, cpu_count - 2)\n",
    "        else:\n",
    "            return cpu_count\n",
    "    \n",
    "    def start_monitoring(self, callback: Optional[Callable] = None):\n",
    "        \"\"\"ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì‹œì‘\"\"\"\n",
    "        self.is_monitoring = True\n",
    "        \n",
    "        def monitor_loop():\n",
    "            while self.is_monitoring:\n",
    "                stats = self.get_current_stats()\n",
    "                self.stats_history.append(stats)\n",
    "                \n",
    "                if callback:\n",
    "                    callback(stats)\n",
    "                \n",
    "                time.sleep(1)\n",
    "        \n",
    "        thread = threading.Thread(target=monitor_loop, daemon=True)\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\"\"\"\n",
    "        self.is_monitoring = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë°°ì¹˜ í ê´€ë¦¬ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchQueue:\n",
    "    \"\"\"ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë°°ì¹˜ í\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: Optional[int] = None):\n",
    "        self.queue = queue.PriorityQueue(maxsize=max_size or 0)\n",
    "        self.processing_items = {}\n",
    "        self.completed_items = {}\n",
    "        self.failed_items = {}\n",
    "        self.lock = threading.Lock()\n",
    "        self.stats = defaultdict(int)\n",
    "        \n",
    "    def add_item(self, item: BatchItem):\n",
    "        \"\"\"í•­ëª© ì¶”ê°€\"\"\"\n",
    "        self.queue.put((item.priority.value, item.timestamp, item))\n",
    "        self.stats['total_added'] += 1\n",
    "        logger.debug(f\"í•­ëª© ì¶”ê°€: {item.id} (ìš°ì„ ìˆœìœ„: {item.priority.name})\")\n",
    "    \n",
    "    def add_batch(self, items: List[BatchItem]):\n",
    "        \"\"\"ì—¬ëŸ¬ í•­ëª© ì¼ê´„ ì¶”ê°€\"\"\"\n",
    "        for item in items:\n",
    "            self.add_item(item)\n",
    "        logger.info(f\"{len(items)}ê°œ í•­ëª© íì— ì¶”ê°€\")\n",
    "    \n",
    "    def get_item(self, timeout: Optional[float] = None) -> Optional[BatchItem]:\n",
    "        \"\"\"í•­ëª© ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            _, _, item = self.queue.get(timeout=timeout)\n",
    "            with self.lock:\n",
    "                item.status = ProcessingStatus.PROCESSING\n",
    "                self.processing_items[item.id] = item\n",
    "            return item\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "    \n",
    "    def get_batch(self, batch_size: int, timeout: float = 1.0) -> List[BatchItem]:\n",
    "        \"\"\"ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•­ëª© ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        batch = []\n",
    "        deadline = time.time() + timeout\n",
    "        \n",
    "        while len(batch) < batch_size and time.time() < deadline:\n",
    "            remaining_time = deadline - time.time()\n",
    "            if remaining_time <= 0:\n",
    "                break\n",
    "            \n",
    "            item = self.get_item(timeout=min(0.1, remaining_time))\n",
    "            if item:\n",
    "                batch.append(item)\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def mark_completed(self, item: BatchItem):\n",
    "        \"\"\"í•­ëª©ì„ ì™„ë£Œë¡œ í‘œì‹œ\"\"\"\n",
    "        with self.lock:\n",
    "            item.status = ProcessingStatus.COMPLETED\n",
    "            if item.id in self.processing_items:\n",
    "                del self.processing_items[item.id]\n",
    "            self.completed_items[item.id] = item\n",
    "            self.stats['completed'] += 1\n",
    "    \n",
    "    def mark_failed(self, item: BatchItem, error: str):\n",
    "        \"\"\"í•­ëª©ì„ ì‹¤íŒ¨ë¡œ í‘œì‹œ\"\"\"\n",
    "        with self.lock:\n",
    "            item.status = ProcessingStatus.FAILED\n",
    "            item.error = error\n",
    "            if item.id in self.processing_items:\n",
    "                del self.processing_items[item.id]\n",
    "            self.failed_items[item.id] = item\n",
    "            self.stats['failed'] += 1\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"í†µê³„ ì •ë³´ ë°˜í™˜\"\"\"\n",
    "        with self.lock:\n",
    "            return {\n",
    "                'pending': self.queue.qsize(),\n",
    "                'processing': len(self.processing_items),\n",
    "                'completed': len(self.completed_items),\n",
    "                'failed': len(self.failed_items),\n",
    "                'total': self.stats['total_added']\n",
    "            }\n",
    "    \n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\"íê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        return self.queue.empty() and len(self.processing_items) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, model_func: Optional[Callable] = None):\n",
    "        self.model_func = model_func or self._default_process\n",
    "        \n",
    "    def _default_process(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"ê¸°ë³¸ ì²˜ë¦¬ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)\"\"\"\n",
    "        # ì‹¤ì œë¡œëŠ” YOLO11 ëª¨ë¸ ì¶”ë¡ ì´ ë“¤ì–´ê°ˆ ìœ„ì¹˜\n",
    "        time.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "        return {\n",
    "            'detections': [],\n",
    "            'confidence': 0.0,\n",
    "            'processing_time': 0.1\n",
    "        }\n",
    "    \n",
    "    def process_image(self, item: BatchItem) -> BatchItem:\n",
    "        \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "            if item.image_data is None:\n",
    "                image = cv2.imread(item.image_path)\n",
    "                if image is None:\n",
    "                    raise ValueError(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {item.image_path}\")\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                image = item.image_data\n",
    "            \n",
    "            # ëª¨ë¸ ì²˜ë¦¬\n",
    "            result = self.model_func(image)\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            item.result = result\n",
    "            item.processing_time = time.time() - start_time\n",
    "            item.status = ProcessingStatus.COMPLETED\n",
    "            \n",
    "        except Exception as e:\n",
    "            item.error = str(e)\n",
    "            item.status = ProcessingStatus.FAILED\n",
    "            item.processing_time = time.time() - start_time\n",
    "            logger.error(f\"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ {item.id}: {e}\")\n",
    "        \n",
    "        return item\n",
    "    \n",
    "    def process_batch(self, items: List[BatchItem]) -> List[BatchItem]:\n",
    "        \"\"\"ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬\"\"\"\n",
    "        results = []\n",
    "        for item in items:\n",
    "            processed = self.process_image(item)\n",
    "            results.append(processed)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchProcessingEngine:\n",
    "    \"\"\"ë©”ì¸ ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_func: Optional[Callable] = None,\n",
    "                 num_workers: Optional[int] = None,\n",
    "                 batch_size: int = 32,\n",
    "                 use_multiprocessing: bool = False):\n",
    "        \n",
    "        self.processor = ImageProcessor(model_func)\n",
    "        self.resource_monitor = ResourceMonitor()\n",
    "        self.batch_queue = BatchQueue()\n",
    "        \n",
    "        # ì›Œì»¤ ì„¤ì •\n",
    "        self.num_workers = num_workers or self.resource_monitor.get_optimal_workers()\n",
    "        self.batch_size = batch_size\n",
    "        self.use_multiprocessing = use_multiprocessing\n",
    "        \n",
    "        # ì‹¤í–‰ ì œì–´\n",
    "        self.is_running = False\n",
    "        self.executor = None\n",
    "        self.workers = []\n",
    "        \n",
    "        # í†µê³„\n",
    "        self.start_time = None\n",
    "        self.processed_count = 0\n",
    "        \n",
    "        logger.info(f\"ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„ ì´ˆê¸°í™” (ì›Œì»¤: {self.num_workers}, ë°°ì¹˜ í¬ê¸°: {self.batch_size})\")\n",
    "    \n",
    "    def add_images(self, image_paths: List[str], priority: Priority = Priority.NORMAL):\n",
    "        \"\"\"ì´ë¯¸ì§€ ì¶”ê°€\"\"\"\n",
    "        items = []\n",
    "        for i, path in enumerate(image_paths):\n",
    "            item = BatchItem(\n",
    "                id=f\"{datetime.now().timestamp()}_{i}\",\n",
    "                image_path=path,\n",
    "                priority=priority\n",
    "            )\n",
    "            items.append(item)\n",
    "        \n",
    "        self.batch_queue.add_batch(items)\n",
    "        logger.info(f\"{len(items)}ê°œ ì´ë¯¸ì§€ ì¶”ê°€ (ìš°ì„ ìˆœìœ„: {priority.name})\")\n",
    "    \n",
    "    def _worker_thread(self, worker_id: int):\n",
    "        \"\"\"ì›Œì»¤ ìŠ¤ë ˆë“œ\"\"\"\n",
    "        logger.info(f\"ì›Œì»¤ {worker_id} ì‹œì‘\")\n",
    "        \n",
    "        while self.is_running:\n",
    "            # ë¦¬ì†ŒìŠ¤ ì²´í¬\n",
    "            if not self.resource_monitor.is_resource_available():\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            \n",
    "            # ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •\n",
    "            current_batch_size = self.resource_monitor.get_optimal_batch_size(self.batch_size)\n",
    "            \n",
    "            # ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°\n",
    "            batch = self.batch_queue.get_batch(current_batch_size, timeout=1.0)\n",
    "            \n",
    "            if not batch:\n",
    "                if self.batch_queue.is_empty():\n",
    "                    time.sleep(0.1)\n",
    "                continue\n",
    "            \n",
    "            # ë°°ì¹˜ ì²˜ë¦¬\n",
    "            logger.debug(f\"ì›Œì»¤ {worker_id}: {len(batch)}ê°œ í•­ëª© ì²˜ë¦¬ ì‹œì‘\")\n",
    "            \n",
    "            try:\n",
    "                processed = self.processor.process_batch(batch)\n",
    "                \n",
    "                for item in processed:\n",
    "                    if item.status == ProcessingStatus.COMPLETED:\n",
    "                        self.batch_queue.mark_completed(item)\n",
    "                    else:\n",
    "                        self.batch_queue.mark_failed(item, item.error or \"Unknown error\")\n",
    "                    \n",
    "                    self.processed_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì›Œì»¤ {worker_id} ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "                for item in batch:\n",
    "                    self.batch_queue.mark_failed(item, str(e))\n",
    "        \n",
    "        logger.info(f\"ì›Œì»¤ {worker_id} ì¢…ë£Œ\")\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"ì²˜ë¦¬ ì‹œì‘\"\"\"\n",
    "        if self.is_running:\n",
    "            logger.warning(\"ì´ë¯¸ ì‹¤í–‰ ì¤‘\")\n",
    "            return\n",
    "        \n",
    "        self.is_running = True\n",
    "        self.start_time = time.time()\n",
    "        self.processed_count = 0\n",
    "        \n",
    "        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘\n",
    "        self.resource_monitor.start_monitoring()\n",
    "        \n",
    "        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘\n",
    "        if self.use_multiprocessing:\n",
    "            self.executor = ProcessPoolExecutor(max_workers=self.num_workers)\n",
    "        else:\n",
    "            self.executor = ThreadPoolExecutor(max_workers=self.num_workers)\n",
    "        \n",
    "        for i in range(self.num_workers):\n",
    "            worker = threading.Thread(target=self._worker_thread, args=(i,))\n",
    "            worker.daemon = True\n",
    "            worker.start()\n",
    "            self.workers.append(worker)\n",
    "        \n",
    "        logger.info(f\"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ ({self.num_workers}ê°œ ì›Œì»¤)\")\n",
    "    \n",
    "    def stop(self, wait: bool = True):\n",
    "        \"\"\"ì²˜ë¦¬ ì¤‘ì§€\"\"\"\n",
    "        if not self.is_running:\n",
    "            return\n",
    "        \n",
    "        logger.info(\"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ì§€ ìš”ì²­\")\n",
    "        self.is_running = False\n",
    "        \n",
    "        # ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°\n",
    "        if wait:\n",
    "            for worker in self.workers:\n",
    "                worker.join(timeout=5)\n",
    "        \n",
    "        # Executor ì¢…ë£Œ\n",
    "        if self.executor:\n",
    "            self.executor.shutdown(wait=wait)\n",
    "        \n",
    "        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\n",
    "        self.resource_monitor.stop_monitoring()\n",
    "        \n",
    "        # ìµœì¢… í†µê³„\n",
    "        if self.start_time:\n",
    "            elapsed = time.time() - self.start_time\n",
    "            logger.info(f\"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {self.processed_count}ê°œ ì²˜ë¦¬, ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ\")\n",
    "    \n",
    "    def wait_for_completion(self, timeout: Optional[float] = None):\n",
    "        \"\"\"ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°\"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        while not self.batch_queue.is_empty():\n",
    "            if timeout and (time.time() - start) > timeout:\n",
    "                logger.warning(\"ì™„ë£Œ ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ\")\n",
    "                return False\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_results(self) -> BatchResult:\n",
    "        \"\"\"ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜\"\"\"\n",
    "        stats = self.batch_queue.get_stats()\n",
    "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
    "        \n",
    "        all_items = (\n",
    "            list(self.batch_queue.completed_items.values()) +\n",
    "            list(self.batch_queue.failed_items.values())\n",
    "        )\n",
    "        \n",
    "        return BatchResult(\n",
    "            batch_id=f\"batch_{datetime.now().timestamp()}\",\n",
    "            total_items=stats['total'],\n",
    "            successful=stats['completed'],\n",
    "            failed=stats['failed'],\n",
    "            total_time=elapsed,\n",
    "            average_time=elapsed / max(1, self.processed_count),\n",
    "            items=all_items\n",
    "        )\n",
    "    \n",
    "    def get_progress(self) -> Dict:\n",
    "        \"\"\"ì§„í–‰ ìƒí™© ì¡°íšŒ\"\"\"\n",
    "        stats = self.batch_queue.get_stats()\n",
    "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
    "        \n",
    "        return {\n",
    "            **stats,\n",
    "            'elapsed_time': elapsed,\n",
    "            'items_per_second': self.processed_count / max(1, elapsed),\n",
    "            'estimated_remaining': self._estimate_remaining_time(stats)\n",
    "        }\n",
    "    \n",
    "    def _estimate_remaining_time(self, stats: Dict) -> float:\n",
    "        \"\"\"ë‚¨ì€ ì‹œê°„ ì˜ˆì¸¡\"\"\"\n",
    "        if self.processed_count == 0:\n",
    "            return -1\n",
    "        \n",
    "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
    "        rate = self.processed_count / max(1, elapsed)\n",
    "        remaining = stats['pending'] + stats['processing']\n",
    "        \n",
    "        return remaining / max(0.01, rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMonitor:\n",
    "    \"\"\"ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§\"\"\"\n",
    "    \n",
    "    def __init__(self, engine: BatchProcessingEngine):\n",
    "        self.engine = engine\n",
    "        self.is_monitoring = False\n",
    "        self.monitor_thread = None\n",
    "        \n",
    "    def start_monitoring(self, interval: float = 1.0, use_tqdm: bool = True):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ì‹œì‘\"\"\"\n",
    "        self.is_monitoring = True\n",
    "        \n",
    "        def monitor_loop():\n",
    "            if use_tqdm:\n",
    "                stats = self.engine.batch_queue.get_stats()\n",
    "                pbar = tqdm(total=stats['total'], desc=\"ë°°ì¹˜ ì²˜ë¦¬\")\n",
    "                last_completed = 0\n",
    "                \n",
    "                while self.is_monitoring:\n",
    "                    progress = self.engine.get_progress()\n",
    "                    \n",
    "                    # tqdm ì—…ë°ì´íŠ¸\n",
    "                    completed = progress['completed'] + progress['failed']\n",
    "                    pbar.update(completed - last_completed)\n",
    "                    last_completed = completed\n",
    "                    \n",
    "                    # ìƒíƒœ í‘œì‹œ\n",
    "                    pbar.set_postfix({\n",
    "                        'ëŒ€ê¸°': progress['pending'],\n",
    "                        'ì²˜ë¦¬ì¤‘': progress['processing'],\n",
    "                        'ì™„ë£Œ': progress['completed'],\n",
    "                        'ì‹¤íŒ¨': progress['failed'],\n",
    "                        'ì†ë„': f\"{progress['items_per_second']:.1f}/s\"\n",
    "                    })\n",
    "                    \n",
    "                    if self.engine.batch_queue.is_empty():\n",
    "                        break\n",
    "                    \n",
    "                    time.sleep(interval)\n",
    "                \n",
    "                pbar.close()\n",
    "            else:\n",
    "                while self.is_monitoring:\n",
    "                    progress = self.engine.get_progress()\n",
    "                    self._print_progress(progress)\n",
    "                    \n",
    "                    if self.engine.batch_queue.is_empty():\n",
    "                        break\n",
    "                    \n",
    "                    time.sleep(interval)\n",
    "        \n",
    "        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)\n",
    "        self.monitor_thread.start()\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\"\"\"\n",
    "        self.is_monitoring = False\n",
    "        if self.monitor_thread:\n",
    "            self.monitor_thread.join(timeout=2)\n",
    "    \n",
    "    def _print_progress(self, progress: Dict):\n",
    "        \"\"\"ì§„í–‰ ìƒí™© ì¶œë ¥\"\"\"\n",
    "        print(f\"\\r[ì§„í–‰ ìƒí™©] ëŒ€ê¸°: {progress['pending']} | \"\n",
    "              f\"ì²˜ë¦¬ì¤‘: {progress['processing']} | \"\n",
    "              f\"ì™„ë£Œ: {progress['completed']} | \"\n",
    "              f\"ì‹¤íŒ¨: {progress['failed']} | \"\n",
    "              f\"ì†ë„: {progress['items_per_second']:.1f}/s\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì‚¬ìš© ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def mock_yolo_inference(image: np.ndarray) -> Dict:\n",
    "    \"\"\"YOLO ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    time.sleep(np.random.uniform(0.05, 0.15))  # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜\n",
    "    \n",
    "    # ê°€ì§œ íƒì§€ ê²°ê³¼ ìƒì„±\n",
    "    num_detections = np.random.randint(0, 5)\n",
    "    detections = []\n",
    "    \n",
    "    for i in range(num_detections):\n",
    "        detections.append({\n",
    "            'class': np.random.choice(['wheat', 'corn', 'rice', 'soybean']),\n",
    "            'confidence': np.random.uniform(0.5, 0.99),\n",
    "            'bbox': [np.random.randint(0, 640) for _ in range(4)]\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'detections': detections,\n",
    "        'num_objects': num_detections,\n",
    "        'inference_time': time.time()\n",
    "    }\n",
    "\n",
    "# ì˜ˆì œ 1: ê¸°ë³¸ ë°°ì¹˜ ì²˜ë¦¬\n",
    "print(\"=== ì˜ˆì œ 1: ê¸°ë³¸ ë°°ì¹˜ ì²˜ë¦¬ ===\")\n",
    "print(\"ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„ ìƒì„±...\")\n",
    "\n",
    "engine = BatchProcessingEngine(\n",
    "    model_func=mock_yolo_inference,\n",
    "    num_workers=4,\n",
    "    batch_size=16,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± (ì‹¤ì œë¡œëŠ” ì‹¤ì œ ê²½ë¡œ ì‚¬ìš©)\n",
    "test_images = [f\"test_image_{i}.jpg\" for i in range(50)]\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¶”ê°€ (ìš°ì„ ìˆœìœ„ë³„)\n",
    "engine.add_images(test_images[:10], priority=Priority.URGENT)\n",
    "engine.add_images(test_images[10:30], priority=Priority.NORMAL)\n",
    "engine.add_images(test_images[30:], priority=Priority.LOW)\n",
    "\n",
    "print(f\"ì´ {len(test_images)}ê°œ ì´ë¯¸ì§€ ì¶”ê°€ ì™„ë£Œ\")\n",
    "print(\"ì²˜ë¦¬ ì‹œì‘...\\n\")\n",
    "\n",
    "# ì²˜ë¦¬ ì‹œì‘\n",
    "engine.start()\n",
    "\n",
    "# ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§\n",
    "monitor = ProgressMonitor(engine)\n",
    "monitor.start_monitoring(use_tqdm=True)\n",
    "\n",
    "# ì™„ë£Œ ëŒ€ê¸°\n",
    "engine.wait_for_completion(timeout=30)\n",
    "\n",
    "# ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "results = engine.get_results()\n",
    "\n",
    "# ì²˜ë¦¬ ì¤‘ì§€\n",
    "engine.stop()\n",
    "monitor.stop_monitoring()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n\\n=== ì²˜ë¦¬ ê²°ê³¼ ===\")\n",
    "print(f\"ì´ ì²˜ë¦¬: {results.total_items}ê°œ\")\n",
    "print(f\"ì„±ê³µ: {results.successful}ê°œ\")\n",
    "print(f\"ì‹¤íŒ¨: {results.failed}ê°œ\")\n",
    "print(f\"ì´ ì†Œìš”ì‹œê°„: {results.total_time:.2f}ì´ˆ\")\n",
    "print(f\"í‰ê·  ì²˜ë¦¬ì‹œê°„: {results.average_time:.3f}ì´ˆ/ì´ë¯¸ì§€\")\n",
    "print(f\"ì²˜ë¦¬ ì†ë„: {results.total_items/max(1, results.total_time):.1f} ì´ë¯¸ì§€/ì´ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ê³ ê¸‰ ê¸°ëŠ¥: ì ì‘ì  ë°°ì¹˜ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveBatchProcessor:\n",
    "    \"\"\"ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ì ì‘ì  ë°°ì¹˜ ì²˜ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, engine: BatchProcessingEngine):\n",
    "        self.engine = engine\n",
    "        self.performance_history = deque(maxlen=100)\n",
    "        self.optimal_batch_size = engine.batch_size\n",
    "        self.optimal_workers = engine.num_workers\n",
    "        \n",
    "    def auto_tune(self, test_images: List[str], duration: float = 30):\n",
    "        \"\"\"ìë™ ì„±ëŠ¥ íŠœë‹\"\"\"\n",
    "        print(\"ìë™ íŠœë‹ ì‹œì‘...\")\n",
    "        \n",
    "        test_configs = [\n",
    "            (8, 2),   # batch_size, num_workers\n",
    "            (16, 4),\n",
    "            (32, 4),\n",
    "            (32, 8),\n",
    "            (64, 8),\n",
    "        ]\n",
    "        \n",
    "        best_throughput = 0\n",
    "        best_config = (self.optimal_batch_size, self.optimal_workers)\n",
    "        \n",
    "        for batch_size, num_workers in test_configs:\n",
    "            print(f\"\\ní…ŒìŠ¤íŠ¸: ë°°ì¹˜í¬ê¸°={batch_size}, ì›Œì»¤={num_workers}\")\n",
    "            \n",
    "            # ì—”ì§„ ì¬êµ¬ì„±\n",
    "            test_engine = BatchProcessingEngine(\n",
    "                model_func=self.engine.processor.model_func,\n",
    "                num_workers=num_workers,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "            test_engine.add_images(test_images[:20])  # ìƒ˜í”Œ ì‚¬ìš©\n",
    "            test_engine.start()\n",
    "            \n",
    "            # ì¼ì • ì‹œê°„ ì‹¤í–‰\n",
    "            time.sleep(min(duration/len(test_configs), 5))\n",
    "            \n",
    "            # ì„±ëŠ¥ ì¸¡ì •\n",
    "            progress = test_engine.get_progress()\n",
    "            throughput = progress['items_per_second']\n",
    "            \n",
    "            print(f\"  ì²˜ë¦¬ëŸ‰: {throughput:.2f} ì´ë¯¸ì§€/ì´ˆ\")\n",
    "            \n",
    "            if throughput > best_throughput:\n",
    "                best_throughput = throughput\n",
    "                best_config = (batch_size, num_workers)\n",
    "            \n",
    "            test_engine.stop(wait=False)\n",
    "        \n",
    "        self.optimal_batch_size, self.optimal_workers = best_config\n",
    "        \n",
    "        print(f\"\\nìµœì  ì„¤ì •: ë°°ì¹˜í¬ê¸°={self.optimal_batch_size}, \"\n",
    "              f\"ì›Œì»¤={self.optimal_workers}, \"\n",
    "              f\"ì²˜ë¦¬ëŸ‰={best_throughput:.2f} ì´ë¯¸ì§€/ì´ˆ\")\n",
    "        \n",
    "        return best_config\n",
    "    \n",
    "    def process_with_adaptation(self, image_paths: List[str]):\n",
    "        \"\"\"ì ì‘ì  ì²˜ë¦¬\"\"\"\n",
    "        # ìµœì  ì„¤ì •ìœ¼ë¡œ ì—”ì§„ ì¬êµ¬ì„±\n",
    "        self.engine.batch_size = self.optimal_batch_size\n",
    "        self.engine.num_workers = self.optimal_workers\n",
    "        \n",
    "        # ì²˜ë¦¬ ì‹œì‘\n",
    "        self.engine.add_images(image_paths)\n",
    "        self.engine.start()\n",
    "        \n",
    "        # ë™ì  ì¡°ì •\n",
    "        def adjust_parameters():\n",
    "            while self.engine.is_running:\n",
    "                stats = self.engine.resource_monitor.get_current_stats()\n",
    "                \n",
    "                # CPU ì‚¬ìš©ë¥ ì— ë”°ë¥¸ ì¡°ì •\n",
    "                if stats['cpu_percent'] > 90:\n",
    "                    self.engine.batch_size = max(1, self.engine.batch_size // 2)\n",
    "                elif stats['cpu_percent'] < 50:\n",
    "                    self.engine.batch_size = min(64, self.engine.batch_size * 2)\n",
    "                \n",
    "                time.sleep(5)\n",
    "        \n",
    "        adjust_thread = threading.Thread(target=adjust_parameters, daemon=True)\n",
    "        adjust_thread.start()\n",
    "        \n",
    "        return self.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultExporter:\n",
    "    \"\"\"ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_to_json(result: BatchResult, output_path: str):\n",
    "        \"\"\"JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        data = result.to_dict()\n",
    "        \n",
    "        # ê° í•­ëª©ì˜ ìƒì„¸ ì •ë³´ ì¶”ê°€\n",
    "        data['items'] = []\n",
    "        for item in result.items:\n",
    "            item_data = {\n",
    "                'id': item.id,\n",
    "                'path': item.image_path,\n",
    "                'status': item.status.value,\n",
    "                'processing_time': item.processing_time,\n",
    "                'error': item.error,\n",
    "                'result': item.result\n",
    "            }\n",
    "            data['items'].append(item_data)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"ê²°ê³¼ ì €ì¥: {output_path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_to_csv(result: BatchResult, output_path: str):\n",
    "        \"\"\"CSV í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        import csv\n",
    "        \n",
    "        with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            fieldnames = ['id', 'path', 'status', 'processing_time', \n",
    "                         'num_detections', 'error']\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()\n",
    "            for item in result.items:\n",
    "                row = {\n",
    "                    'id': item.id,\n",
    "                    'path': item.image_path,\n",
    "                    'status': item.status.value,\n",
    "                    'processing_time': item.processing_time,\n",
    "                    'num_detections': len(item.result.get('detections', [])) if item.result else 0,\n",
    "                    'error': item.error or ''\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "        \n",
    "        logger.info(f\"CSV ê²°ê³¼ ì €ì¥: {output_path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_summary_report(result: BatchResult) -> str:\n",
    "        \"\"\"ìš”ì•½ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "        report = []\n",
    "        report.append(\"=\" * 50)\n",
    "        report.append(\"ë°°ì¹˜ ì²˜ë¦¬ ìš”ì•½ ë³´ê³ ì„œ\")\n",
    "        report.append(\"=\" * 50)\n",
    "        report.append(f\"ë°°ì¹˜ ID: {result.batch_id}\")\n",
    "        report.append(f\"ì²˜ë¦¬ ì‹œê°„: {result.timestamp}\")\n",
    "        report.append(f\"ì´ í•­ëª©: {result.total_items}\")\n",
    "        report.append(f\"ì„±ê³µ: {result.successful} ({result.successful/max(1, result.total_items)*100:.1f}%)\")\n",
    "        report.append(f\"ì‹¤íŒ¨: {result.failed} ({result.failed/max(1, result.total_items)*100:.1f}%)\")\n",
    "        report.append(f\"ì´ ì†Œìš”ì‹œê°„: {result.total_time:.2f}ì´ˆ\")\n",
    "        report.append(f\"í‰ê·  ì²˜ë¦¬ì‹œê°„: {result.average_time:.3f}ì´ˆ\")\n",
    "        report.append(f\"ì²˜ë¦¬ ì†ë„: {result.total_items/max(1, result.total_time):.1f} ì´ë¯¸ì§€/ì´ˆ\")\n",
    "        \n",
    "        if result.failed > 0:\n",
    "            report.append(\"\\nì‹¤íŒ¨ í•­ëª©:\")\n",
    "            for item in result.items:\n",
    "                if item.status == ProcessingStatus.FAILED:\n",
    "                    report.append(f\"  - {item.image_path}: {item.error}\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì œ\n",
    "print(\"=== ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ì˜ˆì œ ===\")\n",
    "\n",
    "# ê°€ì§œ ê²°ê³¼ ìƒì„± (ì‹¤ì œ ì²˜ë¦¬ í›„ ì‚¬ìš©)\n",
    "if 'results' in locals():\n",
    "    # ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥\n",
    "    report = ResultExporter.generate_summary_report(results)\n",
    "    print(report)\n",
    "    \n",
    "    # JSONìœ¼ë¡œ ì €ì¥ (ì‹¤ì œ ì‚¬ìš©ì‹œ)\n",
    "    # ResultExporter.export_to_json(results, \"batch_results.json\")\n",
    "    \n",
    "    # CSVë¡œ ì €ì¥ (ì‹¤ì œ ì‚¬ìš©ì‹œ)\n",
    "    # ResultExporter.export_to_csv(results, \"batch_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. í†µí•© ì‚¬ìš© ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_batch_processing_pipeline():\n",
    "    \"\"\"ì™„ì „í•œ ë°°ì¹˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜ˆì œ\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ í†µí•© ë°°ì¹˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘\\n\")\n",
    "    \n",
    "    # 1. ì—”ì§„ ìƒì„±\n",
    "    print(\"[1/5] ë°°ì¹˜ ì²˜ë¦¬ ì—”ì§„ ì´ˆê¸°í™”...\")\n",
    "    engine = BatchProcessingEngine(\n",
    "        model_func=mock_yolo_inference,\n",
    "        num_workers=None,  # ìë™ ì„¤ì •\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # 2. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¤€ë¹„\n",
    "    print(\"[2/5] ì´ë¯¸ì§€ ì¤€ë¹„...\")\n",
    "    test_images = [f\"drone_image_{i:04d}.jpg\" for i in range(100)]\n",
    "    \n",
    "    # 3. ìë™ íŠœë‹ (ì„ íƒì )\n",
    "    print(\"[3/5] ì„±ëŠ¥ ìë™ íŠœë‹...\")\n",
    "    adaptive = AdaptiveBatchProcessor(engine)\n",
    "    # adaptive.auto_tune(test_images[:20], duration=10)  # ì‹¤ì œ ì‚¬ìš©ì‹œ í™œì„±í™”\n",
    "    \n",
    "    # 4. ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "    print(\"[4/5] ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰...\")\n",
    "    \n",
    "    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì´ë¯¸ì§€ ì¶”ê°€\n",
    "    engine.add_images(test_images[:20], Priority.URGENT)   # ê¸´ê¸‰\n",
    "    engine.add_images(test_images[20:70], Priority.NORMAL) # ì¼ë°˜\n",
    "    engine.add_images(test_images[70:], Priority.LOW)      # ë‚®ìŒ\n",
    "    \n",
    "    # ì²˜ë¦¬ ì‹œì‘\n",
    "    engine.start()\n",
    "    \n",
    "    # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§\n",
    "    monitor = ProgressMonitor(engine)\n",
    "    monitor.start_monitoring(use_tqdm=True)\n",
    "    \n",
    "    # ì™„ë£Œ ëŒ€ê¸°\n",
    "    engine.wait_for_completion(timeout=60)\n",
    "    \n",
    "    # 5. ê²°ê³¼ ì²˜ë¦¬\n",
    "    print(\"\\n[5/5] ê²°ê³¼ ì²˜ë¦¬...\")\n",
    "    results = engine.get_results()\n",
    "    \n",
    "    # ì—”ì§„ ì •ë¦¬\n",
    "    engine.stop()\n",
    "    monitor.stop_monitoring()\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸ“Š ìµœì¢… ê²°ê³¼\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"âœ… ì„±ê³µ: {results.successful}/{results.total_items}\")\n",
    "    print(f\"âŒ ì‹¤íŒ¨: {results.failed}/{results.total_items}\")\n",
    "    print(f\"â±ï¸  ì´ ì‹œê°„: {results.total_time:.1f}ì´ˆ\")\n",
    "    print(f\"ğŸš€ ì²˜ë¦¬ ì†ë„: {results.total_items/max(1, results.total_time):.1f} ì´ë¯¸ì§€/ì´ˆ\")\n",
    "    print(f\"ğŸ“ˆ í‰ê·  ì‹œê°„: {results.average_time*1000:.1f}ms/ì´ë¯¸ì§€\")\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥ (ì‹¤ì œ ì‚¬ìš©ì‹œ)\n",
    "    # ResultExporter.export_to_json(results, \"results/batch_results.json\")\n",
    "    # ResultExporter.export_to_csv(results, \"results/batch_results.csv\")\n",
    "    \n",
    "    print(\"\\nâœ¨ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "final_results = complete_batch_processing_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ë‹¤ìŒ ëª¨ë“ˆ ì—°ë™ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”— ë‹¤ìŒ ëª¨ë“ˆ ì—°ë™ ì •ë³´\\n\")\n",
    "\n",
    "print(\"ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\\n\")\n",
    "\n",
    "print(\"ì´ ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ì´ ì—°ë™ë©ë‹ˆë‹¤:\\n\")\n",
    "\n",
    "print(\"1. â† Todo 2 (ì…ë ¥ ì²˜ë¦¬):\")\n",
    "print(\"   - ProcessedInput ê°ì²´ë¥¼ BatchItemìœ¼ë¡œ ë³€í™˜\")\n",
    "print(\"   - ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì„¤ì •\")\n",
    "\n",
    "print(\"\\n2. â†’ Todo 6 (ê²°ê³¼ ì €ì¥):\")\n",
    "print(\"   - BatchResult ê°ì²´ ì „ë‹¬\")\n",
    "print(\"   - ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì™€ íƒì§€ ê²°ê³¼ ì €ì¥\")\n",
    "\n",
    "print(\"\\n3. â†’ Todo 7 (ìŠ¤ì¼€ì¤„ë§):\")\n",
    "print(\"   - ì •ê¸°ì  ë°°ì¹˜ ì‘ì—… ì‹¤í–‰\")\n",
    "print(\"   - ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì •ë³´ í™œìš©\")\n",
    "\n",
    "print(\"\\n4. â†’ Todo 8 (ì‹œê°í™”):\")\n",
    "print(\"   - ì²˜ë¦¬ í†µê³„ ì‹œê°í™”\")\n",
    "print(\"   - ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëŒ€ì‹œë³´ë“œ\")\n",
    "\n",
    "print(\"\\nì£¼ìš” íŠ¹ì§•:\")\n",
    "print(\"âœ“ ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬\")\n",
    "print(\"âœ“ ë™ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬\")\n",
    "print(\"âœ“ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”\")\n",
    "print(\"âœ“ ì‹¤ì‹œê°„ ì§„í–‰ ëª¨ë‹ˆí„°ë§\")\n",
    "print(\"âœ“ ìë™ ì„±ëŠ¥ íŠœë‹\")\n",
    "\n",
    "print(\"\\në°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ê°œë°œ ì™„ë£Œ! âœ¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}