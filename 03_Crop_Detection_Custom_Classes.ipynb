{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‘ë¬¼ ê°ì²´ íƒì§€ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜ ë° ëª¨ë¸ ì„¤ì •\n",
    "\n",
    "**ëª©ì **: ë“œë¡  ì‘ë¬¼ íƒì§€ì— íŠ¹í™”ëœ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ë° ëª¨ë¸ ì„¤ì •  \n",
    "**ë‹´ë‹¹**: Claude Sonnet 4  \n",
    "**ë‚ ì§œ**: 2025-10-21\n",
    "\n",
    "## ğŸ“‹ ì‘ì—… ë‚´ìš©\n",
    "1. ì‘ë¬¼ ì¢…ë¥˜ë³„ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜\n",
    "2. ë“œë¡  ì˜ìƒ íŠ¹ì„±ì„ ê³ ë ¤í•œ ëª¨ë¸ ì„¤ì •\n",
    "3. ì‘ë¬¼ íƒì§€ ì „ìš© YOLO ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
    "4. ëª¨ë¸ ì„±ëŠ¥ ìµœì í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‘ë¬¼ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë“œë¡  ì‘ë¬¼ íƒì§€ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜\n",
    "CROP_CLASSES = {\n",
    "    # ê³¡ë¬¼ë¥˜\n",
    "    0: 'rice',           # ë²¼/ìŒ€\n",
    "    1: 'wheat',          # ë°€\n",
    "    2: 'corn',           # ì˜¥ìˆ˜ìˆ˜\n",
    "    3: 'barley',         # ë³´ë¦¬\n",
    "    \n",
    "    # ì±„ì†Œë¥˜\n",
    "    4: 'cabbage',        # ë°°ì¶”\n",
    "    5: 'lettuce',        # ìƒì¶”\n",
    "    6: 'spinach',        # ì‹œê¸ˆì¹˜\n",
    "    7: 'carrot',         # ë‹¹ê·¼\n",
    "    8: 'radish',         # ë¬´\n",
    "    9: 'onion',          # ì–‘íŒŒ\n",
    "    10: 'garlic',        # ë§ˆëŠ˜\n",
    "    11: 'pepper',        # ê³ ì¶”\n",
    "    12: 'tomato',        # í† ë§ˆí† \n",
    "    13: 'cucumber',      # ì˜¤ì´\n",
    "    14: 'eggplant',      # ê°€ì§€\n",
    "    15: 'pumpkin',       # í˜¸ë°•\n",
    "    \n",
    "    # ê³¼ì¼ë¥˜\n",
    "    16: 'apple',         # ì‚¬ê³¼\n",
    "    17: 'pear',          # ë°°\n",
    "    18: 'peach',         # ë³µìˆ­ì•„\n",
    "    19: 'grape',         # í¬ë„\n",
    "    20: 'strawberry',    # ë”¸ê¸°\n",
    "    21: 'watermelon',    # ìˆ˜ë°•\n",
    "    22: 'melon',         # ë©œë¡ \n",
    "    \n",
    "    # ê¸°íƒ€\n",
    "    23: 'soybean',       # ì½©\n",
    "    24: 'potato',        # ê°ì\n",
    "    25: 'sweet_potato',  # ê³ êµ¬ë§ˆ\n",
    "    26: 'sesame',        # ì°¸ê¹¨\n",
    "    27: 'sunflower',     # í•´ë°”ë¼ê¸°\n",
    "    \n",
    "    # ìƒíƒœ í´ë˜ìŠ¤\n",
    "    28: 'healthy_crop',  # ê±´ê°•í•œ ì‘ë¬¼\n",
    "    29: 'diseased_crop', # ë³‘ë“  ì‘ë¬¼\n",
    "    30: 'pest_damage',   # í•´ì¶© í”¼í•´\n",
    "    31: 'drought_stress',# ê°€ë­„ ìŠ¤íŠ¸ë ˆìŠ¤\n",
    "    32: 'weed',          # ì¡ì´ˆ\n",
    "    33: 'bare_soil',     # ë§¨ë•…\n",
    "    34: 'irrigation',    # ê´€ê°œì‹œì„¤\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "CLASS_CATEGORIES = {\n",
    "    'grains': [0, 1, 2, 3],                    # ê³¡ë¬¼ë¥˜\n",
    "    'vegetables': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],  # ì±„ì†Œë¥˜\n",
    "    'fruits': [16, 17, 18, 19, 20, 21, 22],    # ê³¼ì¼ë¥˜\n",
    "    'others': [23, 24, 25, 26, 27],            # ê¸°íƒ€ ì‘ë¬¼\n",
    "    'conditions': [28, 29, 30, 31, 32, 33, 34] # ìƒíƒœ/í™˜ê²½\n",
    "}\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì •ì˜ (ì‹œê°í™”ìš©)\n",
    "CLASS_COLORS = {\n",
    "    # ê³¡ë¬¼ë¥˜ - ë…¸ë€ìƒ‰ ê³„ì—´\n",
    "    **{i: (255, 255, 0) for i in range(4)},\n",
    "    # ì±„ì†Œë¥˜ - ì´ˆë¡ìƒ‰ ê³„ì—´\n",
    "    **{i: (0, 255, 0) for i in range(4, 16)},\n",
    "    # ê³¼ì¼ë¥˜ - ë¹¨ê°„ìƒ‰ ê³„ì—´\n",
    "    **{i: (255, 0, 0) for i in range(16, 23)},\n",
    "    # ê¸°íƒ€ - íŒŒë€ìƒ‰ ê³„ì—´\n",
    "    **{i: (0, 0, 255) for i in range(23, 28)},\n",
    "    # ìƒíƒœ - ë³´ë¼ìƒ‰/íšŒìƒ‰ ê³„ì—´\n",
    "    **{i: (128, 0, 128) for i in range(28, 35)}\n",
    "}\n",
    "\n",
    "print(f\"ì •ì˜ëœ ì‘ë¬¼ í´ë˜ìŠ¤ ìˆ˜: {len(CROP_CLASSES)}\")\n",
    "print(f\"ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(CLASS_CATEGORIES)}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ì •ë³´ ì¶œë ¥\n",
    "for category, class_ids in CLASS_CATEGORIES.items():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    for class_id in class_ids:\n",
    "        print(f\"  {class_id}: {CROP_CLASSES[class_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YAML ì„¤ì • íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±\n",
    "def create_crop_dataset_yaml():\n",
    "    \"\"\"ì‘ë¬¼ íƒì§€ë¥¼ ìœ„í•œ YOLO ë°ì´í„°ì…‹ YAML íŒŒì¼ ìƒì„±\"\"\"\n",
    "    \n",
    "    dataset_config = {\n",
    "        'path': './crop_dataset',  # ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ\n",
    "        'train': 'train/images',   # í•™ìŠµ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        'val': 'val/images',       # ê²€ì¦ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        'test': 'test/images',     # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        \n",
    "        'nc': len(CROP_CLASSES),   # í´ë˜ìŠ¤ ìˆ˜\n",
    "        'names': list(CROP_CLASSES.values())  # í´ë˜ìŠ¤ ì´ë¦„ë“¤\n",
    "    }\n",
    "    \n",
    "    # YAML íŒŒì¼ ì €ì¥\n",
    "    yaml_path = 'crop_dataset.yaml'\n",
    "    with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "        yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    print(f\"ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±: {yaml_path}\")\n",
    "    \n",
    "    # ì„¤ì • ë‚´ìš© ì¶œë ¥\n",
    "    print(\"\\nğŸ“‹ ë°ì´í„°ì…‹ ì„¤ì •:\")\n",
    "    print(f\"  í´ë˜ìŠ¤ ìˆ˜: {dataset_config['nc']}\")\n",
    "    print(f\"  í•™ìŠµ ê²½ë¡œ: {dataset_config['train']}\")\n",
    "    print(f\"  ê²€ì¦ ê²½ë¡œ: {dataset_config['val']}\")\n",
    "    \n",
    "    return yaml_path\n",
    "\n",
    "yaml_path = create_crop_dataset_yaml()\n",
    "\n",
    "# ìƒì„±ëœ YAML íŒŒì¼ ë‚´ìš© í™•ì¸\n",
    "with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "    print(\"\\nğŸ“„ ìƒì„±ëœ YAML íŒŒì¼ ë‚´ìš©:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë“œë¡  ì‘ë¬¼ íƒì§€ ì „ìš© í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropDetector:\n",
    "    \"\"\"ë“œë¡  ì‘ë¬¼ íƒì§€ ì „ìš© í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_path: str = 'yolo11n.pt',\n",
    "                 custom_classes: Dict = None,\n",
    "                 device: str = 'auto'):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            model_path: YOLO ëª¨ë¸ ê²½ë¡œ\n",
    "            custom_classes: ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ë”•ì…”ë„ˆë¦¬\n",
    "            device: ì‹¤í–‰ ë””ë°”ì´ìŠ¤\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.device = device if device != 'auto' else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.custom_classes = custom_classes or CROP_CLASSES\n",
    "        self.class_colors = CLASS_COLORS\n",
    "        \n",
    "        print(f\"ğŸŒ¾ CropDetector ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        print(f\"   ëª¨ë¸: {model_path}\")\n",
    "        print(f\"   ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "        print(f\"   ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ìˆ˜: {len(self.custom_classes)}\")\n",
    "    \n",
    "    def detect_crops(self, \n",
    "                    image_source,\n",
    "                    conf_threshold: float = 0.25,\n",
    "                    iou_threshold: float = 0.45,\n",
    "                    image_size: int = 640,\n",
    "                    max_detections: int = 1000) -> Tuple[List[Dict], np.ndarray]:\n",
    "        \"\"\"ì‘ë¬¼ íƒì§€ ì‹¤í–‰\n",
    "        \n",
    "        Args:\n",
    "            image_source: ì´ë¯¸ì§€ ì†ŒìŠ¤ (ê²½ë¡œ, URL, numpy array)\n",
    "            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’\n",
    "            iou_threshold: IoU ì„ê³„ê°’\n",
    "            image_size: ì¶”ë¡  ì´ë¯¸ì§€ í¬ê¸°\n",
    "            max_detections: ìµœëŒ€ íƒì§€ ê°œìˆ˜\n",
    "            \n",
    "        Returns:\n",
    "            detections: íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "            annotated_image: ì£¼ì„ì´ ì¶”ê°€ëœ ì´ë¯¸ì§€\n",
    "        \"\"\"\n",
    "        # YOLO ì¶”ë¡  ì‹¤í–‰\n",
    "        results = self.model(\n",
    "            image_source,\n",
    "            device=self.device,\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            imgsz=image_size,\n",
    "            max_det=max_detections,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        detections = []\n",
    "        annotated_image = None\n",
    "        \n",
    "        for result in results:\n",
    "            # ì£¼ì„ì´ ì¶”ê°€ëœ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "            annotated_image = result.plot()\n",
    "            \n",
    "            # íƒì§€ ê²°ê³¼ ì²˜ë¦¬\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ\n",
    "                    cls_id = int(box.cls)\n",
    "                    confidence = float(box.conf)\n",
    "                    bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "                    \n",
    "                    # COCO í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸°\n",
    "                    coco_class_name = self.model.names[cls_id]\n",
    "                    \n",
    "                    # ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ë¡œ ë§¤í•‘ (ì¶”í›„ í•™ìŠµëœ ëª¨ë¸ì—ì„œ ì‚¬ìš©)\n",
    "                    custom_class_name = self.custom_classes.get(cls_id, f\"unknown_{cls_id}\")\n",
    "                    \n",
    "                    # íƒì§€ ì •ë³´ ì €ì¥\n",
    "                    detection = {\n",
    "                        'class_id': cls_id,\n",
    "                        'coco_class_name': coco_class_name,\n",
    "                        'custom_class_name': custom_class_name,\n",
    "                        'confidence': confidence,\n",
    "                        'bbox': bbox.tolist(),\n",
    "                        'bbox_center': [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2],\n",
    "                        'bbox_area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "                    }\n",
    "                    \n",
    "                    detections.append(detection)\n",
    "        \n",
    "        return detections, annotated_image\n",
    "    \n",
    "    def filter_crop_detections(self, detections: List[Dict], \n",
    "                              crop_keywords: List[str] = None) -> List[Dict]:\n",
    "        \"\"\"ì‘ë¬¼ ê´€ë ¨ íƒì§€ë§Œ í•„í„°ë§\n",
    "        \n",
    "        Args:\n",
    "            detections: ì „ì²´ íƒì§€ ê²°ê³¼\n",
    "            crop_keywords: ì‘ë¬¼ ê´€ë ¨ í‚¤ì›Œë“œ\n",
    "            \n",
    "        Returns:\n",
    "            filtered_detections: í•„í„°ë§ëœ íƒì§€ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        if crop_keywords is None:\n",
    "            crop_keywords = ['plant', 'tree', 'fruit', 'vegetable', 'flower', \n",
    "                           'crop', 'leaf', 'grass', 'agriculture']\n",
    "        \n",
    "        filtered = []\n",
    "        for detection in detections:\n",
    "            class_name = detection['coco_class_name'].lower()\n",
    "            \n",
    "            # í‚¤ì›Œë“œ ë§¤ì¹­\n",
    "            is_crop = any(keyword in class_name for keyword in crop_keywords)\n",
    "            \n",
    "            if is_crop:\n",
    "                filtered.append(detection)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def analyze_crop_distribution(self, detections: List[Dict]) -> Dict:\n",
    "        \"\"\"ì‘ë¬¼ ë¶„í¬ ë¶„ì„\n",
    "        \n",
    "        Args:\n",
    "            detections: íƒì§€ ê²°ê³¼\n",
    "            \n",
    "        Returns:\n",
    "            analysis: ë¶„ì„ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        if not detections:\n",
    "            return {'total_count': 0, 'class_distribution': {}, 'avg_confidence': 0}\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ë¶„í¬\n",
    "        class_counts = {}\n",
    "        confidences = []\n",
    "        total_area = 0\n",
    "        \n",
    "        for detection in detections:\n",
    "            class_name = detection['coco_class_name']\n",
    "            confidence = detection['confidence']\n",
    "            area = detection['bbox_area']\n",
    "            \n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "            confidences.append(confidence)\n",
    "            total_area += area\n",
    "        \n",
    "        analysis = {\n",
    "            'total_count': len(detections),\n",
    "            'class_distribution': class_counts,\n",
    "            'avg_confidence': np.mean(confidences),\n",
    "            'min_confidence': np.min(confidences),\n",
    "            'max_confidence': np.max(confidences),\n",
    "            'total_area': total_area,\n",
    "            'avg_area': total_area / len(detections) if detections else 0\n",
    "        }\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def save_detection_results(self, \n",
    "                              detections: List[Dict], \n",
    "                              analysis: Dict,\n",
    "                              output_path: str = None) -> str:\n",
    "        \"\"\"íƒì§€ ê²°ê³¼ ì €ì¥\n",
    "        \n",
    "        Args:\n",
    "            detections: íƒì§€ ê²°ê³¼\n",
    "            analysis: ë¶„ì„ ê²°ê³¼\n",
    "            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "            \n",
    "        Returns:\n",
    "            saved_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ\n",
    "        \"\"\"\n",
    "        if output_path is None:\n",
    "            timestamp = int(time.time())\n",
    "            output_path = f'crop_detection_results_{timestamp}.json'\n",
    "        \n",
    "        results = {\n",
    "            'timestamp': time.time(),\n",
    "            'model_info': {\n",
    "                'device': self.device,\n",
    "                'custom_classes_count': len(self.custom_classes)\n",
    "            },\n",
    "            'detections': detections,\n",
    "            'analysis': analysis\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"ê²°ê³¼ ì €ì¥: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "# CropDetector ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "crop_detector = CropDetector()\n",
    "print(\"\\nâœ… CropDetector ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë¬¼ íƒì§€ í…ŒìŠ¤íŠ¸\n",
    "def test_crop_detection():\n",
    "    \"\"\"ì‘ë¬¼ íƒì§€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ§ª ì‘ë¬¼ íƒì§€ í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ URLë“¤ (ì‘ë¬¼ ê´€ë ¨)\n",
    "    test_images = [\n",
    "        'https://images.unsplash.com/photo-1574323347407-f5e1ad6d020b',  # ë†ì¥\n",
    "        'https://images.unsplash.com/photo-1500595046743-cd271d694d30',  # í† ë§ˆí† \n",
    "    ]\n",
    "    \n",
    "    for i, image_url in enumerate(test_images):\n",
    "        try:\n",
    "            print(f\"í…ŒìŠ¤íŠ¸ {i+1}: {image_url}\")\n",
    "            \n",
    "            # ì‘ë¬¼ íƒì§€ ì‹¤í–‰\n",
    "            detections, annotated_image = crop_detector.detect_crops(\n",
    "                image_url,\n",
    "                conf_threshold=0.3,\n",
    "                image_size=640\n",
    "            )\n",
    "            \n",
    "            # ì‘ë¬¼ ê´€ë ¨ íƒì§€ë§Œ í•„í„°ë§\n",
    "            crop_detections = crop_detector.filter_crop_detections(detections)\n",
    "            \n",
    "            # ë¶„ì„ ìˆ˜í–‰\n",
    "            analysis = crop_detector.analyze_crop_distribution(crop_detections)\n",
    "            \n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            print(f\"  ì „ì²´ íƒì§€ ìˆ˜: {len(detections)}\")\n",
    "            print(f\"  ì‘ë¬¼ íƒì§€ ìˆ˜: {len(crop_detections)}\")\n",
    "            print(f\"  í‰ê·  ì‹ ë¢°ë„: {analysis['avg_confidence']:.3f}\")\n",
    "            \n",
    "            if crop_detections:\n",
    "                print(\"  íƒì§€ëœ ì‘ë¬¼:\")\n",
    "                for detection in crop_detections[:5]:  # ìƒìœ„ 5ê°œë§Œ\n",
    "                    print(f\"    - {detection['coco_class_name']}: {detection['confidence']:.3f}\")\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            result_path = crop_detector.save_detection_results(\n",
    "                crop_detections, analysis, f'test_result_{i+1}.json'\n",
    "            )\n",
    "            \n",
    "            print(f\"  ì €ì¥ ì™„ë£Œ: {result_path}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "            # ì˜¤í”„ë¼ì¸ í…ŒìŠ¤íŠ¸\n",
    "            print(\"  ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸...\")\n",
    "            dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "            detections, _ = crop_detector.detect_crops(dummy_image)\n",
    "            print(f\"  ë”ë¯¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(detections)}ê°œ íƒì§€\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_crop_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë“œë¡  íŠ¹í™” ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroneSpecificSettings:\n",
    "    \"\"\"ë“œë¡  ì˜ìƒ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì„¤ì • í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    # ë“œë¡  ê³ ë„ë³„ ìµœì  ì„¤ì •\n",
    "    ALTITUDE_SETTINGS = {\n",
    "        'low': {          # ì €ê³ ë„ (10-30m)\n",
    "            'image_size': 1280,\n",
    "            'conf_threshold': 0.4,\n",
    "            'iou_threshold': 0.5,\n",
    "            'max_detections': 500,\n",
    "            'description': 'ê°œë³„ ì‘ë¬¼ ì‹ë³„ ê°€ëŠ¥'\n",
    "        },\n",
    "        'medium': {       # ì¤‘ê³ ë„ (30-100m)\n",
    "            'image_size': 640,\n",
    "            'conf_threshold': 0.3,\n",
    "            'iou_threshold': 0.45,\n",
    "            'max_detections': 300,\n",
    "            'description': 'ì‘ë¬¼ ê·¸ë£¹ ë° íŒ¨í„´ ë¶„ì„'\n",
    "        },\n",
    "        'high': {         # ê³ ê³ ë„ (100m+)\n",
    "            'image_size': 320,\n",
    "            'conf_threshold': 0.25,\n",
    "            'iou_threshold': 0.4,\n",
    "            'max_detections': 100,\n",
    "            'description': 'ì „ì²´ ë†ì¥ ëª¨ë‹ˆí„°ë§'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ê³„ì ˆë³„ ì„¤ì •\n",
    "    SEASONAL_SETTINGS = {\n",
    "        'spring': {\n",
    "            'focus_classes': ['seedling', 'young_plant', 'irrigation'],\n",
    "            'conf_adjustment': 0.05,  # ì‹ ë¢°ë„ ì¡°ì •\n",
    "            'description': 'ìƒˆì‹¹ ë° ì–´ë¦° ì‹ë¬¼ íƒì§€'\n",
    "        },\n",
    "        'summer': {\n",
    "            'focus_classes': ['mature_plant', 'fruit', 'pest_damage'],\n",
    "            'conf_adjustment': 0.0,\n",
    "            'description': 'ì„±ì¥í•œ ì‹ë¬¼ ë° ë³‘í•´ì¶© íƒì§€'\n",
    "        },\n",
    "        'autumn': {\n",
    "            'focus_classes': ['ripe_fruit', 'harvest_ready', 'dry_plant'],\n",
    "            'conf_adjustment': -0.05,\n",
    "            'description': 'ìˆ˜í™• ì‹œê¸° íŒë‹¨'\n",
    "        },\n",
    "        'winter': {\n",
    "            'focus_classes': ['bare_soil', 'greenhouse', 'irrigation'],\n",
    "            'conf_adjustment': 0.1,\n",
    "            'description': 'í† ì–‘ ìƒíƒœ ë° ì‹œì„¤ ëª¨ë‹ˆí„°ë§'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ë‚ ì”¨ë³„ ì„¤ì •\n",
    "    WEATHER_SETTINGS = {\n",
    "        'sunny': {\n",
    "            'brightness_adjust': 0,\n",
    "            'contrast_adjust': 0,\n",
    "            'conf_threshold_adj': 0\n",
    "        },\n",
    "        'cloudy': {\n",
    "            'brightness_adjust': 10,\n",
    "            'contrast_adjust': 5,\n",
    "            'conf_threshold_adj': -0.05\n",
    "        },\n",
    "        'overcast': {\n",
    "            'brightness_adjust': 20,\n",
    "            'contrast_adjust': 10,\n",
    "            'conf_threshold_adj': -0.1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_optimal_settings(altitude: str = 'medium', \n",
    "                           season: str = 'summer', \n",
    "                           weather: str = 'sunny') -> Dict:\n",
    "        \"\"\"ìµœì  ì„¤ì • ê°€ì ¸ì˜¤ê¸°\n",
    "        \n",
    "        Args:\n",
    "            altitude: ë“œë¡  ê³ ë„ ('low', 'medium', 'high')\n",
    "            season: ê³„ì ˆ ('spring', 'summer', 'autumn', 'winter')\n",
    "            weather: ë‚ ì”¨ ('sunny', 'cloudy', 'overcast')\n",
    "            \n",
    "        Returns:\n",
    "            settings: ìµœì í™”ëœ ì„¤ì •\n",
    "        \"\"\"\n",
    "        # ê¸°ë³¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°\n",
    "        base_settings = DroneSpecificSettings.ALTITUDE_SETTINGS.get(altitude, \n",
    "                        DroneSpecificSettings.ALTITUDE_SETTINGS['medium'])\n",
    "        \n",
    "        seasonal = DroneSpecificSettings.SEASONAL_SETTINGS.get(season, \n",
    "                   DroneSpecificSettings.SEASONAL_SETTINGS['summer'])\n",
    "        \n",
    "        weather_adj = DroneSpecificSettings.WEATHER_SETTINGS.get(weather, \n",
    "                      DroneSpecificSettings.WEATHER_SETTINGS['sunny'])\n",
    "        \n",
    "        # ì„¤ì • ì¡°í•©\n",
    "        optimal_settings = base_settings.copy()\n",
    "        optimal_settings['conf_threshold'] += seasonal['conf_adjustment']\n",
    "        optimal_settings['conf_threshold'] += weather_adj['conf_threshold_adj']\n",
    "        \n",
    "        # ì‹ ë¢°ë„ ë²”ìœ„ ì œí•œ\n",
    "        optimal_settings['conf_threshold'] = max(0.1, min(0.9, optimal_settings['conf_threshold']))\n",
    "        \n",
    "        # ì¶”ê°€ ì •ë³´\n",
    "        optimal_settings['focus_classes'] = seasonal['focus_classes']\n",
    "        optimal_settings['weather_adjustments'] = weather_adj\n",
    "        optimal_settings['context'] = {\n",
    "            'altitude': altitude,\n",
    "            'season': season,\n",
    "            'weather': weather\n",
    "        }\n",
    "        \n",
    "        return optimal_settings\n",
    "\n",
    "# ë“œë¡  íŠ¹í™” ì„¤ì • í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸš ë“œë¡  íŠ¹í™” ì„¤ì • í…ŒìŠ¤íŠ¸\\n\")\n",
    "\n",
    "# ë‹¤ì–‘í•œ ì¡°ê±´ë³„ ìµœì  ì„¤ì • í™•ì¸\n",
    "test_conditions = [\n",
    "    ('low', 'spring', 'sunny'),\n",
    "    ('medium', 'summer', 'cloudy'),\n",
    "    ('high', 'autumn', 'overcast')\n",
    "]\n",
    "\n",
    "for altitude, season, weather in test_conditions:\n",
    "    settings = DroneSpecificSettings.get_optimal_settings(altitude, season, weather)\n",
    "    print(f\"ì¡°ê±´: {altitude} ê³ ë„, {season}, {weather}\")\n",
    "    print(f\"  ì´ë¯¸ì§€ í¬ê¸°: {settings['image_size']}\")\n",
    "    print(f\"  ì‹ ë¢°ë„ ì„ê³„ê°’: {settings['conf_threshold']:.3f}\")\n",
    "    print(f\"  IoU ì„ê³„ê°’: {settings['iou_threshold']}\")\n",
    "    print(f\"  ìµœëŒ€ íƒì§€ìˆ˜: {settings['max_detections']}\")\n",
    "    print(f\"  ì¤‘ì  í´ë˜ìŠ¤: {settings['focus_classes']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ íŒŒì¸íŠœë‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropModelTrainer:\n",
    "    \"\"\"ì‘ë¬¼ íƒì§€ ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, base_model: str = 'yolo11n.pt'):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            base_model: ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ\n",
    "        \"\"\"\n",
    "        self.base_model = base_model\n",
    "        self.model = YOLO(base_model)\n",
    "        \n",
    "        print(f\"ğŸ“š CropModelTrainer ì´ˆê¸°í™”\")\n",
    "        print(f\"   ê¸°ë³¸ ëª¨ë¸: {base_model}\")\n",
    "    \n",
    "    def prepare_training_config(self, \n",
    "                               data_yaml: str,\n",
    "                               epochs: int = 100,\n",
    "                               imgsz: int = 640,\n",
    "                               batch: int = 16) -> Dict:\n",
    "        \"\"\"í•™ìŠµ ì„¤ì • ì¤€ë¹„\n",
    "        \n",
    "        Args:\n",
    "            data_yaml: ë°ì´í„°ì…‹ YAML íŒŒì¼ ê²½ë¡œ\n",
    "            epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜\n",
    "            imgsz: ì´ë¯¸ì§€ í¬ê¸°\n",
    "            batch: ë°°ì¹˜ í¬ê¸°\n",
    "            \n",
    "        Returns:\n",
    "            config: í•™ìŠµ ì„¤ì •\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'data': data_yaml,\n",
    "            'epochs': epochs,\n",
    "            'imgsz': imgsz,\n",
    "            'batch': batch,\n",
    "            'optimizer': 'AdamW',\n",
    "            'lr0': 0.01,\n",
    "            'lrf': 0.01,\n",
    "            'momentum': 0.937,\n",
    "            'weight_decay': 0.0005,\n",
    "            'warmup_epochs': 3,\n",
    "            'warmup_momentum': 0.8,\n",
    "            'warmup_bias_lr': 0.1,\n",
    "            'box': 7.5,\n",
    "            'cls': 0.5,\n",
    "            'dfl': 1.5,\n",
    "            'pose': 12.0,\n",
    "            'kobj': 1.0,\n",
    "            'label_smoothing': 0.0,\n",
    "            'nbs': 64,\n",
    "            'hsv_h': 0.015,\n",
    "            'hsv_s': 0.7,\n",
    "            'hsv_v': 0.4,\n",
    "            'degrees': 0.0,\n",
    "            'translate': 0.1,\n",
    "            'scale': 0.5,\n",
    "            'shear': 0.0,\n",
    "            'perspective': 0.0,\n",
    "            'flipud': 0.0,\n",
    "            'fliplr': 0.5,\n",
    "            'mosaic': 1.0,\n",
    "            'mixup': 0.0,\n",
    "            'copy_paste': 0.0\n",
    "        }\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def train_model(self, config: Dict, project_name: str = 'crop_detection'):\n",
    "        \"\"\"ëª¨ë¸ í•™ìŠµ (ì‹¤ì œë¡œëŠ” ì‹¤í–‰í•˜ì§€ ì•Šê³  ì„¤ì •ë§Œ í‘œì‹œ)\n",
    "        \n",
    "        Args:\n",
    "            config: í•™ìŠµ ì„¤ì •\n",
    "            project_name: í”„ë¡œì íŠ¸ ì´ë¦„\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ¯ ëª¨ë¸ í•™ìŠµ ì„¤ì •\")\n",
    "        print(f\"   í”„ë¡œì íŠ¸: {project_name}\")\n",
    "        print(f\"   ë°ì´í„°ì…‹: {config['data']}\")\n",
    "        print(f\"   ì—í¬í¬: {config['epochs']}\")\n",
    "        print(f\"   ë°°ì¹˜ í¬ê¸°: {config['batch']}\")\n",
    "        print(f\"   ì´ë¯¸ì§€ í¬ê¸°: {config['imgsz']}\")\n",
    "        \n",
    "        print(\"\\nâš ï¸  ì‹¤ì œ í•™ìŠµì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:\")\n",
    "        print(\"   1. ë¼ë²¨ë§ëœ ì‘ë¬¼ ì´ë¯¸ì§€ ë°ì´í„°ì…‹\")\n",
    "        print(\"   2. ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ (8GB+)\")\n",
    "        print(\"   3. í•™ìŠµ ì‹œê°„ (ìˆ˜ ì‹œê°„~ìˆ˜ì¼)\")\n",
    "        \n",
    "        # ì‹¤ì œ í•™ìŠµ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬)\n",
    "        \"\"\"\n",
    "        results = self.model.train(\n",
    "            data=config['data'],\n",
    "            epochs=config['epochs'],\n",
    "            imgsz=config['imgsz'],\n",
    "            batch=config['batch'],\n",
    "            project=project_name,\n",
    "            **{k: v for k, v in config.items() if k not in ['data', 'epochs', 'imgsz', 'batch']}\n",
    "        )\n",
    "        return results\n",
    "        \"\"\"\n",
    "    \n",
    "    def validate_model(self, model_path: str, data_yaml: str):\n",
    "        \"\"\"ëª¨ë¸ ê²€ì¦ (ì‹¤ì œë¡œëŠ” ì‹¤í–‰í•˜ì§€ ì•Šê³  ì„¤ì •ë§Œ í‘œì‹œ)\n",
    "        \n",
    "        Args:\n",
    "            model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ\n",
    "            data_yaml: ê²€ì¦ ë°ì´í„°ì…‹ YAML\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ” ëª¨ë¸ ê²€ì¦ ì„¤ì •\")\n",
    "        print(f\"   ëª¨ë¸: {model_path}\")\n",
    "        print(f\"   ë°ì´í„°ì…‹: {data_yaml}\")\n",
    "        \n",
    "        # ì‹¤ì œ ê²€ì¦ ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬)\n",
    "        \"\"\"\n",
    "        model = YOLO(model_path)\n",
    "        results = model.val(data=data_yaml)\n",
    "        return results\n",
    "        \"\"\"\n",
    "\n",
    "# ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ë° ì„¤ì • í™•ì¸\n",
    "trainer = CropModelTrainer('yolo11n.pt')\n",
    "\n",
    "# í•™ìŠµ ì„¤ì • ìƒì„±\n",
    "training_config = trainer.prepare_training_config(\n",
    "    data_yaml='crop_dataset.yaml',\n",
    "    epochs=100,\n",
    "    batch=16\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“‹ ìƒì„±ëœ í•™ìŠµ ì„¤ì •:\")\n",
    "for key, value in list(training_config.items())[:10]:  # ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "    print(f\"   {key}: {value}\")\n",
    "print(\"   ...\")\n",
    "\n",
    "# í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜\n",
    "trainer.train_model(training_config, 'drone_crop_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ìµœì¢… ê²€ì¦ ë° ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ì„±ëŠ¥ ê²€ì¦\n",
    "def final_validation():\n",
    "    \"\"\"Todo 3 ì™„ë£Œë¥¼ ìœ„í•œ ìµœì¢… ê²€ì¦\"\"\"\n",
    "    print(\"ğŸ¯ Todo 3 ìµœì¢… ê²€ì¦\\n\")\n",
    "    \n",
    "    # 1. ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜ í™•ì¸\n",
    "    print(\"âœ… ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜:\")\n",
    "    print(f\"   ì´ {len(CROP_CLASSES)}ê°œ ì‘ë¬¼ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n",
    "    print(f\"   {len(CLASS_CATEGORIES)}ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜\")\n",
    "    \n",
    "    # 2. YAML ì„¤ì • íŒŒì¼ í™•ì¸\n",
    "    print(\"\\nâœ… YAML ì„¤ì • íŒŒì¼:\")\n",
    "    print(f\"   ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±: crop_dataset.yaml\")\n",
    "    \n",
    "    # 3. CropDetector í´ë˜ìŠ¤ í™•ì¸\n",
    "    print(\"\\nâœ… CropDetector í´ë˜ìŠ¤:\")\n",
    "    print(f\"   ë“œë¡  ì‘ë¬¼ íƒì§€ ì „ìš© í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ\")\n",
    "    print(f\"   ë””ë°”ì´ìŠ¤: {crop_detector.device}\")\n",
    "    \n",
    "    # 4. ë“œë¡  íŠ¹í™” ì„¤ì • í™•ì¸\n",
    "    print(\"\\nâœ… ë“œë¡  íŠ¹í™” ì„¤ì •:\")\n",
    "    print(f\"   ê³ ë„ë³„ ì„¤ì •: {len(DroneSpecificSettings.ALTITUDE_SETTINGS)}ê°€ì§€\")\n",
    "    print(f\"   ê³„ì ˆë³„ ì„¤ì •: {len(DroneSpecificSettings.SEASONAL_SETTINGS)}ê°€ì§€\")\n",
    "    print(f\"   ë‚ ì”¨ë³„ ì„¤ì •: {len(DroneSpecificSettings.WEATHER_SETTINGS)}ê°€ì§€\")\n",
    "    \n",
    "    # 5. ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ í™•ì¸\n",
    "    print(\"\\nâœ… ëª¨ë¸ í•™ìŠµ ì¤€ë¹„:\")\n",
    "    print(f\"   CropModelTrainer í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ\")\n",
    "    print(f\"   í•™ìŠµ ì„¤ì • í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    # 6. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸ”¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\n",
    "    test_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "    detections, _ = crop_detector.detect_crops(test_image)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    print(f\"   ì²˜ë¦¬ ì‹œê°„: {processing_time:.4f}ì´ˆ\")\n",
    "    print(f\"   FPS: {1/processing_time:.2f}\")\n",
    "    print(f\"   íƒì§€ ìˆ˜: {len(detections)}\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ Todo 3 ì™„ë£Œ!\")\n",
    "    print(\"\\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "    print(\"   - Todo 4: ì‹¤ì‹œê°„ ì˜ìƒ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬í˜„\")\n",
    "    print(\"   - Todo 9: ì„±ëŠ¥ ìµœì í™” ë° GPU ê°€ì† ì„¤ì •\")\n",
    "    print(\"   - Todo 10: ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„\")\n",
    "\n",
    "final_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Todo 3 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "\n",
    "1. **ì‘ë¬¼ í´ë˜ìŠ¤ ì •ì˜**\n",
    "   - [x] 35ê°œ ì‘ë¬¼ ë° ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜\n",
    "   - [x] 5ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜ (ê³¡ë¬¼, ì±„ì†Œ, ê³¼ì¼, ê¸°íƒ€, ìƒíƒœ)\n",
    "   - [x] í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì½”ë“œ ì •ì˜\n",
    "\n",
    "2. **YAML ì„¤ì • íŒŒì¼**\n",
    "   - [x] YOLO í•™ìŠµìš© ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±\n",
    "   - [x] í´ë˜ìŠ¤ ì •ë³´ ë° ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "3. **CropDetector í´ë˜ìŠ¤**\n",
    "   - [x] ë“œë¡  ì‘ë¬¼ íƒì§€ ì „ìš© í´ë˜ìŠ¤ êµ¬í˜„\n",
    "   - [x] ì‘ë¬¼ í•„í„°ë§ ê¸°ëŠ¥\n",
    "   - [x] ë¶„í¬ ë¶„ì„ ê¸°ëŠ¥\n",
    "   - [x] ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥\n",
    "\n",
    "4. **ë“œë¡  íŠ¹í™” ì„¤ì •**\n",
    "   - [x] ê³ ë„ë³„ ìµœì  ì„¤ì • (ì €/ì¤‘/ê³ ê³ ë„)\n",
    "   - [x] ê³„ì ˆë³„ ì„¤ì • (ë´„/ì—¬ë¦„/ê°€ì„/ê²¨ìš¸)\n",
    "   - [x] ë‚ ì”¨ë³„ ì„¤ì • (ë§‘ìŒ/íë¦¼/íë¦°ë‚ )\n",
    "\n",
    "5. **ëª¨ë¸ í•™ìŠµ ì¤€ë¹„**\n",
    "   - [x] CropModelTrainer í´ë˜ìŠ¤ êµ¬í˜„\n",
    "   - [x] í•™ìŠµ ì„¤ì • í…œí”Œë¦¿ ìƒì„±\n",
    "   - [x] ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì„¤ê³„\n",
    "\n",
    "### ğŸš€ ì£¼ìš” ì„±ê³¼\n",
    "- ë“œë¡  ì‘ë¬¼ íƒì§€ì— íŠ¹í™”ëœ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì²´ê³„ êµ¬ì¶•\n",
    "- ë‹¤ì–‘í•œ í™˜ê²½ ì¡°ê±´ì„ ê³ ë ¤í•œ ì„¤ì • ì‹œìŠ¤í…œ\n",
    "- ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ íƒì§€ ë° ë¶„ì„ ë„êµ¬ êµ¬í˜„\n",
    "- ëª¨ë¸ íŒŒì¸íŠœë‹ì„ ìœ„í•œ ê¸°ë°˜ êµ¬ì¡° ì™„ì„±\n",
    "\n",
    "### ğŸ“ ìƒì„±ëœ íŒŒì¼\n",
    "- `crop_dataset.yaml` - YOLO í•™ìŠµìš© ì„¤ì • íŒŒì¼\n",
    "- í…ŒìŠ¤íŠ¸ ê²°ê³¼ JSON íŒŒì¼ë“¤\n",
    "- ì´ Jupyter ë…¸íŠ¸ë¶ íŒŒì¼\n",
    "\n",
    "ì´ì œ ì‹¤ì‹œê°„ ì˜ìƒ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ (Todo 4)ìœ¼ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}