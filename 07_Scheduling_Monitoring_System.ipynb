{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. ì§€ì†ì  ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ\n",
    "\n",
    "**ë‹´ë‹¹**: Claude Opus  \n",
    "**ì‘ì„±ì¼**: 2025-10-24  \n",
    "**ëª©ì **: ìë™í™”ëœ ì£¼ê¸°ì  ë“œë¡  ì‘ë¬¼ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- í¬ë¡  ê¸°ë°˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§\n",
    "- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ\n",
    "- ì‘ì—… í ê´€ë¦¬\n",
    "- ì•Œë¦¼ ë° ê²½ê³  ì‹œìŠ¤í…œ\n",
    "- ì‘ì—… ì‹¤í–‰ ì´ë ¥ ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "import sys\n",
    "!{sys.executable} -m pip install schedule apscheduler watchdog pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Callable, Any, Union\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import Enum\n",
    "import schedule\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from apscheduler.triggers.cron import CronTrigger\n",
    "from apscheduler.triggers.interval import IntervalTrigger\n",
    "from apscheduler.triggers.date import DateTrigger\n",
    "from apscheduler.executors.pool import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import sqlite3\n",
    "import pickle\n",
    "from collections import defaultdict, deque\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import uuid\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ì‘ì—… ì •ì˜ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobStatus(Enum):\n",
    "    \"\"\"ì‘ì—… ìƒíƒœ\"\"\"\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    CANCELLED = \"cancelled\"\n",
    "    SCHEDULED = \"scheduled\"\n",
    "\n",
    "class JobType(Enum):\n",
    "    \"\"\"ì‘ì—… ìœ í˜•\"\"\"\n",
    "    IMAGE_PROCESSING = \"image_processing\"\n",
    "    VIDEO_ANALYSIS = \"video_analysis\"\n",
    "    BATCH_DETECTION = \"batch_detection\"\n",
    "    DATABASE_BACKUP = \"database_backup\"\n",
    "    REPORT_GENERATION = \"report_generation\"\n",
    "    FOLDER_MONITORING = \"folder_monitoring\"\n",
    "    DATA_CLEANUP = \"data_cleanup\"\n",
    "\n",
    "@dataclass\n",
    "class Job:\n",
    "    \"\"\"ì‘ì—… ì •ì˜\"\"\"\n",
    "    id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    name: str = \"\"\n",
    "    job_type: JobType = JobType.IMAGE_PROCESSING\n",
    "    function: Optional[Callable] = None\n",
    "    args: tuple = field(default_factory=tuple)\n",
    "    kwargs: dict = field(default_factory=dict)\n",
    "    schedule_expression: Optional[str] = None  # í¬ë¡  í‘œí˜„ì‹\n",
    "    interval_seconds: Optional[int] = None     # ê°„ê²© (ì´ˆ)\n",
    "    run_at: Optional[datetime] = None         # íŠ¹ì • ì‹œê°„\n",
    "    max_retries: int = 3\n",
    "    retry_delay: int = 60  # ì´ˆ\n",
    "    timeout: Optional[int] = None  # ì´ˆ\n",
    "    priority: int = 5  # 1-10 (1ì´ ê°€ì¥ ë†’ìŒ)\n",
    "    enabled: bool = True\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.priority < other.priority\n",
    "\n",
    "@dataclass\n",
    "class JobResult:\n",
    "    \"\"\"ì‘ì—… ì‹¤í–‰ ê²°ê³¼\"\"\"\n",
    "    job_id: str\n",
    "    job_name: str\n",
    "    status: JobStatus\n",
    "    started_at: datetime\n",
    "    completed_at: Optional[datetime] = None\n",
    "    duration: Optional[float] = None\n",
    "    result: Any = None\n",
    "    error: Optional[str] = None\n",
    "    retry_count: int = 0\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'job_id': self.job_id,\n",
    "            'job_name': self.job_name,\n",
    "            'status': self.status.value,\n",
    "            'started_at': self.started_at.isoformat(),\n",
    "            'completed_at': self.completed_at.isoformat() if self.completed_at else None,\n",
    "            'duration': self.duration,\n",
    "            'error': self.error,\n",
    "            'retry_count': self.retry_count\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‘ì—… ì‹¤í–‰ ì´ë ¥ ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobHistoryManager:\n",
    "    \"\"\"ì‘ì—… ì‹¤í–‰ ì´ë ¥ ê´€ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"job_history.db\"):\n",
    "        self.db_path = db_path\n",
    "        self._init_database()\n",
    "        \n",
    "    def _init_database(self):\n",
    "        \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS job_history (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                job_id TEXT NOT NULL,\n",
    "                job_name TEXT NOT NULL,\n",
    "                job_type TEXT,\n",
    "                status TEXT NOT NULL,\n",
    "                started_at TIMESTAMP NOT NULL,\n",
    "                completed_at TIMESTAMP,\n",
    "                duration REAL,\n",
    "                error TEXT,\n",
    "                retry_count INTEGER DEFAULT 0,\n",
    "                metadata TEXT\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE INDEX IF NOT EXISTS idx_job_id ON job_history(job_id);\n",
    "        ''')\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE INDEX IF NOT EXISTS idx_started_at ON job_history(started_at);\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "    def save_result(self, result: JobResult, job_type: Optional[JobType] = None):\n",
    "        \"\"\"ì‘ì—… ê²°ê³¼ ì €ì¥\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            INSERT INTO job_history \n",
    "            (job_id, job_name, job_type, status, started_at, completed_at, duration, error, retry_count)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            result.job_id,\n",
    "            result.job_name,\n",
    "            job_type.value if job_type else None,\n",
    "            result.status.value,\n",
    "            result.started_at,\n",
    "            result.completed_at,\n",
    "            result.duration,\n",
    "            result.error,\n",
    "            result.retry_count\n",
    "        ))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "    def get_history(self, \n",
    "                   job_id: Optional[str] = None,\n",
    "                   status: Optional[JobStatus] = None,\n",
    "                   date_from: Optional[datetime] = None,\n",
    "                   date_to: Optional[datetime] = None,\n",
    "                   limit: int = 100) -> List[Dict]:\n",
    "        \"\"\"ì‘ì—… ì´ë ¥ ì¡°íšŒ\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = \"SELECT * FROM job_history WHERE 1=1\"\n",
    "        params = []\n",
    "        \n",
    "        if job_id:\n",
    "            query += \" AND job_id = ?\"\n",
    "            params.append(job_id)\n",
    "            \n",
    "        if status:\n",
    "            query += \" AND status = ?\"\n",
    "            params.append(status.value)\n",
    "            \n",
    "        if date_from:\n",
    "            query += \" AND started_at >= ?\"\n",
    "            params.append(date_from)\n",
    "            \n",
    "        if date_to:\n",
    "            query += \" AND started_at <= ?\"\n",
    "            params.append(date_to)\n",
    "            \n",
    "        query += \" ORDER BY started_at DESC LIMIT ?\"\n",
    "        params.append(limit)\n",
    "        \n",
    "        cursor.execute(query, params)\n",
    "        results = [dict(row) for row in cursor.fetchall()]\n",
    "        \n",
    "        conn.close()\n",
    "        return results\n",
    "    \n",
    "    def get_statistics(self, days: int = 7) -> Dict:\n",
    "        \"\"\"í†µê³„ ì •ë³´ ì¡°íšŒ\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        date_from = datetime.now() - timedelta(days=days)\n",
    "        \n",
    "        # ì „ì²´ í†µê³„\n",
    "        cursor.execute('''\n",
    "            SELECT \n",
    "                COUNT(*) as total,\n",
    "                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,\n",
    "                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed,\n",
    "                AVG(duration) as avg_duration\n",
    "            FROM job_history\n",
    "            WHERE started_at >= ?\n",
    "        ''', (date_from,))\n",
    "        \n",
    "        stats = dict(cursor.fetchone())\n",
    "        \n",
    "        # ì‘ì—… ìœ í˜•ë³„ í†µê³„\n",
    "        cursor.execute('''\n",
    "            SELECT job_type, COUNT(*) as count, AVG(duration) as avg_duration\n",
    "            FROM job_history\n",
    "            WHERE started_at >= ? AND job_type IS NOT NULL\n",
    "            GROUP BY job_type\n",
    "        ''', (date_from,))\n",
    "        \n",
    "        stats['by_type'] = {row[0]: {'count': row[1], 'avg_duration': row[2]} \n",
    "                           for row in cursor.fetchall()}\n",
    "        \n",
    "        conn.close()\n",
    "        return stats\n",
    "    \n",
    "    def cleanup_old_records(self, days: int = 30):\n",
    "        \"\"\"ì˜¤ë˜ëœ ê¸°ë¡ ì •ë¦¬\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cutoff_date = datetime.now() - timedelta(days=days)\n",
    "        \n",
    "        cursor.execute('''\n",
    "            DELETE FROM job_history WHERE started_at < ?\n",
    "        ''', (cutoff_date,))\n",
    "        \n",
    "        deleted_count = cursor.rowcount\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        logger.info(f\"ì˜¤ë˜ëœ ê¸°ë¡ {deleted_count}ê°œ ì‚­ì œ\")\n",
    "        return deleted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. í´ë” ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FolderMonitor(FileSystemEventHandler):\n",
    "    \"\"\"í´ë” ë³€ê²½ ì‚¬í•­ ëª¨ë‹ˆí„°ë§\"\"\"\n",
    "    \n",
    "    def __init__(self, callback: Callable, file_extensions: List[str] = None):\n",
    "        self.callback = callback\n",
    "        self.file_extensions = file_extensions or ['.jpg', '.jpeg', '.png', '.mp4', '.avi']\n",
    "        self.processing_queue = queue.Queue()\n",
    "        self.processed_files = set()\n",
    "        \n",
    "    def on_created(self, event):\n",
    "        \"\"\"íŒŒì¼ ìƒì„± ì´ë²¤íŠ¸\"\"\"\n",
    "        if not event.is_directory:\n",
    "            file_path = Path(event.src_path)\n",
    "            if file_path.suffix.lower() in self.file_extensions:\n",
    "                if str(file_path) not in self.processed_files:\n",
    "                    logger.info(f\"ìƒˆ íŒŒì¼ ê°ì§€: {file_path}\")\n",
    "                    self.processing_queue.put(str(file_path))\n",
    "                    self.processed_files.add(str(file_path))\n",
    "                    \n",
    "                    # ì½œë°± ì‹¤í–‰\n",
    "                    if self.callback:\n",
    "                        try:\n",
    "                            self.callback(str(file_path))\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    def on_modified(self, event):\n",
    "        \"\"\"íŒŒì¼ ìˆ˜ì • ì´ë²¤íŠ¸\"\"\"\n",
    "        # í•„ìš”ì‹œ ì²˜ë¦¬\n",
    "        pass\n",
    "    \n",
    "    def get_pending_files(self) -> List[str]:\n",
    "        \"\"\"ëŒ€ê¸° ì¤‘ì¸ íŒŒì¼ ëª©ë¡\"\"\"\n",
    "        files = []\n",
    "        while not self.processing_queue.empty():\n",
    "            try:\n",
    "                files.append(self.processing_queue.get_nowait())\n",
    "            except queue.Empty:\n",
    "                break\n",
    "        return files\n",
    "\n",
    "class FolderWatcher:\n",
    "    \"\"\"í´ë” ê°ì‹œì\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.observers = {}\n",
    "        self.monitors = {}\n",
    "        \n",
    "    def add_watch(self, folder_path: str, callback: Callable, \n",
    "                 file_extensions: List[str] = None, recursive: bool = True) -> str:\n",
    "        \"\"\"í´ë” ê°ì‹œ ì¶”ê°€\"\"\"\n",
    "        watch_id = str(uuid.uuid4())\n",
    "        \n",
    "        # ëª¨ë‹ˆí„° ìƒì„±\n",
    "        monitor = FolderMonitor(callback, file_extensions)\n",
    "        self.monitors[watch_id] = monitor\n",
    "        \n",
    "        # Observer ìƒì„±\n",
    "        observer = Observer()\n",
    "        observer.schedule(monitor, folder_path, recursive=recursive)\n",
    "        observer.start()\n",
    "        self.observers[watch_id] = observer\n",
    "        \n",
    "        logger.info(f\"í´ë” ê°ì‹œ ì‹œì‘: {folder_path} (ID: {watch_id})\")\n",
    "        return watch_id\n",
    "    \n",
    "    def remove_watch(self, watch_id: str):\n",
    "        \"\"\"í´ë” ê°ì‹œ ì œê±°\"\"\"\n",
    "        if watch_id in self.observers:\n",
    "            self.observers[watch_id].stop()\n",
    "            self.observers[watch_id].join()\n",
    "            del self.observers[watch_id]\n",
    "            del self.monitors[watch_id]\n",
    "            logger.info(f\"í´ë” ê°ì‹œ ì¤‘ì§€: {watch_id}\")\n",
    "    \n",
    "    def stop_all(self):\n",
    "        \"\"\"ëª¨ë“  ê°ì‹œ ì¤‘ì§€\"\"\"\n",
    "        for watch_id in list(self.observers.keys()):\n",
    "            self.remove_watch(watch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì•Œë¦¼ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertLevel(Enum):\n",
    "    \"\"\"ì•Œë¦¼ ë ˆë²¨\"\"\"\n",
    "    INFO = \"info\"\n",
    "    WARNING = \"warning\"\n",
    "    ERROR = \"error\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "@dataclass\n",
    "class Alert:\n",
    "    \"\"\"ì•Œë¦¼ ë©”ì‹œì§€\"\"\"\n",
    "    level: AlertLevel\n",
    "    title: str\n",
    "    message: str\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    metadata: Dict = field(default_factory=dict)\n",
    "\n",
    "class NotificationService:\n",
    "    \"\"\"ì•Œë¦¼ ì„œë¹„ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.handlers = []\n",
    "        self.alert_history = deque(maxlen=1000)\n",
    "        \n",
    "    def add_handler(self, handler: Callable):\n",
    "        \"\"\"ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì¶”ê°€\"\"\"\n",
    "        self.handlers.append(handler)\n",
    "        \n",
    "    def send_alert(self, alert: Alert):\n",
    "        \"\"\"ì•Œë¦¼ ì „ì†¡\"\"\"\n",
    "        self.alert_history.append(alert)\n",
    "        \n",
    "        for handler in self.handlers:\n",
    "            try:\n",
    "                handler(alert)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    def get_recent_alerts(self, count: int = 10, level: Optional[AlertLevel] = None) -> List[Alert]:\n",
    "        \"\"\"ìµœê·¼ ì•Œë¦¼ ì¡°íšŒ\"\"\"\n",
    "        alerts = list(self.alert_history)\n",
    "        \n",
    "        if level:\n",
    "            alerts = [a for a in alerts if a.level == level]\n",
    "        \n",
    "        return alerts[-count:]\n",
    "\n",
    "class EmailNotifier:\n",
    "    \"\"\"ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡\"\"\"\n",
    "    \n",
    "    def __init__(self, smtp_config: Dict):\n",
    "        self.smtp_server = smtp_config.get('server', 'localhost')\n",
    "        self.smtp_port = smtp_config.get('port', 587)\n",
    "        self.username = smtp_config.get('username')\n",
    "        self.password = smtp_config.get('password')\n",
    "        self.from_email = smtp_config.get('from_email')\n",
    "        self.to_emails = smtp_config.get('to_emails', [])\n",
    "        \n",
    "    def send(self, alert: Alert):\n",
    "        \"\"\"ì´ë©”ì¼ ì „ì†¡\"\"\"\n",
    "        if alert.level in [AlertLevel.ERROR, AlertLevel.CRITICAL]:\n",
    "            try:\n",
    "                msg = MIMEMultipart()\n",
    "                msg['From'] = self.from_email\n",
    "                msg['To'] = ', '.join(self.to_emails)\n",
    "                msg['Subject'] = f\"[{alert.level.value.upper()}] {alert.title}\"\n",
    "                \n",
    "                body = f\"\"\"\n",
    "                ì•Œë¦¼ ë ˆë²¨: {alert.level.value}\n",
    "                ì‹œê°„: {alert.timestamp}\n",
    "                \n",
    "                {alert.message}\n",
    "                \n",
    "                ì¶”ê°€ ì •ë³´:\n",
    "                {json.dumps(alert.metadata, indent=2)}\n",
    "                \"\"\"\n",
    "                \n",
    "                msg.attach(MIMEText(body, 'plain'))\n",
    "                \n",
    "                # SMTP ì—°ê²° ë° ì „ì†¡ (ì‹¤ì œ êµ¬í˜„ì‹œ)\n",
    "                # with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:\n",
    "                #     server.starttls()\n",
    "                #     server.login(self.username, self.password)\n",
    "                #     server.send_message(msg)\n",
    "                \n",
    "                logger.info(f\"ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡: {alert.title}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "class ConsoleNotifier:\n",
    "    \"\"\"ì½˜ì†” ì•Œë¦¼ ì¶œë ¥\"\"\"\n",
    "    \n",
    "    def send(self, alert: Alert):\n",
    "        \"\"\"ì½˜ì†” ì¶œë ¥\"\"\"\n",
    "        colors = {\n",
    "            AlertLevel.INFO: '\\033[94m',     # íŒŒë€ìƒ‰\n",
    "            AlertLevel.WARNING: '\\033[93m',   # ë…¸ë€ìƒ‰\n",
    "            AlertLevel.ERROR: '\\033[91m',     # ë¹¨ê°„ìƒ‰\n",
    "            AlertLevel.CRITICAL: '\\033[95m'   # ìì£¼ìƒ‰\n",
    "        }\n",
    "        \n",
    "        color = colors.get(alert.level, '')\n",
    "        reset = '\\033[0m'\n",
    "        \n",
    "        print(f\"{color}[{alert.level.value.upper()}] {alert.timestamp} - {alert.title}{reset}\")\n",
    "        print(f\"  {alert.message}\")\n",
    "        \n",
    "        if alert.metadata:\n",
    "            print(f\"  ë©”íƒ€ë°ì´í„°: {alert.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë©”ì¸ ìŠ¤ì¼€ì¤„ëŸ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulingSystem:\n",
    "    \"\"\"í†µí•© ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, config_file: Optional[str] = None):\n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”\n",
    "        self.scheduler = BackgroundScheduler(\n",
    "            executors={\n",
    "                'default': ThreadPoolExecutor(20),\n",
    "                'processpool': ProcessPoolExecutor(5)\n",
    "            },\n",
    "            job_defaults={\n",
    "                'coalesce': False,\n",
    "                'max_instances': 3\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”\n",
    "        self.history_manager = JobHistoryManager()\n",
    "        self.folder_watcher = FolderWatcher()\n",
    "        self.notification_service = NotificationService()\n",
    "        \n",
    "        # ì•Œë¦¼ í•¸ë“¤ëŸ¬ ì¶”ê°€\n",
    "        console_notifier = ConsoleNotifier()\n",
    "        self.notification_service.add_handler(console_notifier.send)\n",
    "        \n",
    "        # ì‘ì—… ë ˆì§€ìŠ¤íŠ¸ë¦¬\n",
    "        self.registered_jobs = {}\n",
    "        \n",
    "        # ì„¤ì • ë¡œë“œ\n",
    "        if config_file:\n",
    "            self.load_config(config_file)\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘\n",
    "        self.scheduler.start()\n",
    "        logger.info(\"ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì‹œì‘\")\n",
    "    \n",
    "    def register_job(self, job: Job) -> str:\n",
    "        \"\"\"ì‘ì—… ë“±ë¡\"\"\"\n",
    "        if not job.enabled:\n",
    "            logger.info(f\"ì‘ì—… ë¹„í™œì„±í™”: {job.name}\")\n",
    "            return job.id\n",
    "        \n",
    "        # APScheduler ì‘ì—… ì¶”ê°€\n",
    "        if job.schedule_expression:  # í¬ë¡  í‘œí˜„ì‹\n",
    "            trigger = CronTrigger.from_crontab(job.schedule_expression)\n",
    "        elif job.interval_seconds:  # ê°„ê²©\n",
    "            trigger = IntervalTrigger(seconds=job.interval_seconds)\n",
    "        elif job.run_at:  # íŠ¹ì • ì‹œê°„\n",
    "            trigger = DateTrigger(run_date=job.run_at)\n",
    "        else:\n",
    "            logger.error(f\"ì‘ì—… ìŠ¤ì¼€ì¤„ ì •ì˜ ì—†ìŒ: {job.name}\")\n",
    "            return job.id\n",
    "        \n",
    "        # ì‘ì—… ë˜í¼ í•¨ìˆ˜\n",
    "        def job_wrapper():\n",
    "            self._execute_job(job)\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ì— ì¶”ê°€\n",
    "        self.scheduler.add_job(\n",
    "            job_wrapper,\n",
    "            trigger=trigger,\n",
    "            id=job.id,\n",
    "            name=job.name,\n",
    "            replace_existing=True\n",
    "        )\n",
    "        \n",
    "        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥\n",
    "        self.registered_jobs[job.id] = job\n",
    "        \n",
    "        logger.info(f\"ì‘ì—… ë“±ë¡: {job.name} (ID: {job.id})\")\n",
    "        return job.id\n",
    "    \n",
    "    def _execute_job(self, job: Job):\n",
    "        \"\"\"ì‘ì—… ì‹¤í–‰\"\"\"\n",
    "        result = JobResult(\n",
    "            job_id=job.id,\n",
    "            job_name=job.name,\n",
    "            status=JobStatus.RUNNING,\n",
    "            started_at=datetime.now()\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"ì‘ì—… ì‹œì‘: {job.name}\")\n",
    "        \n",
    "        try:\n",
    "            # íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬\n",
    "            if job.timeout:\n",
    "                import signal\n",
    "                \n",
    "                def timeout_handler(signum, frame):\n",
    "                    raise TimeoutError(f\"ì‘ì—… íƒ€ì„ì•„ì›ƒ: {job.timeout}ì´ˆ\")\n",
    "                \n",
    "                # signal.signal(signal.SIGALRM, timeout_handler)\n",
    "                # signal.alarm(job.timeout)\n",
    "            \n",
    "            # ì‘ì—… ì‹¤í–‰\n",
    "            if job.function:\n",
    "                result.result = job.function(*job.args, **job.kwargs)\n",
    "            \n",
    "            # ì„±ê³µ\n",
    "            result.status = JobStatus.COMPLETED\n",
    "            result.completed_at = datetime.now()\n",
    "            result.duration = (result.completed_at - result.started_at).total_seconds()\n",
    "            \n",
    "            logger.info(f\"ì‘ì—… ì™„ë£Œ: {job.name} (ì†Œìš”ì‹œê°„: {result.duration:.2f}ì´ˆ)\")\n",
    "            \n",
    "            # ì„±ê³µ ì•Œë¦¼\n",
    "            if job.job_type in [JobType.DATABASE_BACKUP, JobType.REPORT_GENERATION]:\n",
    "                self.notification_service.send_alert(Alert(\n",
    "                    level=AlertLevel.INFO,\n",
    "                    title=f\"ì‘ì—… ì™„ë£Œ: {job.name}\",\n",
    "                    message=f\"ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì†Œìš”ì‹œê°„: {result.duration:.2f}ì´ˆ)\"\n",
    "                ))\n",
    "            \n",
    "        except Exception as e:\n",
    "            # ì‹¤íŒ¨\n",
    "            result.status = JobStatus.FAILED\n",
    "            result.error = str(e)\n",
    "            result.completed_at = datetime.now()\n",
    "            result.duration = (result.completed_at - result.started_at).total_seconds()\n",
    "            \n",
    "            logger.error(f\"ì‘ì—… ì‹¤íŒ¨: {job.name} - {e}\")\n",
    "            \n",
    "            # ì‹¤íŒ¨ ì•Œë¦¼\n",
    "            self.notification_service.send_alert(Alert(\n",
    "                level=AlertLevel.ERROR,\n",
    "                title=f\"ì‘ì—… ì‹¤íŒ¨: {job.name}\",\n",
    "                message=str(e),\n",
    "                metadata={'job_id': job.id, 'retry_count': result.retry_count}\n",
    "            ))\n",
    "            \n",
    "            # ì¬ì‹œë„\n",
    "            if result.retry_count < job.max_retries:\n",
    "                result.retry_count += 1\n",
    "                logger.info(f\"ì‘ì—… ì¬ì‹œë„ ì˜ˆì •: {job.name} ({result.retry_count}/{job.max_retries})\")\n",
    "                \n",
    "                # ì¬ì‹œë„ ìŠ¤ì¼€ì¤„\n",
    "                retry_time = datetime.now() + timedelta(seconds=job.retry_delay)\n",
    "                self.scheduler.add_job(\n",
    "                    lambda: self._execute_job(job),\n",
    "                    trigger=DateTrigger(run_date=retry_time),\n",
    "                    id=f\"{job.id}_retry_{result.retry_count}\"\n",
    "                )\n",
    "        \n",
    "        finally:\n",
    "            # íƒ€ì„ì•„ì›ƒ í•´ì œ\n",
    "            if job.timeout:\n",
    "                pass  # signal.alarm(0)\n",
    "            \n",
    "            # ì´ë ¥ ì €ì¥\n",
    "            self.history_manager.save_result(result, job.job_type)\n",
    "    \n",
    "    def remove_job(self, job_id: str):\n",
    "        \"\"\"ì‘ì—… ì œê±°\"\"\"\n",
    "        try:\n",
    "            self.scheduler.remove_job(job_id)\n",
    "            if job_id in self.registered_jobs:\n",
    "                del self.registered_jobs[job_id]\n",
    "            logger.info(f\"ì‘ì—… ì œê±°: {job_id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì‘ì—… ì œê±° ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    def pause_job(self, job_id: str):\n",
    "        \"\"\"ì‘ì—… ì¼ì‹œì •ì§€\"\"\"\n",
    "        self.scheduler.pause_job(job_id)\n",
    "        logger.info(f\"ì‘ì—… ì¼ì‹œì •ì§€: {job_id}\")\n",
    "    \n",
    "    def resume_job(self, job_id: str):\n",
    "        \"\"\"ì‘ì—… ì¬ê°œ\"\"\"\n",
    "        self.scheduler.resume_job(job_id)\n",
    "        logger.info(f\"ì‘ì—… ì¬ê°œ: {job_id}\")\n",
    "    \n",
    "    def get_status(self) -> Dict:\n",
    "        \"\"\"ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ\"\"\"\n",
    "        jobs = self.scheduler.get_jobs()\n",
    "        \n",
    "        return {\n",
    "            'scheduler_running': self.scheduler.running,\n",
    "            'total_jobs': len(jobs),\n",
    "            'active_jobs': len([j for j in jobs if not j.pending]),\n",
    "            'pending_jobs': len([j for j in jobs if j.pending]),\n",
    "            'watched_folders': len(self.folder_watcher.observers),\n",
    "            'recent_alerts': len(self.notification_service.alert_history),\n",
    "            'job_statistics': self.history_manager.get_statistics()\n",
    "        }\n",
    "    \n",
    "    def load_config(self, config_file: str):\n",
    "        \"\"\"ì„¤ì • íŒŒì¼ ë¡œë“œ\"\"\"\n",
    "        with open(config_file, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        # ì‘ì—… ì„¤ì • ë¡œë“œ\n",
    "        for job_config in config.get('jobs', []):\n",
    "            job = Job(\n",
    "                name=job_config['name'],\n",
    "                job_type=JobType(job_config.get('type', 'image_processing')),\n",
    "                schedule_expression=job_config.get('schedule'),\n",
    "                interval_seconds=job_config.get('interval'),\n",
    "                enabled=job_config.get('enabled', True)\n",
    "            )\n",
    "            self.register_job(job)\n",
    "        \n",
    "        # í´ë” ê°ì‹œ ì„¤ì •\n",
    "        for watch_config in config.get('folder_watches', []):\n",
    "            self.folder_watcher.add_watch(\n",
    "                watch_config['path'],\n",
    "                lambda x: logger.info(f\"ìƒˆ íŒŒì¼: {x}\"),\n",
    "                watch_config.get('extensions'),\n",
    "                watch_config.get('recursive', True)\n",
    "            )\n",
    "    \n",
    "    def shutdown(self):\n",
    "        \"\"\"ì‹œìŠ¤í…œ ì¢…ë£Œ\"\"\"\n",
    "        logger.info(\"ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...\")\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ\n",
    "        self.scheduler.shutdown(wait=True)\n",
    "        \n",
    "        # í´ë” ê°ì‹œ ì¢…ë£Œ\n",
    "        self.folder_watcher.stop_all()\n",
    "        \n",
    "        logger.info(\"ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‚¬ìš© ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ ì‘ì—… í•¨ìˆ˜ë“¤\n",
    "def process_drone_images():\n",
    "    \"\"\"ë“œë¡  ì´ë¯¸ì§€ ì²˜ë¦¬ ì‘ì—…\"\"\"\n",
    "    logger.info(\"ë“œë¡  ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\")\n",
    "    time.sleep(2)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "    return {\"processed\": 10, \"failed\": 0}\n",
    "\n",
    "def backup_database():\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‘ì—…\"\"\"\n",
    "    logger.info(\"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹œì‘\")\n",
    "    time.sleep(1)\n",
    "    return {\"backup_file\": \"backup_20251024.db\", \"size_mb\": 156}\n",
    "\n",
    "def generate_daily_report():\n",
    "    \"\"\"ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
    "    logger.info(\"ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘\")\n",
    "    time.sleep(1)\n",
    "    return {\"report_file\": \"daily_report_20251024.pdf\"}\n",
    "\n",
    "def cleanup_old_data():\n",
    "    \"\"\"ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬\"\"\"\n",
    "    logger.info(\"ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‹œì‘\")\n",
    "    time.sleep(1)\n",
    "    return {\"deleted_files\": 25, \"freed_space_mb\": 500}\n",
    "\n",
    "# ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ë°ëª¨\n",
    "def demo_scheduling_system():\n",
    "    \"\"\"ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ë°ëª¨\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ë°ëª¨ ì‹œì‘\\n\")\n",
    "    \n",
    "    # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    print(\"[1/5] ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "    scheduler = SchedulingSystem()\n",
    "    \n",
    "    # 2. ì‘ì—… ë“±ë¡\n",
    "    print(\"[2/5] ì‘ì—… ë“±ë¡...\")\n",
    "    \n",
    "    # ë§¤ 30ì´ˆë§ˆë‹¤ ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "    job1 = Job(\n",
    "        name=\"ë“œë¡  ì´ë¯¸ì§€ ì²˜ë¦¬\",\n",
    "        job_type=JobType.IMAGE_PROCESSING,\n",
    "        function=process_drone_images,\n",
    "        interval_seconds=30,\n",
    "        max_retries=3\n",
    "    )\n",
    "    scheduler.register_job(job1)\n",
    "    \n",
    "    # ë§¤ì‹œ ì •ê° ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…\n",
    "    job2 = Job(\n",
    "        name=\"ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…\",\n",
    "        job_type=JobType.DATABASE_BACKUP,\n",
    "        function=backup_database,\n",
    "        schedule_expression=\"0 * * * *\",  # ë§¤ì‹œ ì •ê°\n",
    "        priority=1\n",
    "    )\n",
    "    scheduler.register_job(job2)\n",
    "    \n",
    "    # ë§¤ì¼ ì˜¤ì „ 6ì‹œ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "    job3 = Job(\n",
    "        name=\"ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±\",\n",
    "        job_type=JobType.REPORT_GENERATION,\n",
    "        function=generate_daily_report,\n",
    "        schedule_expression=\"0 6 * * *\",  # ë§¤ì¼ 06:00\n",
    "        priority=2\n",
    "    )\n",
    "    scheduler.register_job(job3)\n",
    "    \n",
    "    # ë§¤ì£¼ ì¼ìš”ì¼ ìì • ë°ì´í„° ì •ë¦¬\n",
    "    job4 = Job(\n",
    "        name=\"ì£¼ê°„ ë°ì´í„° ì •ë¦¬\",\n",
    "        job_type=JobType.DATA_CLEANUP,\n",
    "        function=cleanup_old_data,\n",
    "        schedule_expression=\"0 0 * * 0\",  # ë§¤ì£¼ ì¼ìš”ì¼ 00:00\n",
    "        priority=3\n",
    "    )\n",
    "    scheduler.register_job(job4)\n",
    "    \n",
    "    print(f\"  âœ“ {len(scheduler.registered_jobs)}ê°œ ì‘ì—… ë“±ë¡ ì™„ë£Œ\")\n",
    "    \n",
    "    # 3. í´ë” ê°ì‹œ ì¶”ê°€\n",
    "    print(\"[3/5] í´ë” ê°ì‹œ ì„¤ì •...\")\n",
    "    \n",
    "    def on_new_file(file_path):\n",
    "        print(f\"  ìƒˆ íŒŒì¼ ê°ì§€: {file_path}\")\n",
    "        # ì—¬ê¸°ì— íŒŒì¼ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€\n",
    "    \n",
    "    # watch_id = scheduler.folder_watcher.add_watch(\n",
    "    #     \"./drone_images\",\n",
    "    #     on_new_file,\n",
    "    #     ['.jpg', '.png'],\n",
    "    #     recursive=True\n",
    "    # )\n",
    "    # print(f\"  âœ“ í´ë” ê°ì‹œ ì‹œì‘: ./drone_images\")\n",
    "    \n",
    "    # 4. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
    "    print(\"\\n[4/5] ì‹œìŠ¤í…œ ìƒíƒœ...\")\n",
    "    status = scheduler.get_status()\n",
    "    print(f\"  ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ: {'ì‹¤í–‰ì¤‘' if status['scheduler_running'] else 'ì¤‘ì§€'}\")\n",
    "    print(f\"  ë“±ë¡ëœ ì‘ì—…: {status['total_jobs']}ê°œ\")\n",
    "    print(f\"  í™œì„± ì‘ì—…: {status['active_jobs']}ê°œ\")\n",
    "    print(f\"  ëŒ€ê¸° ì‘ì—…: {status['pending_jobs']}ê°œ\")\n",
    "    \n",
    "    # 5. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì§§ì€ ì‹œê°„)\n",
    "    print(\"\\n[5/5] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (10ì´ˆê°„)...\")\n",
    "    print(\"  ì‘ì—…ì´ ìŠ¤ì¼€ì¤„ì— ë”°ë¼ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 10ì´ˆê°„ ì‹¤í–‰\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # ì´ë ¥ í™•ì¸\n",
    "    print(\"\\nğŸ“Š ì‘ì—… ì‹¤í–‰ ì´ë ¥:\")\n",
    "    history = scheduler.history_manager.get_history(limit=5)\n",
    "    for record in history:\n",
    "        print(f\"  - {record['job_name']}: {record['status']} \"\n",
    "              f\"(ì†Œìš”ì‹œê°„: {record.get('duration', 0):.2f}ì´ˆ)\")\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ì¢…ë£Œ\n",
    "    print(\"\\nì‹œìŠ¤í…œ ì¢…ë£Œ...\")\n",
    "    scheduler.shutdown()\n",
    "    \n",
    "    print(\"\\nâœ… ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ë°ëª¨ ì™„ë£Œ!\")\n",
    "    \n",
    "    return scheduler\n",
    "\n",
    "# ë°ëª¨ ì‹¤í–‰\n",
    "demo_scheduler = demo_scheduling_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì„¤ì • íŒŒì¼ ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì • íŒŒì¼ ì˜ˆì œ ìƒì„±\n",
    "config_example = \"\"\"\n",
    "# ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ì„¤ì •\n",
    "system:\n",
    "  name: \"ë“œë¡  ì‘ë¬¼ ëª¨ë‹ˆí„°ë§ ìŠ¤ì¼€ì¤„ëŸ¬\"\n",
    "  timezone: \"Asia/Seoul\"\n",
    "  \n",
    "# ì‘ì—… ì •ì˜\n",
    "jobs:\n",
    "  - name: \"ì•„ì¹¨ ë“œë¡  ì˜ìƒ ì²˜ë¦¬\"\n",
    "    type: \"image_processing\"\n",
    "    schedule: \"0 7 * * *\"  # ë§¤ì¼ 07:00\n",
    "    enabled: true\n",
    "    \n",
    "  - name: \"ì ì‹¬ ë“œë¡  ì˜ìƒ ì²˜ë¦¬\"\n",
    "    type: \"image_processing\"\n",
    "    schedule: \"0 12 * * *\"  # ë§¤ì¼ 12:00\n",
    "    enabled: true\n",
    "    \n",
    "  - name: \"ì €ë… ë“œë¡  ì˜ìƒ ì²˜ë¦¬\"\n",
    "    type: \"image_processing\"\n",
    "    schedule: \"0 18 * * *\"  # ë§¤ì¼ 18:00\n",
    "    enabled: true\n",
    "    \n",
    "  - name: \"ì¼ì¼ ë°±ì—…\"\n",
    "    type: \"database_backup\"\n",
    "    schedule: \"0 2 * * *\"  # ë§¤ì¼ 02:00\n",
    "    enabled: true\n",
    "    \n",
    "  - name: \"ì£¼ê°„ ë¦¬í¬íŠ¸\"\n",
    "    type: \"report_generation\"\n",
    "    schedule: \"0 9 * * 1\"  # ë§¤ì£¼ ì›”ìš”ì¼ 09:00\n",
    "    enabled: true\n",
    "    \n",
    "  - name: \"ì›”ê°„ ë°ì´í„° ì •ë¦¬\"\n",
    "    type: \"data_cleanup\"\n",
    "    schedule: \"0 3 1 * *\"  # ë§¤ì›” 1ì¼ 03:00\n",
    "    enabled: true\n",
    "\n",
    "# í´ë” ê°ì‹œ\n",
    "folder_watches:\n",
    "  - path: \"/drone/incoming\"\n",
    "    extensions: [\".jpg\", \".jpeg\", \".png\", \".tiff\"]\n",
    "    recursive: true\n",
    "    \n",
    "  - path: \"/drone/videos\"\n",
    "    extensions: [\".mp4\", \".avi\", \".mov\"]\n",
    "    recursive: false\n",
    "\n",
    "# ì•Œë¦¼ ì„¤ì •\n",
    "notifications:\n",
    "  email:\n",
    "    enabled: false\n",
    "    smtp_server: \"smtp.gmail.com\"\n",
    "    smtp_port: 587\n",
    "    from_email: \"drone@example.com\"\n",
    "    to_emails:\n",
    "      - \"admin@example.com\"\n",
    "      - \"operator@example.com\"\n",
    "  \n",
    "  slack:\n",
    "    enabled: false\n",
    "    webhook_url: \"https://hooks.slack.com/services/...\"\n",
    "\"\"\"\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ì €ì¥\n",
    "config_path = Path(\"scheduling_config.yaml\")\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_example)\n",
    "\n",
    "print(\"ğŸ“ ì„¤ì • íŒŒì¼ ì˜ˆì œ:\")\n",
    "print(config_example)\n",
    "print(f\"\\nì„¤ì • íŒŒì¼ ì €ì¥: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonitoringDashboard:\n",
    "    \"\"\"ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ\"\"\"\n",
    "    \n",
    "    def __init__(self, scheduler: SchedulingSystem):\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "    def get_dashboard_data(self) -> Dict:\n",
    "        \"\"\"ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±\"\"\"\n",
    "        status = self.scheduler.get_status()\n",
    "        \n",
    "        # ì‘ì—… ëª©ë¡\n",
    "        jobs = []\n",
    "        for job_id, job in self.scheduler.registered_jobs.items():\n",
    "            next_run = None\n",
    "            scheduled_job = self.scheduler.scheduler.get_job(job_id)\n",
    "            if scheduled_job:\n",
    "                next_run = scheduled_job.next_run_time\n",
    "            \n",
    "            jobs.append({\n",
    "                'id': job.id,\n",
    "                'name': job.name,\n",
    "                'type': job.job_type.value,\n",
    "                'enabled': job.enabled,\n",
    "                'next_run': next_run.isoformat() if next_run else None\n",
    "            })\n",
    "        \n",
    "        # ìµœê·¼ ì•Œë¦¼\n",
    "        recent_alerts = [\n",
    "            {\n",
    "                'level': alert.level.value,\n",
    "                'title': alert.title,\n",
    "                'message': alert.message,\n",
    "                'timestamp': alert.timestamp.isoformat()\n",
    "            }\n",
    "            for alert in self.scheduler.notification_service.get_recent_alerts(5)\n",
    "        ]\n",
    "        \n",
    "        # ì‘ì—… í†µê³„\n",
    "        stats = self.scheduler.history_manager.get_statistics(7)\n",
    "        \n",
    "        return {\n",
    "            'system_status': status,\n",
    "            'jobs': jobs,\n",
    "            'recent_alerts': recent_alerts,\n",
    "            'statistics': stats,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def print_dashboard(self):\n",
    "        \"\"\"ì½˜ì†” ëŒ€ì‹œë³´ë“œ ì¶œë ¥\"\"\"\n",
    "        data = self.get_dashboard_data()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nâš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ\")\n",
    "        print(f\"  ìŠ¤ì¼€ì¤„ëŸ¬: {'ğŸŸ¢ ì‹¤í–‰ì¤‘' if data['system_status']['scheduler_running'] else 'ğŸ”´ ì¤‘ì§€'}\")\n",
    "        print(f\"  ë“±ë¡ ì‘ì—…: {data['system_status']['total_jobs']}ê°œ\")\n",
    "        print(f\"  ê°ì‹œ í´ë”: {data['system_status']['watched_folders']}ê°œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ ì˜ˆì • ì‘ì—…\")\n",
    "        for job in data['jobs'][:5]:\n",
    "            status = 'âœ…' if job['enabled'] else 'â¸ï¸'\n",
    "            print(f\"  {status} {job['name']} ({job['type']})\")\n",
    "            if job['next_run']:\n",
    "                print(f\"     ë‹¤ìŒ ì‹¤í–‰: {job['next_run']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ ìµœê·¼ 7ì¼ í†µê³„\")\n",
    "        stats = data['statistics']\n",
    "        if stats:\n",
    "            print(f\"  ì´ ì‹¤í–‰: {stats.get('total', 0)}íšŒ\")\n",
    "            print(f\"  ì„±ê³µ: {stats.get('completed', 0)}íšŒ\")\n",
    "            print(f\"  ì‹¤íŒ¨: {stats.get('failed', 0)}íšŒ\")\n",
    "            if stats.get('avg_duration'):\n",
    "                print(f\"  í‰ê·  ì‹œê°„: {stats['avg_duration']:.2f}ì´ˆ\")\n",
    "        \n",
    "        if data['recent_alerts']:\n",
    "            print(f\"\\nğŸ”” ìµœê·¼ ì•Œë¦¼\")\n",
    "            for alert in data['recent_alerts'][:3]:\n",
    "                icon = {'info': 'â„¹ï¸', 'warning': 'âš ï¸', 'error': 'âŒ', 'critical': 'ğŸš¨'}\n",
    "                print(f\"  {icon.get(alert['level'], 'â€¢')} {alert['title']}\")\n",
    "        \n",
    "        print(f\"\\në§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {data['timestamp']}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# ëŒ€ì‹œë³´ë“œ ì¶œë ¥ ì˜ˆì œ\n",
    "if 'demo_scheduler' in locals():\n",
    "    print(\"\\nëŒ€ì‹œë³´ë“œ ì˜ˆì œ:\")\n",
    "    dashboard = MonitoringDashboard(demo_scheduler)\n",
    "    # dashboard.print_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ë‹¤ìŒ ëª¨ë“ˆ ì—°ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”— ë‹¤ìŒ ëª¨ë“ˆ ì—°ë™ ì •ë³´\\n\")\n",
    "\n",
    "print(\"ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\\n\")\n",
    "\n",
    "print(\"ì´ ëª¨ë“ˆì´ ì—°ë™í•˜ëŠ” ë‹¤ë¥¸ ëª¨ë“ˆë“¤:\\n\")\n",
    "\n",
    "print(\"1. â†’ Todo 2 (ì…ë ¥ ì²˜ë¦¬):\")\n",
    "print(\"   - í´ë” ê°ì‹œë¥¼ í†µí•œ ìë™ ì…ë ¥ ì²˜ë¦¬\")\n",
    "print(\"   - ìŠ¤ì¼€ì¤„ì— ë”°ë¥¸ ì£¼ê¸°ì  ì²˜ë¦¬\")\n",
    "\n",
    "print(\"\\n2. â†’ Todo 5 (ë°°ì¹˜ ì²˜ë¦¬):\")\n",
    "print(\"   - ì •ê¸°ì  ë°°ì¹˜ ì‘ì—… ì‹¤í–‰\")\n",
    "print(\"   - ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ì‘ì—… ì¡°ì ˆ\")\n",
    "\n",
    "print(\"\\n3. â†’ Todo 6 (ê²°ê³¼ ì €ì¥):\")\n",
    "print(\"   - ì •ê¸°ì  ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…\")\n",
    "print(\"   - ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì •ë¦¬\")\n",
    "\n",
    "print(\"\\n4. â†’ Todo 8 (ì‹œê°í™”/ë¦¬í¬íŠ¸):\")\n",
    "print(\"   - ì •ê¸° ë¦¬í¬íŠ¸ ìë™ ìƒì„±\")\n",
    "print(\"   - ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì œê³µ\")\n",
    "\n",
    "print(\"\\nì£¼ìš” íŠ¹ì§•:\")\n",
    "print(\"âœ“ í¬ë¡  í‘œí˜„ì‹ ì§€ì›\")\n",
    "print(\"âœ“ í´ë” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§\")\n",
    "print(\"âœ“ ì‘ì—… ì‹¤í–‰ ì´ë ¥ ê´€ë¦¬\")\n",
    "print(\"âœ“ ì•Œë¦¼ ì‹œìŠ¤í…œ\")\n",
    "print(\"âœ“ ìë™ ì¬ì‹œë„ ë° ë³µêµ¬\")\n",
    "print(\"âœ“ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ\")\n",
    "\n",
    "print(\"\\nì§€ì†ì  ëª¨ë‹ˆí„°ë§ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ê°œë°œ ì™„ë£Œ! âœ¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}