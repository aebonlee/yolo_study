{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‹¤ì‹œê°„ ì˜ìƒ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
    "\n",
    "**ëª©ì **: ë“œë¡  ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹¤ì‹œê°„ ì²˜ë¦¬ ë° ì‘ë¬¼ íƒì§€  \n",
    "**ë‹´ë‹¹**: Claude Sonnet 4  \n",
    "**ë‚ ì§œ**: 2025-10-21\n",
    "\n",
    "## ğŸ“‹ ì‘ì—… ë‚´ìš©\n",
    "1. ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "2. ë©€í‹°ìŠ¤ë ˆë”© ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™”\n",
    "3. í”„ë ˆì„ í ê´€ë¦¬ ë° ë²„í¼ë§\n",
    "4. ì‹¤ì‹œê°„ ê²°ê³¼ ì‹œê°í™”\n",
    "5. ìŠ¤íŠ¸ë¦¬ë° í’ˆì§ˆ ìë™ ì¡°ì ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "import logging\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„í•œ í´ë˜ìŠ¤ë“¤ ì¬ì‚¬ìš©\n",
    "# (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” importë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŒ)\n",
    "\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"OpenCV ë²„ì „: {cv2.__version__}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PerformanceMetrics:\n",
    "    \"\"\"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    fps: float = 0.0\n",
    "    processing_time: float = 0.0\n",
    "    detection_count: int = 0\n",
    "    frame_drops: int = 0\n",
    "    queue_size: int = 0\n",
    "    gpu_memory_used: float = 0.0\n",
    "    timestamp: float = 0.0\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size: int = 30):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            window_size: ì´ë™ í‰ê·  ìœˆë„ìš° í¬ê¸°\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.reset()\n",
    "        \n",
    "        # ë¡œê¹… ì„¤ì •\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"ë©”íŠ¸ë¦­ ë¦¬ì…‹\"\"\"\n",
    "        self.frame_times = deque(maxlen=self.window_size)\n",
    "        self.processing_times = deque(maxlen=self.window_size)\n",
    "        self.detection_counts = deque(maxlen=self.window_size)\n",
    "        self.total_frames = 0\n",
    "        self.total_drops = 0\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def update(self, processing_time: float, detection_count: int, \n",
    "               frame_dropped: bool = False, queue_size: int = 0):\n",
    "        \"\"\"ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸\n",
    "        \n",
    "        Args:\n",
    "            processing_time: ì²˜ë¦¬ ì‹œê°„\n",
    "            detection_count: íƒì§€ ê°œìˆ˜\n",
    "            frame_dropped: í”„ë ˆì„ ë“œë¡­ ì—¬ë¶€\n",
    "            queue_size: í í¬ê¸°\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        self.frame_times.append(current_time)\n",
    "        self.processing_times.append(processing_time)\n",
    "        self.detection_counts.append(detection_count)\n",
    "        self.total_frames += 1\n",
    "        \n",
    "        if frame_dropped:\n",
    "            self.total_drops += 1\n",
    "    \n",
    "    def get_metrics(self) -> PerformanceMetrics:\n",
    "        \"\"\"í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            metrics: ì„±ëŠ¥ ë©”íŠ¸ë¦­\n",
    "        \"\"\"\n",
    "        if len(self.frame_times) < 2:\n",
    "            return PerformanceMetrics()\n",
    "        \n",
    "        # FPS ê³„ì‚° (ì´ë™ í‰ê· )\n",
    "        time_diff = self.frame_times[-1] - self.frame_times[0]\n",
    "        fps = len(self.frame_times) / time_diff if time_diff > 0 else 0\n",
    "        \n",
    "        # í‰ê·  ì²˜ë¦¬ ì‹œê°„\n",
    "        avg_processing_time = np.mean(self.processing_times)\n",
    "        \n",
    "        # í‰ê·  íƒì§€ ê°œìˆ˜\n",
    "        avg_detection_count = np.mean(self.detection_counts)\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "        gpu_memory = 0.0\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.memory_allocated() / 1024**3  # GB\n",
    "        \n",
    "        return PerformanceMetrics(\n",
    "            fps=fps,\n",
    "            processing_time=avg_processing_time,\n",
    "            detection_count=int(avg_detection_count),\n",
    "            frame_drops=self.total_drops,\n",
    "            gpu_memory_used=gpu_memory,\n",
    "            timestamp=time.time()\n",
    "        )\n",
    "    \n",
    "    def log_metrics(self):\n",
    "        \"\"\"ë©”íŠ¸ë¦­ ë¡œê¹…\"\"\"\n",
    "        metrics = self.get_metrics()\n",
    "        self.logger.info(\n",
    "            f\"FPS: {metrics.fps:.2f} | \"\n",
    "            f\"ì²˜ë¦¬ì‹œê°„: {metrics.processing_time*1000:.1f}ms | \"\n",
    "            f\"íƒì§€ìˆ˜: {metrics.detection_count} | \"\n",
    "            f\"ë“œë¡­: {metrics.frame_drops} | \"\n",
    "            f\"GPU: {metrics.gpu_memory_used:.2f}GB\"\n",
    "        )\n",
    "\n",
    "# ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "perf_monitor = PerformanceMonitor()\n",
    "print(\"âœ… PerformanceMonitor ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. í”„ë ˆì„ í ë° ë²„í¼ ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameBuffer:\n",
    "    \"\"\"í”„ë ˆì„ ë²„í¼ ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: int = 10, drop_policy: str = 'oldest'):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            max_size: ìµœëŒ€ ë²„í¼ í¬ê¸°\n",
    "            drop_policy: ë“œë¡­ ì •ì±… ('oldest', 'newest')\n",
    "        \"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.drop_policy = drop_policy\n",
    "        self.frame_queue = queue.Queue(maxsize=max_size)\n",
    "        self.frame_counter = 0\n",
    "        self.dropped_frames = 0\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def put_frame(self, frame: np.ndarray, timestamp: float = None) -> bool:\n",
    "        \"\"\"í”„ë ˆì„ ì¶”ê°€\n",
    "        \n",
    "        Args:\n",
    "            frame: í”„ë ˆì„ ì´ë¯¸ì§€\n",
    "            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„\n",
    "            \n",
    "        Returns:\n",
    "            success: ì¶”ê°€ ì„±ê³µ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = time.time()\n",
    "        \n",
    "        frame_data = {\n",
    "            'frame': frame,\n",
    "            'timestamp': timestamp,\n",
    "            'frame_id': self.frame_counter\n",
    "        }\n",
    "        \n",
    "        with self.lock:\n",
    "            if self.frame_queue.full():\n",
    "                if self.drop_policy == 'oldest':\n",
    "                    try:\n",
    "                        self.frame_queue.get_nowait()\n",
    "                        self.dropped_frames += 1\n",
    "                    except queue.Empty:\n",
    "                        pass\n",
    "                elif self.drop_policy == 'newest':\n",
    "                    self.dropped_frames += 1\n",
    "                    return False\n",
    "            \n",
    "            try:\n",
    "                self.frame_queue.put_nowait(frame_data)\n",
    "                self.frame_counter += 1\n",
    "                return True\n",
    "            except queue.Full:\n",
    "                self.dropped_frames += 1\n",
    "                return False\n",
    "    \n",
    "    def get_frame(self, timeout: float = 0.1) -> Optional[Dict]:\n",
    "        \"\"\"í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°\n",
    "        \n",
    "        Args:\n",
    "            timeout: íƒ€ì„ì•„ì›ƒ\n",
    "            \n",
    "        Returns:\n",
    "            frame_data: í”„ë ˆì„ ë°ì´í„° ë˜ëŠ” None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.frame_queue.get(timeout=timeout)\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"ë²„í¼ í†µê³„ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            stats: ë²„í¼ í†µê³„\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            return {\n",
    "                'queue_size': self.frame_queue.qsize(),\n",
    "                'max_size': self.max_size,\n",
    "                'total_frames': self.frame_counter,\n",
    "                'dropped_frames': self.dropped_frames,\n",
    "                'drop_rate': self.dropped_frames / max(1, self.frame_counter)\n",
    "            }\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"ë²„í¼ ë¹„ìš°ê¸°\"\"\"\n",
    "        with self.lock:\n",
    "            while not self.frame_queue.empty():\n",
    "                try:\n",
    "                    self.frame_queue.get_nowait()\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "# í”„ë ˆì„ ë²„í¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "frame_buffer = FrameBuffer(max_size=5, drop_policy='oldest')\n",
    "print(\"âœ… FrameBuffer ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeVideoPipeline:\n",
    "    \"\"\"ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_path: str = 'yolo11n.pt',\n",
    "                 device: str = 'auto',\n",
    "                 buffer_size: int = 5,\n",
    "                 target_fps: float = 30.0):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            model_path: YOLO ëª¨ë¸ ê²½ë¡œ\n",
    "            device: ì‹¤í–‰ ë””ë°”ì´ìŠ¤\n",
    "            buffer_size: í”„ë ˆì„ ë²„í¼ í¬ê¸°\n",
    "            target_fps: ëª©í‘œ FPS\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.device = device if device != 'auto' else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.target_fps = target_fps\n",
    "        self.frame_interval = 1.0 / target_fps\n",
    "        \n",
    "        # ë²„í¼ ë° ëª¨ë‹ˆí„°ë§\n",
    "        self.frame_buffer = FrameBuffer(max_size=buffer_size)\n",
    "        self.performance_monitor = PerformanceMonitor()\n",
    "        \n",
    "        # ìŠ¤ë ˆë“œ ê´€ë¦¬\n",
    "        self.capture_thread = None\n",
    "        self.process_thread = None\n",
    "        self.display_thread = None\n",
    "        self.running = False\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        self.results_queue = queue.Queue(maxsize=100)\n",
    "        self.detection_history = deque(maxlen=1000)\n",
    "        \n",
    "        # ë™ì  í’ˆì§ˆ ì¡°ì ˆ\n",
    "        self.adaptive_quality = True\n",
    "        self.current_quality = 1.0  # 1.0 = ì›ë³¸ í•´ìƒë„\n",
    "        self.conf_threshold = 0.25\n",
    "        \n",
    "        print(f\"ğŸ¥ RealTimeVideoPipeline ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        print(f\"   ëª¨ë¸: {model_path}\")\n",
    "        print(f\"   ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "        print(f\"   ëª©í‘œ FPS: {target_fps}\")\n",
    "    \n",
    "    def capture_frames(self, source):\n",
    "        \"\"\"í”„ë ˆì„ ìº¡ì²˜ ìŠ¤ë ˆë“œ\n",
    "        \n",
    "        Args:\n",
    "            source: ë¹„ë””ì˜¤ ì†ŒìŠ¤ (ì›¹ìº , íŒŒì¼, ìŠ¤íŠ¸ë¦¼)\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"âŒ ë¹„ë””ì˜¤ ì†ŒìŠ¤ ì—´ê¸° ì‹¤íŒ¨: {source}\")\n",
    "            return\n",
    "        \n",
    "        # í•´ìƒë„ ì„¤ì •\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_FPS, self.target_fps)\n",
    "        \n",
    "        print(f\"ğŸ“¹ ìº¡ì²˜ ì‹œì‘: {source}\")\n",
    "        frame_count = 0\n",
    "        last_frame_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"âš ï¸ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨\")\n",
    "                    break\n",
    "                \n",
    "                current_time = time.time()\n",
    "                \n",
    "                # FPS ì œì–´\n",
    "                if current_time - last_frame_time < self.frame_interval:\n",
    "                    continue\n",
    "                \n",
    "                # í•´ìƒë„ ë™ì  ì¡°ì ˆ\n",
    "                if self.adaptive_quality and self.current_quality != 1.0:\n",
    "                    h, w = frame.shape[:2]\n",
    "                    new_h, new_w = int(h * self.current_quality), int(w * self.current_quality)\n",
    "                    frame = cv2.resize(frame, (new_w, new_h))\n",
    "                \n",
    "                # í”„ë ˆì„ ë²„í¼ì— ì¶”ê°€\n",
    "                success = self.frame_buffer.put_frame(frame, current_time)\n",
    "                if not success:\n",
    "                    # í”„ë ˆì„ ë“œë¡­ ì‹œ í’ˆì§ˆ ì¡°ì ˆ\n",
    "                    if self.adaptive_quality:\n",
    "                        self.adjust_quality(decrease=True)\n",
    "                \n",
    "                last_frame_time = current_time\n",
    "                frame_count += 1\n",
    "                \n",
    "                # ì£¼ê¸°ì  ìƒíƒœ ì¶œë ¥\n",
    "                if frame_count % 100 == 0:\n",
    "                    stats = self.frame_buffer.get_stats()\n",
    "                    print(f\"ìº¡ì²˜ëœ í”„ë ˆì„: {frame_count}, ë“œë¡­ë¥ : {stats['drop_rate']:.3f}\")\n",
    "        \n",
    "        finally:\n",
    "            cap.release()\n",
    "            print(\"ğŸ“¹ ìº¡ì²˜ ì¢…ë£Œ\")\n",
    "    \n",
    "    def process_frames(self):\n",
    "        \"\"\"í”„ë ˆì„ ì²˜ë¦¬ ìŠ¤ë ˆë“œ\"\"\"\n",
    "        print(\"ğŸ”„ í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘\")\n",
    "        \n",
    "        while self.running:\n",
    "            frame_data = self.frame_buffer.get_frame(timeout=0.1)\n",
    "            if frame_data is None:\n",
    "                continue\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # YOLO ì¶”ë¡ \n",
    "                results = self.model(\n",
    "                    frame_data['frame'],\n",
    "                    device=self.device,\n",
    "                    conf=self.conf_threshold,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                # ê²°ê³¼ ì²˜ë¦¬\n",
    "                detections = []\n",
    "                annotated_frame = frame_data['frame'].copy()\n",
    "                \n",
    "                for result in results:\n",
    "                    # ì£¼ì„ì´ ì¶”ê°€ëœ í”„ë ˆì„\n",
    "                    annotated_frame = result.plot()\n",
    "                    \n",
    "                    # íƒì§€ ê²°ê³¼ ì¶”ì¶œ\n",
    "                    if result.boxes is not None:\n",
    "                        for box in result.boxes:\n",
    "                            cls_id = int(box.cls)\n",
    "                            confidence = float(box.conf)\n",
    "                            bbox = box.xyxy[0].cpu().numpy()\n",
    "                            class_name = self.model.names[cls_id]\n",
    "                            \n",
    "                            detections.append({\n",
    "                                'class_id': cls_id,\n",
    "                                'class_name': class_name,\n",
    "                                'confidence': confidence,\n",
    "                                'bbox': bbox.tolist(),\n",
    "                                'timestamp': frame_data['timestamp'],\n",
    "                                'frame_id': frame_data['frame_id']\n",
    "                            })\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥\n",
    "                result_data = {\n",
    "                    'frame': annotated_frame,\n",
    "                    'detections': detections,\n",
    "                    'processing_time': processing_time,\n",
    "                    'timestamp': frame_data['timestamp'],\n",
    "                    'frame_id': frame_data['frame_id']\n",
    "                }\n",
    "                \n",
    "                # ê²°ê³¼ íì— ì¶”ê°€\n",
    "                try:\n",
    "                    self.results_queue.put_nowait(result_data)\n",
    "                except queue.Full:\n",
    "                    # íê°€ ê°€ë“ ì°¬ ê²½ìš° ê°€ì¥ ì˜¤ë˜ëœ ê²°ê³¼ ì œê±°\n",
    "                    try:\n",
    "                        self.results_queue.get_nowait()\n",
    "                        self.results_queue.put_nowait(result_data)\n",
    "                    except queue.Empty:\n",
    "                        pass\n",
    "                \n",
    "                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸\n",
    "                self.performance_monitor.update(\n",
    "                    processing_time=processing_time,\n",
    "                    detection_count=len(detections),\n",
    "                    queue_size=self.results_queue.qsize()\n",
    "                )\n",
    "                \n",
    "                # íƒì§€ ì´ë ¥ ì €ì¥\n",
    "                self.detection_history.append({\n",
    "                    'timestamp': frame_data['timestamp'],\n",
    "                    'detection_count': len(detections),\n",
    "                    'processing_time': processing_time\n",
    "                })\n",
    "                \n",
    "                # ë™ì  í’ˆì§ˆ ì¡°ì ˆ\n",
    "                if self.adaptive_quality:\n",
    "                    target_processing_time = self.frame_interval * 0.8  # 80% ëª©í‘œ\n",
    "                    if processing_time > target_processing_time:\n",
    "                        self.adjust_quality(decrease=True)\n",
    "                    elif processing_time < target_processing_time * 0.5:\n",
    "                        self.adjust_quality(decrease=False)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(\"ğŸ”„ í”„ë ˆì„ ì²˜ë¦¬ ì¢…ë£Œ\")\n",
    "    \n",
    "    def adjust_quality(self, decrease: bool = True):\n",
    "        \"\"\"í’ˆì§ˆ ë™ì  ì¡°ì ˆ\n",
    "        \n",
    "        Args:\n",
    "            decrease: í’ˆì§ˆ ê°ì†Œ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        if decrease:\n",
    "            self.current_quality = max(0.5, self.current_quality - 0.1)\n",
    "            self.conf_threshold = min(0.5, self.conf_threshold + 0.05)\n",
    "        else:\n",
    "            self.current_quality = min(1.0, self.current_quality + 0.1)\n",
    "            self.conf_threshold = max(0.15, self.conf_threshold - 0.05)\n",
    "    \n",
    "    def display_results(self, show_window: bool = True):\n",
    "        \"\"\"ê²°ê³¼ í‘œì‹œ ìŠ¤ë ˆë“œ\n",
    "        \n",
    "        Args:\n",
    "            show_window: ìœˆë„ìš° í‘œì‹œ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        print(\"ğŸ–¥ï¸ ê²°ê³¼ í‘œì‹œ ì‹œì‘\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                result_data = self.results_queue.get(timeout=0.1)\n",
    "                \n",
    "                if show_window:\n",
    "                    # OpenCV ìœˆë„ìš°ì— í‘œì‹œ\n",
    "                    frame = result_data['frame']\n",
    "                    \n",
    "                    # ì„±ëŠ¥ ì •ë³´ ì˜¤ë²„ë ˆì´\n",
    "                    metrics = self.performance_monitor.get_metrics()\n",
    "                    info_text = [\n",
    "                        f\"FPS: {metrics.fps:.1f}\",\n",
    "                        f\"ì²˜ë¦¬ì‹œê°„: {result_data['processing_time']*1000:.1f}ms\",\n",
    "                        f\"íƒì§€ìˆ˜: {len(result_data['detections'])}\",\n",
    "                        f\"í’ˆì§ˆ: {self.current_quality:.1f}\"\n",
    "                    ]\n",
    "                    \n",
    "                    for i, text in enumerate(info_text):\n",
    "                        cv2.putText(frame, text, (10, 30 + i*25), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    \n",
    "                    cv2.imshow('Drone Crop Detection', frame)\n",
    "                    \n",
    "                    # ESC í‚¤ë¡œ ì¢…ë£Œ\n",
    "                    if cv2.waitKey(1) & 0xFF == 27:\n",
    "                        self.stop()\n",
    "                        break\n",
    "                \n",
    "                # ì£¼ê¸°ì  ì„±ëŠ¥ ë¡œê¹…\n",
    "                if result_data['frame_id'] % 30 == 0:\n",
    "                    self.performance_monitor.log_metrics()\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ í‘œì‹œ ì˜¤ë¥˜: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if show_window:\n",
    "            cv2.destroyAllWindows()\n",
    "        print(\"ğŸ–¥ï¸ ê²°ê³¼ í‘œì‹œ ì¢…ë£Œ\")\n",
    "    \n",
    "    def start(self, source, show_display: bool = True):\n",
    "        \"\"\"íŒŒì´í”„ë¼ì¸ ì‹œì‘\n",
    "        \n",
    "        Args:\n",
    "            source: ë¹„ë””ì˜¤ ì†ŒìŠ¤\n",
    "            show_display: í™”ë©´ í‘œì‹œ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        if self.running:\n",
    "            print(\"âš ï¸ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤\")\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        \n",
    "        # ìŠ¤ë ˆë“œ ì‹œì‘\n",
    "        self.capture_thread = threading.Thread(target=self.capture_frames, args=(source,))\n",
    "        self.process_thread = threading.Thread(target=self.process_frames)\n",
    "        self.display_thread = threading.Thread(target=self.display_results, args=(show_display,))\n",
    "        \n",
    "        self.capture_thread.start()\n",
    "        self.process_thread.start()\n",
    "        self.display_thread.start()\n",
    "        \n",
    "        print(\"ğŸš€ ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì‹œì‘\")\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"íŒŒì´í”„ë¼ì¸ ì¤‘ì§€\"\"\"\n",
    "        print(\"ğŸ›‘ íŒŒì´í”„ë¼ì¸ ì¤‘ì§€ ì¤‘...\")\n",
    "        self.running = False\n",
    "        \n",
    "        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°\n",
    "        if self.capture_thread:\n",
    "            self.capture_thread.join(timeout=2)\n",
    "        if self.process_thread:\n",
    "            self.process_thread.join(timeout=2)\n",
    "        if self.display_thread:\n",
    "            self.display_thread.join(timeout=2)\n",
    "        \n",
    "        print(\"âœ… íŒŒì´í”„ë¼ì¸ ì¤‘ì§€ ì™„ë£Œ\")\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"ì „ì²´ í†µê³„ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            stats: ì „ì²´ í†µê³„\n",
    "        \"\"\"\n",
    "        metrics = self.performance_monitor.get_metrics()\n",
    "        buffer_stats = self.frame_buffer.get_stats()\n",
    "        \n",
    "        # íƒì§€ ì´ë ¥ ë¶„ì„\n",
    "        detection_counts = [h['detection_count'] for h in self.detection_history]\n",
    "        processing_times = [h['processing_time'] for h in self.detection_history]\n",
    "        \n",
    "        return {\n",
    "            'performance': {\n",
    "                'current_fps': metrics.fps,\n",
    "                'target_fps': self.target_fps,\n",
    "                'avg_processing_time': metrics.processing_time,\n",
    "                'gpu_memory_used': metrics.gpu_memory_used\n",
    "            },\n",
    "            'buffer': buffer_stats,\n",
    "            'quality': {\n",
    "                'current_quality': self.current_quality,\n",
    "                'conf_threshold': self.conf_threshold,\n",
    "                'adaptive_enabled': self.adaptive_quality\n",
    "            },\n",
    "            'detection_stats': {\n",
    "                'total_frames_processed': len(self.detection_history),\n",
    "                'avg_detections_per_frame': np.mean(detection_counts) if detection_counts else 0,\n",
    "                'max_detections_per_frame': np.max(detection_counts) if detection_counts else 0,\n",
    "                'avg_processing_time': np.mean(processing_times) if processing_times else 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "# ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "pipeline = RealTimeVideoPipeline(\n",
    "    model_path='yolo11n.pt',\n",
    "    target_fps=15.0,  # ì½”ë© í™˜ê²½ì„ ê³ ë ¤í•œ ë‚®ì€ FPS\n",
    "    buffer_size=3\n",
    ")\n",
    "print(\"âœ… RealTimeVideoPipeline ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì›¹ìº  í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ìº  í…ŒìŠ¤íŠ¸ (ì½”ë©ì—ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜)\n",
    "def test_webcam_simulation():\n",
    "    \"\"\"ì›¹ìº  ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“· ì›¹ìº  ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸\\n\")\n",
    "    \n",
    "    # ê°€ìƒ ì›¹ìº  ì‹œë®¬ë ˆì´í„°\n",
    "    class VirtualWebcam:\n",
    "        def __init__(self, width=640, height=480, fps=15):\n",
    "            self.width = width\n",
    "            self.height = height\n",
    "            self.fps = fps\n",
    "            self.frame_count = 0\n",
    "            self.start_time = time.time()\n",
    "        \n",
    "        def read(self):\n",
    "            # ê°€ìƒ í”„ë ˆì„ ìƒì„± (ë†ì¥ ì‹œë®¬ë ˆì´ì…˜)\n",
    "            frame = np.random.randint(50, 200, (self.height, self.width, 3), dtype=np.uint8)\n",
    "            \n",
    "            # ê°€ìƒ ì‘ë¬¼ ëª¨ì–‘ ì¶”ê°€\n",
    "            for _ in range(np.random.randint(3, 8)):\n",
    "                x = np.random.randint(50, self.width-50)\n",
    "                y = np.random.randint(50, self.height-50)\n",
    "                size = np.random.randint(20, 60)\n",
    "                color = (0, np.random.randint(100, 255), 0)  # ë…¹ìƒ‰ ê³„ì—´\n",
    "                cv2.circle(frame, (x, y), size, color, -1)\n",
    "            \n",
    "            # íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ë²„ë ˆì´\n",
    "            elapsed = time.time() - self.start_time\n",
    "            cv2.putText(frame, f\"Frame: {self.frame_count}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Time: {elapsed:.1f}s\", (10, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            self.frame_count += 1\n",
    "            \n",
    "            # FPS ì œì–´\n",
    "            time.sleep(1.0 / self.fps)\n",
    "            \n",
    "            return True, frame\n",
    "        \n",
    "        def release(self):\n",
    "            pass\n",
    "    \n",
    "    # ê°€ìƒ ì›¹ìº ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "    virtual_cam = VirtualWebcam()\n",
    "    \n",
    "    print(\"ê°€ìƒ ì›¹ìº ìœ¼ë¡œ 10ì´ˆê°„ í…ŒìŠ¤íŠ¸...\")\n",
    "    \n",
    "    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë£¨í”„\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    \n",
    "    while time.time() - start_time < 10:  # 10ì´ˆê°„ í…ŒìŠ¤íŠ¸\n",
    "        ret, frame = virtual_cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # YOLO ì¶”ë¡  (ê°„ë‹¨í•œ ë²„ì „)\n",
    "        inference_start = time.time()\n",
    "        results = pipeline.model(frame, device=pipeline.device, verbose=False)\n",
    "        inference_time = time.time() - inference_start\n",
    "        \n",
    "        # ê²°ê³¼ ì²˜ë¦¬\n",
    "        detection_count = 0\n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                detection_count = len(result.boxes)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # ì£¼ê¸°ì  ì¶œë ¥\n",
    "        if frame_count % 30 == 0:\n",
    "            fps = frame_count / (time.time() - start_time)\n",
    "            print(f\"í”„ë ˆì„: {frame_count}, FPS: {fps:.1f}, \"\n",
    "                  f\"ì¶”ë¡ ì‹œê°„: {inference_time*1000:.1f}ms, íƒì§€ìˆ˜: {detection_count}\")\n",
    "    \n",
    "    final_fps = frame_count / (time.time() - start_time)\n",
    "    print(f\"\\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ: {frame_count}í”„ë ˆì„, í‰ê·  FPS: {final_fps:.2f}\")\n",
    "    \n",
    "    virtual_cam.release()\n",
    "\n",
    "# ì›¹ìº  ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰\n",
    "test_webcam_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "def test_video_file_processing():\n",
    "    \"\"\"ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\\n\")\n",
    "    \n",
    "    # ê°€ìƒ ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±\n",
    "    def create_virtual_video(filename='test_video.mp4', duration=5, fps=15):\n",
    "        \"\"\"ê°€ìƒ ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±\"\"\"\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(filename, fourcc, fps, (640, 480))\n",
    "        \n",
    "        total_frames = duration * fps\n",
    "        \n",
    "        for i in range(total_frames):\n",
    "            # ë†ì¥ ì¥ë©´ ì‹œë®¬ë ˆì´ì…˜\n",
    "            frame = np.random.randint(30, 150, (480, 640, 3), dtype=np.uint8)\n",
    "            \n",
    "            # ì›€ì§ì´ëŠ” ì‘ë¬¼ íŒ¨í„´\n",
    "            for j in range(5):\n",
    "                x = int(100 + 50 * np.sin(i * 0.1 + j))\n",
    "                y = int(100 + j * 60)\n",
    "                cv2.circle(frame, (x, y), 25, (0, 200, 0), -1)\n",
    "            \n",
    "            # í”„ë ˆì„ ì •ë³´\n",
    "            cv2.putText(frame, f\"Frame {i+1}/{total_frames}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            out.write(frame)\n",
    "        \n",
    "        out.release()\n",
    "        return filename\n",
    "    \n",
    "    # ê°€ìƒ ë¹„ë””ì˜¤ ìƒì„±\n",
    "    video_file = create_virtual_video('drone_test.mp4', duration=3, fps=10)\n",
    "    print(f\"ê°€ìƒ ë¹„ë””ì˜¤ ìƒì„±: {video_file}\")\n",
    "    \n",
    "    # ë¹„ë””ì˜¤ ì²˜ë¦¬ í´ë˜ìŠ¤\n",
    "    class VideoProcessor:\n",
    "        def __init__(self, model_path='yolo11n.pt'):\n",
    "            self.model = YOLO(model_path)\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        def process_video(self, input_path, output_path=None):\n",
    "            cap = cv2.VideoCapture(input_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {input_path}\")\n",
    "                return\n",
    "            \n",
    "            # ë¹„ë””ì˜¤ ì •ë³´\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            \n",
    "            print(f\"ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps}fps, {total_frames}í”„ë ˆì„\")\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥ìš© ë¹„ë””ì˜¤ ì‘ì„±ê¸°\n",
    "            if output_path:\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "            \n",
    "            # í†µê³„\n",
    "            processing_times = []\n",
    "            detection_counts = []\n",
    "            \n",
    "            frame_idx = 0\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # YOLO ì¶”ë¡ \n",
    "                start_time = time.time()\n",
    "                results = self.model(frame, device=self.device, verbose=False)\n",
    "                processing_time = time.time() - start_time\n",
    "                \n",
    "                # ê²°ê³¼ ì²˜ë¦¬\n",
    "                detection_count = 0\n",
    "                annotated_frame = frame.copy()\n",
    "                \n",
    "                for result in results:\n",
    "                    annotated_frame = result.plot()\n",
    "                    if result.boxes is not None:\n",
    "                        detection_count = len(result.boxes)\n",
    "                \n",
    "                # ì„±ëŠ¥ ì •ë³´ ì˜¤ë²„ë ˆì´\n",
    "                info_text = f\"Frame: {frame_idx+1}/{total_frames} | \"\n",
    "                info_text += f\"Time: {processing_time*1000:.1f}ms | \"\n",
    "                info_text += f\"Detections: {detection_count}\"\n",
    "                \n",
    "                cv2.putText(annotated_frame, info_text, (10, height-20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥\n",
    "                if output_path:\n",
    "                    out.write(annotated_frame)\n",
    "                \n",
    "                # í†µê³„ ìˆ˜ì§‘\n",
    "                processing_times.append(processing_time)\n",
    "                detection_counts.append(detection_count)\n",
    "                \n",
    "                frame_idx += 1\n",
    "                \n",
    "                # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "                if frame_idx % 10 == 0 or frame_idx == total_frames:\n",
    "                    progress = frame_idx / total_frames * 100\n",
    "                    avg_time = np.mean(processing_times[-10:])\n",
    "                    print(f\"ì§„í–‰ë¥ : {progress:.1f}% | í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_time*1000:.1f}ms\")\n",
    "            \n",
    "            # ì •ë¦¬\n",
    "            cap.release()\n",
    "            if output_path:\n",
    "                out.release()\n",
    "                print(f\"ê²°ê³¼ ì €ì¥: {output_path}\")\n",
    "            \n",
    "            # ìµœì¢… í†µê³„\n",
    "            avg_processing_time = np.mean(processing_times)\n",
    "            avg_detections = np.mean(detection_counts)\n",
    "            effective_fps = 1.0 / avg_processing_time\n",
    "            \n",
    "            print(f\"\\nğŸ“Š ì²˜ë¦¬ ì™„ë£Œ í†µê³„:\")\n",
    "            print(f\"   í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_processing_time*1000:.2f}ms\")\n",
    "            print(f\"   í‰ê·  íƒì§€ìˆ˜: {avg_detections:.1f}\")\n",
    "            print(f\"   íš¨ê³¼ì  FPS: {effective_fps:.1f}\")\n",
    "            print(f\"   ì´ í”„ë ˆì„: {frame_idx}\")\n",
    "            \n",
    "            return {\n",
    "                'total_frames': frame_idx,\n",
    "                'avg_processing_time': avg_processing_time,\n",
    "                'avg_detections': avg_detections,\n",
    "                'effective_fps': effective_fps\n",
    "            }\n",
    "    \n",
    "    # ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤í–‰\n",
    "    processor = VideoProcessor()\n",
    "    stats = processor.process_video(video_file, 'processed_drone_test.mp4')\n",
    "    \n",
    "    # íŒŒì¼ ì •ë¦¬\n",
    "    try:\n",
    "        os.remove(video_file)\n",
    "        print(f\"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {video_file}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "video_stats = test_video_file_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ìŠ¤íŠ¸ë¦¬ë° í’ˆì§ˆ ìµœì í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamOptimizer:\n",
    "    \"\"\"ìŠ¤íŠ¸ë¦¬ë° í’ˆì§ˆ ìµœì í™” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, target_fps: float = 15.0, target_latency: float = 0.1):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            target_fps: ëª©í‘œ FPS\n",
    "            target_latency: ëª©í‘œ ì§€ì—°ì‹œê°„ (ì´ˆ)\n",
    "        \"\"\"\n",
    "        self.target_fps = target_fps\n",
    "        self.target_latency = target_latency\n",
    "        self.target_frame_time = 1.0 / target_fps\n",
    "        \n",
    "        # ìµœì í™” íŒŒë¼ë¯¸í„°\n",
    "        self.quality_levels = {\n",
    "            'ultra': {'scale': 1.0, 'conf': 0.15, 'imgsz': 640},\n",
    "            'high': {'scale': 0.8, 'conf': 0.25, 'imgsz': 512},\n",
    "            'medium': {'scale': 0.6, 'conf': 0.35, 'imgsz': 416},\n",
    "            'low': {'scale': 0.4, 'conf': 0.45, 'imgsz': 320},\n",
    "            'potato': {'scale': 0.3, 'conf': 0.55, 'imgsz': 256}\n",
    "        }\n",
    "        \n",
    "        self.current_quality = 'medium'\n",
    "        self.performance_history = deque(maxlen=50)\n",
    "        \n",
    "        print(f\"ğŸ“ˆ StreamOptimizer ì´ˆê¸°í™”\")\n",
    "        print(f\"   ëª©í‘œ FPS: {target_fps}\")\n",
    "        print(f\"   ëª©í‘œ ì§€ì—°ì‹œê°„: {target_latency}ì´ˆ\")\n",
    "    \n",
    "    def update_performance(self, processing_time: float, detection_count: int):\n",
    "        \"\"\"ì„±ëŠ¥ ì—…ë°ì´íŠ¸\n",
    "        \n",
    "        Args:\n",
    "            processing_time: ì²˜ë¦¬ ì‹œê°„\n",
    "            detection_count: íƒì§€ ê°œìˆ˜\n",
    "        \"\"\"\n",
    "        self.performance_history.append({\n",
    "            'processing_time': processing_time,\n",
    "            'detection_count': detection_count,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "    \n",
    "    def get_optimal_quality(self) -> str:\n",
    "        \"\"\"ìµœì  í’ˆì§ˆ ë ˆë²¨ ê²°ì •\n",
    "        \n",
    "        Returns:\n",
    "            quality_level: í’ˆì§ˆ ë ˆë²¨\n",
    "        \"\"\"\n",
    "        if len(self.performance_history) < 10:\n",
    "            return self.current_quality\n",
    "        \n",
    "        # ìµœê·¼ ì„±ëŠ¥ ë¶„ì„\n",
    "        recent_times = [p['processing_time'] for p in list(self.performance_history)[-10:]]\n",
    "        avg_processing_time = np.mean(recent_times)\n",
    "        max_processing_time = np.max(recent_times)\n",
    "        \n",
    "        # í˜„ì¬ í’ˆì§ˆ ë ˆë²¨ ì¸ë±ìŠ¤\n",
    "        quality_names = list(self.quality_levels.keys())\n",
    "        current_idx = quality_names.index(self.current_quality)\n",
    "        \n",
    "        # í’ˆì§ˆ ì¡°ì • ê²°ì •\n",
    "        if avg_processing_time > self.target_frame_time * 0.8:  # 80% ì„ê³„ê°’\n",
    "            # í’ˆì§ˆ ë‚®ì¶”ê¸°\n",
    "            if current_idx < len(quality_names) - 1:\n",
    "                new_quality = quality_names[current_idx + 1]\n",
    "                print(f\"í’ˆì§ˆ ë‚®ì¶¤: {self.current_quality} â†’ {new_quality}\")\n",
    "                self.current_quality = new_quality\n",
    "        elif avg_processing_time < self.target_frame_time * 0.4:  # 40% ì„ê³„ê°’\n",
    "            # í’ˆì§ˆ ë†’ì´ê¸°\n",
    "            if current_idx > 0:\n",
    "                new_quality = quality_names[current_idx - 1]\n",
    "                print(f\"í’ˆì§ˆ ë†’ì„: {self.current_quality} â†’ {new_quality}\")\n",
    "                self.current_quality = new_quality\n",
    "        \n",
    "        return self.current_quality\n",
    "    \n",
    "    def get_quality_settings(self, quality_level: str = None) -> Dict:\n",
    "        \"\"\"í’ˆì§ˆ ì„¤ì • ë°˜í™˜\n",
    "        \n",
    "        Args:\n",
    "            quality_level: í’ˆì§ˆ ë ˆë²¨\n",
    "            \n",
    "        Returns:\n",
    "            settings: í’ˆì§ˆ ì„¤ì •\n",
    "        \"\"\"\n",
    "        if quality_level is None:\n",
    "            quality_level = self.current_quality\n",
    "        \n",
    "        return self.quality_levels.get(quality_level, self.quality_levels['medium'])\n",
    "    \n",
    "    def benchmark_quality_levels(self, model, test_frame: np.ndarray) -> Dict:\n",
    "        \"\"\"í’ˆì§ˆ ë ˆë²¨ë³„ ë²¤ì¹˜ë§ˆí¬\n",
    "        \n",
    "        Args:\n",
    "            model: YOLO ëª¨ë¸\n",
    "            test_frame: í…ŒìŠ¤íŠ¸ í”„ë ˆì„\n",
    "            \n",
    "        Returns:\n",
    "            benchmark_results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        print(\"ğŸ” í’ˆì§ˆ ë ˆë²¨ë³„ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for quality_name, settings in self.quality_levels.items():\n",
    "            # í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "            h, w = test_frame.shape[:2]\n",
    "            new_h, new_w = int(h * settings['scale']), int(w * settings['scale'])\n",
    "            resized_frame = cv2.resize(test_frame, (new_w, new_h))\n",
    "            \n",
    "            # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\n",
    "            times = []\n",
    "            detection_counts = []\n",
    "            \n",
    "            for _ in range(5):  # 5íšŒ í‰ê· \n",
    "                start_time = time.time()\n",
    "                \n",
    "                results_yolo = model(\n",
    "                    resized_frame,\n",
    "                    conf=settings['conf'],\n",
    "                    imgsz=settings['imgsz'],\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                times.append(processing_time)\n",
    "                \n",
    "                # íƒì§€ ê°œìˆ˜\n",
    "                detection_count = 0\n",
    "                for result in results_yolo:\n",
    "                    if result.boxes is not None:\n",
    "                        detection_count = len(result.boxes)\n",
    "                detection_counts.append(detection_count)\n",
    "            \n",
    "            # í†µê³„ ê³„ì‚°\n",
    "            avg_time = np.mean(times)\n",
    "            fps = 1.0 / avg_time\n",
    "            avg_detections = np.mean(detection_counts)\n",
    "            \n",
    "            results[quality_name] = {\n",
    "                'avg_processing_time': avg_time,\n",
    "                'fps': fps,\n",
    "                'avg_detections': avg_detections,\n",
    "                'settings': settings,\n",
    "                'meets_target': fps >= self.target_fps\n",
    "            }\n",
    "            \n",
    "            print(f\"  {quality_name:8s}: {avg_time*1000:5.1f}ms | {fps:5.1f}fps | {avg_detections:4.1f}íƒì§€\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ìµœì í™” í…ŒìŠ¤íŠ¸\n",
    "def test_stream_optimization():\n",
    "    \"\"\"ìŠ¤íŠ¸ë¦¼ ìµœì í™” í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"âš¡ ìŠ¤íŠ¸ë¦¼ ìµœì í™” í…ŒìŠ¤íŠ¸\\n\")\n",
    "    \n",
    "    # ìµœì í™” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    optimizer = StreamOptimizer(target_fps=15.0)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ìƒì„±\n",
    "    test_frame = np.random.randint(0, 255, (720, 1280, 3), dtype=np.uint8)\n",
    "    \n",
    "    # ê°€ìƒ ì‘ë¬¼ ì¶”ê°€\n",
    "    for _ in range(10):\n",
    "        x = np.random.randint(100, 1180)\n",
    "        y = np.random.randint(100, 620)\n",
    "        size = np.random.randint(20, 50)\n",
    "        cv2.circle(test_frame, (x, y), size, (0, 200, 0), -1)\n",
    "    \n",
    "    # YOLO ëª¨ë¸ ë¡œë“œ\n",
    "    model = YOLO('yolo11n.pt')\n",
    "    \n",
    "    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\n",
    "    benchmark_results = optimizer.benchmark_quality_levels(model, test_frame)\n",
    "    \n",
    "    # ìµœì  í’ˆì§ˆ ì¶”ì²œ\n",
    "    print(\"\\nğŸ¯ í’ˆì§ˆ ë ˆë²¨ ë¶„ì„:\")\n",
    "    \n",
    "    suitable_qualities = []\n",
    "    for quality, result in benchmark_results.items():\n",
    "        status = \"âœ…\" if result['meets_target'] else \"âŒ\"\n",
    "        efficiency = result['avg_detections'] / result['avg_processing_time']\n",
    "        \n",
    "        print(f\"{status} {quality:8s}: FPS {result['fps']:5.1f} | íš¨ìœ¨ì„± {efficiency:6.1f}\")\n",
    "        \n",
    "        if result['meets_target']:\n",
    "            suitable_qualities.append((quality, result, efficiency))\n",
    "    \n",
    "    # ê°€ì¥ íš¨ìœ¨ì ì¸ í’ˆì§ˆ ì„ íƒ\n",
    "    if suitable_qualities:\n",
    "        best_quality = max(suitable_qualities, key=lambda x: x[2])\n",
    "        print(f\"\\nğŸ† ì¶”ì²œ í’ˆì§ˆ: {best_quality[0]} (íš¨ìœ¨ì„±: {best_quality[2]:.1f})\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ëª©í‘œ FPSë¥¼ ë§Œì¡±í•˜ëŠ” í’ˆì§ˆì´ ì—†ìŠµë‹ˆë‹¤. í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ í•„ìš”\")\n",
    "    \n",
    "    return benchmark_results\n",
    "\n",
    "# ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "optimization_results = test_stream_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_integration_test():\n",
    "    \"\"\"ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ¯ Todo 4 ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸\\n\")\n",
    "    \n",
    "    # 1. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸\n",
    "    print(\"âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:\")\n",
    "    perf_monitor = PerformanceMonitor()\n",
    "    \n",
    "    # ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
    "    for i in range(10):\n",
    "        processing_time = np.random.uniform(0.02, 0.08)\n",
    "        detection_count = np.random.randint(1, 10)\n",
    "        perf_monitor.update(processing_time, detection_count)\n",
    "        time.sleep(0.01)\n",
    "    \n",
    "    metrics = perf_monitor.get_metrics()\n",
    "    print(f\"   í‰ê·  FPS: {metrics.fps:.2f}\")\n",
    "    print(f\"   í‰ê·  ì²˜ë¦¬ì‹œê°„: {metrics.processing_time*1000:.1f}ms\")\n",
    "    print(f\"   í‰ê·  íƒì§€ìˆ˜: {metrics.detection_count}\")\n",
    "    \n",
    "    # 2. í”„ë ˆì„ ë²„í¼ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nâœ… í”„ë ˆì„ ë²„í¼:\")\n",
    "    buffer = FrameBuffer(max_size=5)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì¶”ê°€\n",
    "    for i in range(8):  # ë²„í¼ í¬ê¸°ë³´ë‹¤ ë§ì´ ì¶”ê°€\n",
    "        test_frame = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)\n",
    "        success = buffer.put_frame(test_frame)\n",
    "        if not success:\n",
    "            print(f\"   í”„ë ˆì„ {i+1} ë“œë¡­ë¨\")\n",
    "    \n",
    "    stats = buffer.get_stats()\n",
    "    print(f\"   ë²„í¼ ìƒíƒœ: {stats['queue_size']}/{stats['max_size']}\")\n",
    "    print(f\"   ë“œë¡­ë¥ : {stats['drop_rate']:.3f}\")\n",
    "    \n",
    "    # 3. ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nâœ… ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸:\")\n",
    "    pipeline = RealTimeVideoPipeline(\n",
    "        model_path='yolo11n.pt',\n",
    "        target_fps=10.0,\n",
    "        buffer_size=3\n",
    "    )\n",
    "    \n",
    "    # ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "    test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = pipeline.model(test_frame, device=pipeline.device, verbose=False)\n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    detection_count = 0\n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            detection_count = len(result.boxes)\n",
    "    \n",
    "    print(f\"   ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ì‹œê°„: {processing_time*1000:.1f}ms\")\n",
    "    print(f\"   íƒì§€ëœ ê°ì²´ ìˆ˜: {detection_count}\")\n",
    "    print(f\"   ì‹¤íš¨ FPS: {1/processing_time:.1f}\")\n",
    "    \n",
    "    # 4. ìŠ¤íŠ¸ë¦¼ ìµœì í™” í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nâœ… ìŠ¤íŠ¸ë¦¼ ìµœì í™”:\")\n",
    "    optimizer = StreamOptimizer(target_fps=15.0)\n",
    "    \n",
    "    # ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜\n",
    "    for _ in range(20):\n",
    "        sim_time = np.random.uniform(0.03, 0.12)\n",
    "        sim_detections = np.random.randint(1, 8)\n",
    "        optimizer.update_performance(sim_time, sim_detections)\n",
    "    \n",
    "    optimal_quality = optimizer.get_optimal_quality()\n",
    "    quality_settings = optimizer.get_quality_settings(optimal_quality)\n",
    "    \n",
    "    print(f\"   ìµœì  í’ˆì§ˆ ë ˆë²¨: {optimal_quality}\")\n",
    "    print(f\"   ìŠ¤ì¼€ì¼: {quality_settings['scale']}\")\n",
    "    print(f\"   ì‹ ë¢°ë„ ì„ê³„ê°’: {quality_settings['conf']}\")\n",
    "    print(f\"   ì´ë¯¸ì§€ í¬ê¸°: {quality_settings['imgsz']}\")\n",
    "    \n",
    "    # 5. ì¢…í•© ì„±ëŠ¥ í‰ê°€\n",
    "    print(\"\\nğŸ“Š ì¢…í•© ì„±ëŠ¥ í‰ê°€:\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ í™•ì¸\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "        max_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"   GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {gpu_memory:.2f}GB / {max_memory:.1f}GB ({gpu_memory/max_memory*100:.1f}%)\")\n",
    "    \n",
    "    # ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ì„± í‰ê°€\n",
    "    target_frame_time = 1.0 / 15.0  # 15 FPS ëª©í‘œ\n",
    "    processing_margin = (target_frame_time - processing_time) / target_frame_time * 100\n",
    "    \n",
    "    print(f\"   ëª©í‘œ í”„ë ˆì„ ì‹œê°„: {target_frame_time*1000:.1f}ms\")\n",
    "    print(f\"   ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„: {processing_time*1000:.1f}ms\")\n",
    "    print(f\"   ì„±ëŠ¥ ì—¬ìœ ë„: {processing_margin:.1f}%\")\n",
    "    \n",
    "    if processing_margin > 20:\n",
    "        print(\"   ğŸŸ¢ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (ì—¬ìœ ë„ ì¶©ë¶„)\")\n",
    "    elif processing_margin > 0:\n",
    "        print(\"   ğŸŸ¡ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (ìµœì í™” ê¶Œì¥)\")\n",
    "    else:\n",
    "        print(\"   ğŸ”´ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì–´ë ¤ì›€ (í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ ë˜ëŠ” í’ˆì§ˆ ì¡°ì • í•„ìš”)\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ Todo 4 ì™„ë£Œ!\")\n",
    "    print(\"\\nğŸ“‹ êµ¬í˜„ëœ ê¸°ëŠ¥:\")\n",
    "    print(\"   âœ… ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "    print(\"   âœ… í”„ë ˆì„ ë²„í¼ ë° í ê´€ë¦¬\")\n",
    "    print(\"   âœ… ë©€í‹°ìŠ¤ë ˆë“œ ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\")\n",
    "    print(\"   âœ… ë™ì  í’ˆì§ˆ ì¡°ì ˆ\")\n",
    "    print(\"   âœ… ìŠ¤íŠ¸ë¦¼ ìµœì í™”\")\n",
    "    print(\"   âœ… ì›¹ìº  ë° ë¹„ë””ì˜¤ íŒŒì¼ ì§€ì›\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "    print(\"   - Todo 9: ì„±ëŠ¥ ìµœì í™” ë° GPU ê°€ì† ì„¤ì •\")\n",
    "    print(\"   - Todo 10: ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„\")\n",
    "    \n",
    "    return {\n",
    "        'performance_monitor': metrics,\n",
    "        'buffer_stats': stats,\n",
    "        'processing_time': processing_time,\n",
    "        'detection_count': detection_count,\n",
    "        'optimal_quality': optimal_quality,\n",
    "        'performance_margin': processing_margin\n",
    "    }\n",
    "\n",
    "# ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "integration_results = final_integration_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Todo 4 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "\n",
    "1. **ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**\n",
    "   - [x] PerformanceMetrics ë°ì´í„° í´ë˜ìŠ¤\n",
    "   - [x] PerformanceMonitor í´ë˜ìŠ¤ (FPS, ì²˜ë¦¬ì‹œê°„, GPU ë©”ëª¨ë¦¬ ì¶”ì )\n",
    "   - [x] ì´ë™ í‰ê·  ê¸°ë°˜ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§\n",
    "   - [x] ë¡œê¹… ì‹œìŠ¤í…œ í†µí•©\n",
    "\n",
    "2. **í”„ë ˆì„ ë²„í¼ ë° í ê´€ë¦¬**\n",
    "   - [x] FrameBuffer í´ë˜ìŠ¤ (ë©€í‹°ìŠ¤ë ˆë“œ ì•ˆì „)\n",
    "   - [x] í”„ë ˆì„ ë“œë¡­ ì •ì±… (oldest/newest)\n",
    "   - [x] í í†µê³„ ë° ëª¨ë‹ˆí„°ë§\n",
    "   - [x] ìŠ¤ë ˆë“œ ë™ê¸°í™”\n",
    "\n",
    "3. **ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**\n",
    "   - [x] RealTimeVideoPipeline í´ë˜ìŠ¤\n",
    "   - [x] ë©€í‹°ìŠ¤ë ˆë“œ ì•„í‚¤í…ì²˜ (ìº¡ì²˜/ì²˜ë¦¬/í‘œì‹œ)\n",
    "   - [x] ì›¹ìº  ë° ë¹„ë””ì˜¤ íŒŒì¼ ì§€ì›\n",
    "   - [x] ì‹¤ì‹œê°„ ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "4. **ë™ì  í’ˆì§ˆ ì¡°ì ˆ**\n",
    "   - [x] í•´ìƒë„ ìë™ ì¡°ì ˆ\n",
    "   - [x] ì‹ ë¢°ë„ ì„ê³„ê°’ ë™ì  ë³€ê²½\n",
    "   - [x] FPS ê¸°ë°˜ ì ì‘í˜• ì²˜ë¦¬\n",
    "   - [x] í”„ë ˆì„ ë“œë¡­ ì‹œ í’ˆì§ˆ ê°ì†Œ\n",
    "\n",
    "5. **ìŠ¤íŠ¸ë¦¼ ìµœì í™”**\n",
    "   - [x] StreamOptimizer í´ë˜ìŠ¤\n",
    "   - [x] 5ë‹¨ê³„ í’ˆì§ˆ ë ˆë²¨ (ultra~potato)\n",
    "   - [x] í’ˆì§ˆ ë ˆë²¨ë³„ ë²¤ì¹˜ë§ˆí‚¹\n",
    "   - [x] íš¨ìœ¨ì„± ê¸°ë°˜ ìµœì í™”\n",
    "\n",
    "6. **í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**\n",
    "   - [x] ì›¹ìº  ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸\n",
    "   - [x] ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "   - [x] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n",
    "   - [x] í†µí•© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### ğŸš€ ì£¼ìš” ì„±ê³¼\n",
    "- ë©€í‹°ìŠ¤ë ˆë“œ ê¸°ë°˜ ì‹¤ì‹œê°„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
    "- ë™ì  í’ˆì§ˆ ì¡°ì ˆë¡œ ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ í™˜ê²½ ì§€ì›\n",
    "- ì²´ê³„ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ì‹œìŠ¤í…œ\n",
    "- í”„ë ˆì„ ë“œë¡­ ë°©ì§€ ë° ì§€ì—°ì‹œê°„ ìµœì†Œí™”\n",
    "- ì½”ë©ê³¼ ë¡œì»¬ í™˜ê²½ ëª¨ë‘ ì§€ì›\n",
    "\n",
    "### ğŸ”§ êµ¬í˜„ëœ í´ë˜ìŠ¤\n",
    "- `PerformanceMonitor`: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì \n",
    "- `FrameBuffer`: ìŠ¤ë ˆë“œ ì•ˆì „ í”„ë ˆì„ í\n",
    "- `RealTimeVideoPipeline`: í†µí•© ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "- `StreamOptimizer`: í’ˆì§ˆ ìµœì í™” ê´€ë¦¬\n",
    "\n",
    "### ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•\n",
    "- ëª©í‘œ FPS ë‹¬ì„±ì„ ìœ„í•œ ìë™ í’ˆì§ˆ ì¡°ì ˆ\n",
    "- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§\n",
    "- í”„ë ˆì„ ë“œë¡­ë¥  ì¶”ì  ë° ìµœì†Œí™”\n",
    "- ì‹¤ì‹œê°„ íƒì§€ ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "ì´ì œ Todo 9 (ì„±ëŠ¥ ìµœì í™”)ì™€ Todo 10 (ì—ëŸ¬ ì²˜ë¦¬)ì„ êµ¬í˜„í•  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}