{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "\n",
    "**ëª©ì **: ì•ˆì •ì ì´ê³  ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ë“œë¡  ì‘ë¬¼ íƒì§€ ì‹œìŠ¤í…œ  \n",
    "**ë‹´ë‹¹**: Claude Sonnet 4  \n",
    "**ë‚ ì§œ**: 2025-10-21\n",
    "\n",
    "## ğŸ“‹ ì‘ì—… ë‚´ìš©\n",
    "1. í¬ê´„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ\n",
    "2. êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ\n",
    "3. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼\n",
    "4. ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜\n",
    "5. ë””ë²„ê¹… ë° ì§„ë‹¨ ë„êµ¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import logging.handlers\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import queue\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Callable\n",
    "from dataclasses import dataclass, asdict\n",
    "from collections import deque\n",
    "from enum import Enum\n",
    "import datetime\n",
    "import functools\n",
    "import warnings\n",
    "import signal\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ê²½ê³  ì„¤ì •\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(f\"Python ë²„ì „: {sys.version}\")\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"OpenCV ë²„ì „: {cv2.__version__}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì—ëŸ¬ íƒ€ì… ë° ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorSeverity(Enum):\n",
    "    \"\"\"ì—ëŸ¬ ì‹¬ê°ë„ ë ˆë²¨\"\"\"\n",
    "    LOW = \"LOW\"           # ê²½ê³ , ìë™ ë³µêµ¬ ê°€ëŠ¥\n",
    "    MEDIUM = \"MEDIUM\"     # ì£¼ì˜, ìˆ˜ë™ ê°œì… ê¶Œì¥\n",
    "    HIGH = \"HIGH\"         # ì‹¬ê°, ì¦‰ì‹œ ê°œì… í•„ìš”\n",
    "    CRITICAL = \"CRITICAL\" # ì¹˜ëª…ì , ì‹œìŠ¤í…œ ì¤‘ë‹¨\n",
    "\n",
    "class ErrorCategory(Enum):\n",
    "    \"\"\"ì—ëŸ¬ ì¹´í…Œê³ ë¦¬\"\"\"\n",
    "    MODEL = \"MODEL\"                 # ëª¨ë¸ ê´€ë ¨ ì—ëŸ¬\n",
    "    INPUT = \"INPUT\"                 # ì…ë ¥ ë°ì´í„° ì—ëŸ¬\n",
    "    GPU = \"GPU\"                     # GPU/ë©”ëª¨ë¦¬ ì—ëŸ¬\n",
    "    NETWORK = \"NETWORK\"             # ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬\n",
    "    FILE_IO = \"FILE_IO\"             # íŒŒì¼ ì…ì¶œë ¥ ì—ëŸ¬\n",
    "    CONFIGURATION = \"CONFIGURATION\" # ì„¤ì • ì—ëŸ¬\n",
    "    SYSTEM = \"SYSTEM\"               # ì‹œìŠ¤í…œ ì—ëŸ¬\n",
    "    UNKNOWN = \"UNKNOWN\"             # ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬\n",
    "\n",
    "@dataclass\n",
    "class ErrorInfo:\n",
    "    \"\"\"ì—ëŸ¬ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    timestamp: float\n",
    "    error_id: str\n",
    "    category: ErrorCategory\n",
    "    severity: ErrorSeverity\n",
    "    message: str\n",
    "    traceback_str: str\n",
    "    context: Dict[str, Any]\n",
    "    recovery_attempted: bool = False\n",
    "    recovery_successful: bool = False\n",
    "    recovery_method: Optional[str] = None\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤\n",
    "class DroneDetectionError(Exception):\n",
    "    \"\"\"ë“œë¡  íƒì§€ ì‹œìŠ¤í…œ ê¸°ë³¸ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, category: ErrorCategory = ErrorCategory.UNKNOWN, \n",
    "                 severity: ErrorSeverity = ErrorSeverity.MEDIUM, context: Dict = None):\n",
    "        super().__init__(message)\n",
    "        self.category = category\n",
    "        self.severity = severity\n",
    "        self.context = context or {}\n",
    "        self.timestamp = time.time()\n",
    "\n",
    "class ModelError(DroneDetectionError):\n",
    "    \"\"\"ëª¨ë¸ ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, severity: ErrorSeverity = ErrorSeverity.HIGH, context: Dict = None):\n",
    "        super().__init__(message, ErrorCategory.MODEL, severity, context)\n",
    "\n",
    "class InputError(DroneDetectionError):\n",
    "    \"\"\"ì…ë ¥ ë°ì´í„° ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, severity: ErrorSeverity = ErrorSeverity.LOW, context: Dict = None):\n",
    "        super().__init__(message, ErrorCategory.INPUT, severity, context)\n",
    "\n",
    "class GPUError(DroneDetectionError):\n",
    "    \"\"\"GPU/ë©”ëª¨ë¦¬ ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, severity: ErrorSeverity = ErrorSeverity.HIGH, context: Dict = None):\n",
    "        super().__init__(message, ErrorCategory.GPU, severity, context)\n",
    "\n",
    "class NetworkError(DroneDetectionError):\n",
    "    \"\"\"ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, severity: ErrorSeverity = ErrorSeverity.MEDIUM, context: Dict = None):\n",
    "        super().__init__(message, ErrorCategory.NETWORK, severity, context)\n",
    "\n",
    "class FileIOError(DroneDetectionError):\n",
    "    \"\"\"íŒŒì¼ ì…ì¶œë ¥ ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, severity: ErrorSeverity = ErrorSeverity.MEDIUM, context: Dict = None):\n",
    "        super().__init__(message, ErrorCategory.FILE_IO, severity, context)\n",
    "\n",
    "class ConfigurationError(DroneDetectionError):\n",
    "    \"\"\"ì„¤ì • ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    def __init__(self, message: str, severity: ErrorSeverity = ErrorSeverity.HIGH, context: Dict = None):\n",
    "        super().__init__(message, ErrorCategory.CONFIGURATION, severity, context)\n",
    "\n",
    "print(\"âœ… ì—ëŸ¬ íƒ€ì… ë° ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ê³ ê¸‰ ë¡œê¹… ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredLogger:\n",
    "    \"\"\"êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 name: str = \"DroneDetection\",\n",
    "                 log_dir: str = \"logs\",\n",
    "                 max_file_size: int = 10*1024*1024,  # 10MB\n",
    "                 backup_count: int = 5,\n",
    "                 enable_console: bool = True):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            name: ë¡œê±° ì´ë¦„\n",
    "            log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬\n",
    "            max_file_size: ìµœëŒ€ íŒŒì¼ í¬ê¸°\n",
    "            backup_count: ë°±ì—… íŒŒì¼ ìˆ˜\n",
    "            enable_console: ì½˜ì†” ì¶œë ¥ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # ë¡œê±° ìƒì„±\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        \n",
    "        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°\n",
    "        for handler in self.logger.handlers[:]:\n",
    "            self.logger.removeHandler(handler)\n",
    "        \n",
    "        # í¬ë§¤í„° ì •ì˜\n",
    "        self.formatter = logging.Formatter(\n",
    "            '%(asctime)s | %(levelname)-8s | %(name)s | %(funcName)s:%(lineno)d | %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "        \n",
    "        # JSON í¬ë§¤í„° (êµ¬ì¡°í™”ëœ ë¡œê·¸ìš©)\n",
    "        self.json_formatter = self._create_json_formatter()\n",
    "        \n",
    "        # íŒŒì¼ í•¸ë“¤ëŸ¬ ì„¤ì •\n",
    "        self._setup_file_handlers(max_file_size, backup_count)\n",
    "        \n",
    "        # ì½˜ì†” í•¸ë“¤ëŸ¬ ì„¤ì •\n",
    "        if enable_console:\n",
    "            self._setup_console_handler()\n",
    "        \n",
    "        # ë©”íŠ¸ë¦­ ì¶”ì \n",
    "        self.log_counts = {\n",
    "            'DEBUG': 0, 'INFO': 0, 'WARNING': 0, 'ERROR': 0, 'CRITICAL': 0\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ“ StructuredLogger ì´ˆê¸°í™” ì™„ë£Œ: {name}\")\n",
    "        print(f\"   ë¡œê·¸ ë””ë ‰í† ë¦¬: {self.log_dir}\")\n",
    "    \n",
    "    def _create_json_formatter(self):\n",
    "        \"\"\"JSON í¬ë§¤í„° ìƒì„±\"\"\"\n",
    "        class JSONFormatter(logging.Formatter):\n",
    "            def format(self, record):\n",
    "                log_data = {\n",
    "                    'timestamp': datetime.datetime.fromtimestamp(record.created).isoformat(),\n",
    "                    'level': record.levelname,\n",
    "                    'logger': record.name,\n",
    "                    'module': record.module,\n",
    "                    'function': record.funcName,\n",
    "                    'line': record.lineno,\n",
    "                    'message': record.getMessage(),\n",
    "                    'thread': record.thread,\n",
    "                    'process': record.process\n",
    "                }\n",
    "                \n",
    "                # ì¶”ê°€ ì†ì„± í¬í•¨\n",
    "                if hasattr(record, 'extra_data'):\n",
    "                    log_data['extra'] = record.extra_data\n",
    "                \n",
    "                if record.exc_info:\n",
    "                    log_data['exception'] = self.formatException(record.exc_info)\n",
    "                \n",
    "                return json.dumps(log_data, ensure_ascii=False)\n",
    "        \n",
    "        return JSONFormatter()\n",
    "    \n",
    "    def _setup_file_handlers(self, max_file_size: int, backup_count: int):\n",
    "        \"\"\"íŒŒì¼ í•¸ë“¤ëŸ¬ ì„¤ì •\"\"\"\n",
    "        # ì¼ë°˜ ë¡œê·¸ íŒŒì¼\n",
    "        log_file = self.log_dir / f\"{self.name}.log\"\n",
    "        file_handler = logging.handlers.RotatingFileHandler(\n",
    "            log_file, maxBytes=max_file_size, backupCount=backup_count\n",
    "        )\n",
    "        file_handler.setLevel(logging.DEBUG)\n",
    "        file_handler.setFormatter(self.formatter)\n",
    "        self.logger.addHandler(file_handler)\n",
    "        \n",
    "        # ì—ëŸ¬ ì „ìš© ë¡œê·¸ íŒŒì¼\n",
    "        error_file = self.log_dir / f\"{self.name}_errors.log\"\n",
    "        error_handler = logging.handlers.RotatingFileHandler(\n",
    "            error_file, maxBytes=max_file_size, backupCount=backup_count\n",
    "        )\n",
    "        error_handler.setLevel(logging.ERROR)\n",
    "        error_handler.setFormatter(self.formatter)\n",
    "        self.logger.addHandler(error_handler)\n",
    "        \n",
    "        # JSON ë¡œê·¸ íŒŒì¼ (êµ¬ì¡°í™”ëœ ë°ì´í„°)\n",
    "        json_file = self.log_dir / f\"{self.name}_structured.jsonl\"\n",
    "        json_handler = logging.handlers.RotatingFileHandler(\n",
    "            json_file, maxBytes=max_file_size, backupCount=backup_count\n",
    "        )\n",
    "        json_handler.setLevel(logging.INFO)\n",
    "        json_handler.setFormatter(self.json_formatter)\n",
    "        self.logger.addHandler(json_handler)\n",
    "    \n",
    "    def _setup_console_handler(self):\n",
    "        \"\"\"ì½˜ì†” í•¸ë“¤ëŸ¬ ì„¤ì •\"\"\"\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setLevel(logging.INFO)\n",
    "        \n",
    "        # ì½˜ì†”ìš© ì»¬ëŸ¬ í¬ë§¤í„°\n",
    "        class ColoredFormatter(logging.Formatter):\n",
    "            COLORS = {\n",
    "                'DEBUG': '\\033[36m',    # ì²­ë¡ìƒ‰\n",
    "                'INFO': '\\033[32m',     # ë…¹ìƒ‰\n",
    "                'WARNING': '\\033[33m',  # ë…¸ë€ìƒ‰\n",
    "                'ERROR': '\\033[31m',    # ë¹¨ê°„ìƒ‰\n",
    "                'CRITICAL': '\\033[35m', # ìì£¼ìƒ‰\n",
    "                'RESET': '\\033[0m'      # ë¦¬ì…‹\n",
    "            }\n",
    "            \n",
    "            def format(self, record):\n",
    "                color = self.COLORS.get(record.levelname, self.COLORS['RESET'])\n",
    "                reset = self.COLORS['RESET']\n",
    "                record.levelname = f\"{color}{record.levelname}{reset}\"\n",
    "                return super().format(record)\n",
    "        \n",
    "        colored_formatter = ColoredFormatter(\n",
    "            '%(asctime)s | %(levelname)s | %(name)s | %(message)s',\n",
    "            datefmt='%H:%M:%S'\n",
    "        )\n",
    "        console_handler.setFormatter(colored_formatter)\n",
    "        self.logger.addHandler(console_handler)\n",
    "    \n",
    "    def log_with_context(self, level: str, message: str, **context):\n",
    "        \"\"\"ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë¡œê·¸ ê¸°ë¡\n",
    "        \n",
    "        Args:\n",
    "            level: ë¡œê·¸ ë ˆë²¨\n",
    "            message: ë¡œê·¸ ë©”ì‹œì§€\n",
    "            **context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´\n",
    "        \"\"\"\n",
    "        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸\n",
    "        if level.upper() in self.log_counts:\n",
    "            self.log_counts[level.upper()] += 1\n",
    "        \n",
    "        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´\n",
    "        context.update({\n",
    "            'system_time': time.time(),\n",
    "            'memory_usage': psutil.virtual_memory().percent,\n",
    "            'cpu_usage': psutil.cpu_percent()\n",
    "        })\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            context['gpu_memory'] = torch.cuda.memory_allocated() / 1024**3\n",
    "        \n",
    "        # ë¡œê·¸ ë ˆì½”ë“œì— ì¶”ê°€ ë°ì´í„° ì²¨ë¶€\n",
    "        extra = {'extra_data': context}\n",
    "        \n",
    "        # ë ˆë²¨ì— ë”°ë¥¸ ë¡œê·¸ ê¸°ë¡\n",
    "        log_method = getattr(self.logger, level.lower())\n",
    "        log_method(message, extra=extra)\n",
    "    \n",
    "    def debug(self, message: str, **context):\n",
    "        self.log_with_context('DEBUG', message, **context)\n",
    "    \n",
    "    def info(self, message: str, **context):\n",
    "        self.log_with_context('INFO', message, **context)\n",
    "    \n",
    "    def warning(self, message: str, **context):\n",
    "        self.log_with_context('WARNING', message, **context)\n",
    "    \n",
    "    def error(self, message: str, **context):\n",
    "        self.log_with_context('ERROR', message, **context)\n",
    "    \n",
    "    def critical(self, message: str, **context):\n",
    "        self.log_with_context('CRITICAL', message, **context)\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"ë¡œê¹… í†µê³„ ë°˜í™˜\"\"\"\n",
    "        total_logs = sum(self.log_counts.values())\n",
    "        return {\n",
    "            'total_logs': total_logs,\n",
    "            'log_counts': self.log_counts.copy(),\n",
    "            'log_rates': {k: v/total_logs if total_logs > 0 else 0 \n",
    "                         for k, v in self.log_counts.items()}\n",
    "        }\n",
    "\n",
    "# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤\n",
    "system_logger = StructuredLogger(\"DroneDetectionSystem\")\n",
    "print(\"âœ… StructuredLogger ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì—ëŸ¬ í•¸ë“¤ëŸ¬ ë° ë³µêµ¬ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorHandler:\n",
    "    \"\"\"ì—ëŸ¬ ì²˜ë¦¬ ë° ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, logger: StructuredLogger):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤\n",
    "        \"\"\"\n",
    "        self.logger = logger\n",
    "        self.error_history = deque(maxlen=1000)\n",
    "        self.recovery_strategies = {}\n",
    "        self.recovery_attempts = {}\n",
    "        \n",
    "        # ê¸°ë³¸ ë³µêµ¬ ì „ëµ ë“±ë¡\n",
    "        self._register_default_strategies()\n",
    "        \n",
    "        print(\"ğŸ›¡ï¸ ErrorHandler ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def _register_default_strategies(self):\n",
    "        \"\"\"ê¸°ë³¸ ë³µêµ¬ ì „ëµ ë“±ë¡\"\"\"\n",
    "        \n",
    "        def gpu_memory_recovery():\n",
    "            \"\"\"GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë³µêµ¬\"\"\"\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        def model_reload_recovery():\n",
    "            \"\"\"ëª¨ë¸ ì¬ë¡œë“œ ë³µêµ¬\"\"\"\n",
    "            try:\n",
    "                # ëª¨ë¸ ì¬ë¡œë“œ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì°¸ì¡° í•„ìš”)\n",
    "                return True\n",
    "            except Exception:\n",
    "                return False\n",
    "        \n",
    "        def network_retry_recovery():\n",
    "            \"\"\"ë„¤íŠ¸ì›Œí¬ ì¬ì‹œë„ ë³µêµ¬\"\"\"\n",
    "            import time\n",
    "            time.sleep(1)  # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„\n",
    "            return True\n",
    "        \n",
    "        def file_permission_recovery():\n",
    "            \"\"\"íŒŒì¼ ê¶Œí•œ ë¬¸ì œ ë³µêµ¬\"\"\"\n",
    "            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš© ë“±ì˜ ìš°íšŒ ë°©ë²•\n",
    "            return True\n",
    "        \n",
    "        # ë³µêµ¬ ì „ëµ ë“±ë¡\n",
    "        self.recovery_strategies = {\n",
    "            ErrorCategory.GPU: gpu_memory_recovery,\n",
    "            ErrorCategory.MODEL: model_reload_recovery,\n",
    "            ErrorCategory.NETWORK: network_retry_recovery,\n",
    "            ErrorCategory.FILE_IO: file_permission_recovery\n",
    "        }\n",
    "    \n",
    "    def register_recovery_strategy(self, category: ErrorCategory, strategy: Callable):\n",
    "        \"\"\"ë³µêµ¬ ì „ëµ ë“±ë¡\n",
    "        \n",
    "        Args:\n",
    "            category: ì—ëŸ¬ ì¹´í…Œê³ ë¦¬\n",
    "            strategy: ë³µêµ¬ í•¨ìˆ˜\n",
    "        \"\"\"\n",
    "        self.recovery_strategies[category] = strategy\n",
    "        self.logger.info(f\"ë³µêµ¬ ì „ëµ ë“±ë¡: {category.value}\", category=category.value)\n",
    "    \n",
    "    def handle_error(self, error: Exception, context: Dict = None) -> ErrorInfo:\n",
    "        \"\"\"ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œë„\n",
    "        \n",
    "        Args:\n",
    "            error: ë°œìƒí•œ ì˜ˆì™¸\n",
    "            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´\n",
    "            \n",
    "        Returns:\n",
    "            error_info: ì—ëŸ¬ ì •ë³´\n",
    "        \"\"\"\n",
    "        # ì—ëŸ¬ ì •ë³´ ìƒì„±\n",
    "        error_info = self._create_error_info(error, context or {})\n",
    "        \n",
    "        # ì—ëŸ¬ ë¡œê¹…\n",
    "        self._log_error(error_info)\n",
    "        \n",
    "        # ë³µêµ¬ ì‹œë„\n",
    "        if error_info.severity in [ErrorSeverity.LOW, ErrorSeverity.MEDIUM]:\n",
    "            recovery_result = self._attempt_recovery(error_info)\n",
    "            error_info.recovery_attempted = True\n",
    "            error_info.recovery_successful = recovery_result['success']\n",
    "            error_info.recovery_method = recovery_result['method']\n",
    "        \n",
    "        # ì—ëŸ¬ ì´ë ¥ ì €ì¥\n",
    "        self.error_history.append(error_info)\n",
    "        \n",
    "        return error_info\n",
    "    \n",
    "    def _create_error_info(self, error: Exception, context: Dict) -> ErrorInfo:\n",
    "        \"\"\"ì—ëŸ¬ ì •ë³´ ìƒì„±\n",
    "        \n",
    "        Args:\n",
    "            error: ì˜ˆì™¸ ê°ì²´\n",
    "            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´\n",
    "            \n",
    "        Returns:\n",
    "            error_info: ì—ëŸ¬ ì •ë³´\n",
    "        \"\"\"\n",
    "        # ì—ëŸ¬ ID ìƒì„±\n",
    "        error_id = f\"{type(error).__name__}_{int(time.time())}_{id(error)}\"\n",
    "        \n",
    "        # ì»¤ìŠ¤í…€ ì˜ˆì™¸ì¸ ê²½ìš° ì •ë³´ ì¶”ì¶œ\n",
    "        if isinstance(error, DroneDetectionError):\n",
    "            category = error.category\n",
    "            severity = error.severity\n",
    "            context.update(error.context)\n",
    "        else:\n",
    "            # ì¼ë°˜ ì˜ˆì™¸ì˜ ê²½ìš° íƒ€ì…ì— ë”°ë¼ ë¶„ë¥˜\n",
    "            category, severity = self._classify_error(error)\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ì •ë³´ ì¶”ê°€\n",
    "        context.update({\n",
    "            'python_version': sys.version,\n",
    "            'pytorch_version': torch.__version__,\n",
    "            'cuda_available': torch.cuda.is_available(),\n",
    "            'memory_usage': psutil.virtual_memory().percent,\n",
    "            'cpu_usage': psutil.cpu_percent()\n",
    "        })\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            context['gpu_memory_allocated'] = torch.cuda.memory_allocated()\n",
    "            context['gpu_memory_reserved'] = torch.cuda.memory_reserved()\n",
    "        \n",
    "        return ErrorInfo(\n",
    "            timestamp=time.time(),\n",
    "            error_id=error_id,\n",
    "            category=category,\n",
    "            severity=severity,\n",
    "            message=str(error),\n",
    "            traceback_str=traceback.format_exc(),\n",
    "            context=context\n",
    "        )\n",
    "    \n",
    "    def _classify_error(self, error: Exception) -> Tuple[ErrorCategory, ErrorSeverity]:\n",
    "        \"\"\"ì¼ë°˜ ì˜ˆì™¸ ë¶„ë¥˜\n",
    "        \n",
    "        Args:\n",
    "            error: ì˜ˆì™¸ ê°ì²´\n",
    "            \n",
    "        Returns:\n",
    "            category, severity: ì—ëŸ¬ ì¹´í…Œê³ ë¦¬ì™€ ì‹¬ê°ë„\n",
    "        \"\"\"\n",
    "        error_type = type(error).__name__\n",
    "        error_msg = str(error).lower()\n",
    "        \n",
    "        # GPU/ë©”ëª¨ë¦¬ ê´€ë ¨\n",
    "        if any(keyword in error_msg for keyword in ['cuda', 'gpu', 'memory', 'out of memory']):\n",
    "            return ErrorCategory.GPU, ErrorSeverity.HIGH\n",
    "        \n",
    "        # íŒŒì¼ ì…ì¶œë ¥ ê´€ë ¨\n",
    "        if error_type in ['FileNotFoundError', 'PermissionError', 'IOError']:\n",
    "            return ErrorCategory.FILE_IO, ErrorSeverity.MEDIUM\n",
    "        \n",
    "        # ë„¤íŠ¸ì›Œí¬ ê´€ë ¨\n",
    "        if any(keyword in error_msg for keyword in ['connection', 'network', 'timeout', 'url']):\n",
    "            return ErrorCategory.NETWORK, ErrorSeverity.MEDIUM\n",
    "        \n",
    "        # ì…ë ¥ ê´€ë ¨\n",
    "        if error_type in ['ValueError', 'TypeError', 'IndexError']:\n",
    "            return ErrorCategory.INPUT, ErrorSeverity.LOW\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ê´€ë ¨\n",
    "        if error_type in ['SystemError', 'OSError', 'RuntimeError']:\n",
    "            return ErrorCategory.SYSTEM, ErrorSeverity.HIGH\n",
    "        \n",
    "        return ErrorCategory.UNKNOWN, ErrorSeverity.MEDIUM\n",
    "    \n",
    "    def _log_error(self, error_info: ErrorInfo):\n",
    "        \"\"\"ì—ëŸ¬ ë¡œê¹…\n",
    "        \n",
    "        Args:\n",
    "            error_info: ì—ëŸ¬ ì •ë³´\n",
    "        \"\"\"\n",
    "        log_context = {\n",
    "            'error_id': error_info.error_id,\n",
    "            'category': error_info.category.value,\n",
    "            'severity': error_info.severity.value,\n",
    "            'traceback': error_info.traceback_str\n",
    "        }\n",
    "        log_context.update(error_info.context)\n",
    "        \n",
    "        # ì‹¬ê°ë„ì— ë”°ë¥¸ ë¡œê·¸ ë ˆë²¨ ê²°ì •\n",
    "        if error_info.severity == ErrorSeverity.CRITICAL:\n",
    "            self.logger.critical(error_info.message, **log_context)\n",
    "        elif error_info.severity == ErrorSeverity.HIGH:\n",
    "            self.logger.error(error_info.message, **log_context)\n",
    "        elif error_info.severity == ErrorSeverity.MEDIUM:\n",
    "            self.logger.warning(error_info.message, **log_context)\n",
    "        else:\n",
    "            self.logger.info(error_info.message, **log_context)\n",
    "    \n",
    "    def _attempt_recovery(self, error_info: ErrorInfo) -> Dict:\n",
    "        \"\"\"ë³µêµ¬ ì‹œë„\n",
    "        \n",
    "        Args:\n",
    "            error_info: ì—ëŸ¬ ì •ë³´\n",
    "            \n",
    "        Returns:\n",
    "            recovery_result: ë³µêµ¬ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        category = error_info.category\n",
    "        \n",
    "        # ë³µêµ¬ ì‹œë„ íšŸìˆ˜ í™•ì¸\n",
    "        attempt_key = f\"{category.value}_{error_info.message}\"\n",
    "        attempts = self.recovery_attempts.get(attempt_key, 0)\n",
    "        \n",
    "        if attempts >= 3:  # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì‹œë„\n",
    "            self.logger.warning(f\"ë³µêµ¬ ì‹œë„ í•œê³„ ì´ˆê³¼: {category.value}\", \n",
    "                              error_id=error_info.error_id, attempts=attempts)\n",
    "            return {'success': False, 'method': 'max_attempts_exceeded'}\n",
    "        \n",
    "        # ë³µêµ¬ ì „ëµ ì‹¤í–‰\n",
    "        if category in self.recovery_strategies:\n",
    "            try:\n",
    "                self.logger.info(f\"ë³µêµ¬ ì‹œë„ ì‹œì‘: {category.value}\", \n",
    "                               error_id=error_info.error_id, attempt=attempts+1)\n",
    "                \n",
    "                strategy = self.recovery_strategies[category]\n",
    "                success = strategy()\n",
    "                \n",
    "                self.recovery_attempts[attempt_key] = attempts + 1\n",
    "                \n",
    "                if success:\n",
    "                    self.logger.info(f\"ë³µêµ¬ ì„±ê³µ: {category.value}\", \n",
    "                                   error_id=error_info.error_id)\n",
    "                    return {'success': True, 'method': category.value}\n",
    "                else:\n",
    "                    self.logger.warning(f\"ë³µêµ¬ ì‹¤íŒ¨: {category.value}\", \n",
    "                                      error_id=error_info.error_id)\n",
    "                    return {'success': False, 'method': category.value}\n",
    "                    \n",
    "            except Exception as recovery_error:\n",
    "                self.logger.error(f\"ë³µêµ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {category.value}\", \n",
    "                                error_id=error_info.error_id, \n",
    "                                recovery_error=str(recovery_error))\n",
    "                return {'success': False, 'method': 'recovery_error'}\n",
    "        \n",
    "        return {'success': False, 'method': 'no_strategy'}\n",
    "    \n",
    "    def get_error_statistics(self) -> Dict:\n",
    "        \"\"\"ì—ëŸ¬ í†µê³„ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            stats: ì—ëŸ¬ í†µê³„\n",
    "        \"\"\"\n",
    "        if not self.error_history:\n",
    "            return {\n",
    "                'total_errors': 0,\n",
    "                'category_counts': {},\n",
    "                'severity_counts': {},\n",
    "                'recovery_rate': 0\n",
    "            }\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n",
    "        category_counts = {}\n",
    "        severity_counts = {}\n",
    "        recovery_successes = 0\n",
    "        recovery_attempts = 0\n",
    "        \n",
    "        for error in self.error_history:\n",
    "            # ì¹´í…Œê³ ë¦¬ ì¹´ìš´íŠ¸\n",
    "            cat = error.category.value\n",
    "            category_counts[cat] = category_counts.get(cat, 0) + 1\n",
    "            \n",
    "            # ì‹¬ê°ë„ ì¹´ìš´íŠ¸\n",
    "            sev = error.severity.value\n",
    "            severity_counts[sev] = severity_counts.get(sev, 0) + 1\n",
    "            \n",
    "            # ë³µêµ¬ í†µê³„\n",
    "            if error.recovery_attempted:\n",
    "                recovery_attempts += 1\n",
    "                if error.recovery_successful:\n",
    "                    recovery_successes += 1\n",
    "        \n",
    "        recovery_rate = recovery_successes / recovery_attempts if recovery_attempts > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'total_errors': len(self.error_history),\n",
    "            'category_counts': category_counts,\n",
    "            'severity_counts': severity_counts,\n",
    "            'recovery_attempts': recovery_attempts,\n",
    "            'recovery_successes': recovery_successes,\n",
    "            'recovery_rate': recovery_rate\n",
    "        }\n",
    "\n",
    "# ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤\n",
    "error_handler = ErrorHandler(system_logger)\n",
    "print(\"âœ… ErrorHandler ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë°ì½”ë ˆì´í„° ê¸°ë°˜ ì—ëŸ¬ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_handler_decorator(category: ErrorCategory = ErrorCategory.UNKNOWN,\n",
    "                          severity: ErrorSeverity = ErrorSeverity.MEDIUM,\n",
    "                          reraise: bool = True,\n",
    "                          default_return = None):\n",
    "    \"\"\"ì—ëŸ¬ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°\n",
    "    \n",
    "    Args:\n",
    "        category: ì—ëŸ¬ ì¹´í…Œê³ ë¦¬\n",
    "        severity: ê¸°ë³¸ ì‹¬ê°ë„\n",
    "        reraise: ì˜ˆì™¸ ì¬ë°œìƒ ì—¬ë¶€\n",
    "        default_return: ì—ëŸ¬ ì‹œ ê¸°ë³¸ ë°˜í™˜ê°’\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ì‹œì‘ ë¡œê¹…\n",
    "                system_logger.debug(f\"í•¨ìˆ˜ ì‹¤í–‰ ì‹œì‘: {func.__name__}\", \n",
    "                                   function=func.__name__, \n",
    "                                   args_count=len(args),\n",
    "                                   kwargs_keys=list(kwargs.keys()))\n",
    "                \n",
    "                start_time = time.time()\n",
    "                result = func(*args, **kwargs)\n",
    "                execution_time = time.time() - start_time\n",
    "                \n",
    "                # ì„±ê³µ ë¡œê¹…\n",
    "                system_logger.debug(f\"í•¨ìˆ˜ ì‹¤í–‰ ì™„ë£Œ: {func.__name__}\", \n",
    "                                   function=func.__name__,\n",
    "                                   execution_time=execution_time,\n",
    "                                   success=True)\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                execution_time = time.time() - start_time if 'start_time' in locals() else 0\n",
    "                \n",
    "                # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„±\n",
    "                context = {\n",
    "                    'function': func.__name__,\n",
    "                    'module': func.__module__,\n",
    "                    'execution_time': execution_time,\n",
    "                    'args_count': len(args),\n",
    "                    'kwargs_keys': list(kwargs.keys())\n",
    "                }\n",
    "                \n",
    "                # ì»¤ìŠ¤í…€ ì˜ˆì™¸ê°€ ì•„ë‹Œ ê²½ìš° ë³€í™˜\n",
    "                if not isinstance(e, DroneDetectionError):\n",
    "                    e = DroneDetectionError(\n",
    "                        f\"Error in {func.__name__}: {str(e)}\",\n",
    "                        category=category,\n",
    "                        severity=severity,\n",
    "                        context=context\n",
    "                    )\n",
    "                else:\n",
    "                    e.context.update(context)\n",
    "                \n",
    "                # ì—ëŸ¬ ì²˜ë¦¬\n",
    "                error_info = error_handler.handle_error(e, context)\n",
    "                \n",
    "                # ì¬ë°œìƒ ë˜ëŠ” ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "                if reraise:\n",
    "                    raise e\n",
    "                else:\n",
    "                    system_logger.warning(f\"ì—ëŸ¬ ì–µì œë¨: {func.__name__}\", \n",
    "                                         error_id=error_info.error_id,\n",
    "                                         default_return=default_return)\n",
    "                    return default_return\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def retry_on_error(max_retries: int = 3, \n",
    "                  delay: float = 1.0,\n",
    "                  backoff_factor: float = 2.0,\n",
    "                  retry_on: Tuple = (Exception,)):\n",
    "    \"\"\"ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°\n",
    "    \n",
    "    Args:\n",
    "        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜\n",
    "        delay: ì´ˆê¸° ì§€ì—° ì‹œê°„\n",
    "        backoff_factor: ì§€ì—° ì‹œê°„ ì¦ê°€ ë°°ìˆ˜\n",
    "        retry_on: ì¬ì‹œë„í•  ì˜ˆì™¸ íƒ€ì…ë“¤\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            \n",
    "            for attempt in range(max_retries + 1):\n",
    "                try:\n",
    "                    if attempt > 0:\n",
    "                        wait_time = delay * (backoff_factor ** (attempt - 1))\n",
    "                        system_logger.info(f\"ì¬ì‹œë„ {attempt}/{max_retries}: {func.__name__}\", \n",
    "                                          function=func.__name__,\n",
    "                                          attempt=attempt,\n",
    "                                          wait_time=wait_time)\n",
    "                        time.sleep(wait_time)\n",
    "                    \n",
    "                    return func(*args, **kwargs)\n",
    "                    \n",
    "                except retry_on as e:\n",
    "                    last_exception = e\n",
    "                    \n",
    "                    if attempt == max_retries:\n",
    "                        system_logger.error(f\"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {func.__name__}\", \n",
    "                                           function=func.__name__,\n",
    "                                           max_retries=max_retries,\n",
    "                                           final_error=str(e))\n",
    "                        raise e\n",
    "                    else:\n",
    "                        system_logger.warning(f\"ì¬ì‹œë„ í•„ìš”: {func.__name__}\", \n",
    "                                             function=func.__name__,\n",
    "                                             attempt=attempt,\n",
    "                                             error=str(e))\n",
    "                except Exception as e:\n",
    "                    # ì¬ì‹œë„ ëŒ€ìƒì´ ì•„ë‹Œ ì˜ˆì™¸ëŠ” ì¦‰ì‹œ ë°œìƒ\n",
    "                    system_logger.error(f\"ì¬ì‹œë„ ë¶ˆê°€ ì—ëŸ¬: {func.__name__}\", \n",
    "                                       function=func.__name__,\n",
    "                                       error=str(e))\n",
    "                    raise e\n",
    "            \n",
    "            # ì—¬ê¸°ì— ë„ë‹¬í•  ì¼ì€ ì—†ì§€ë§Œ ì•ˆì „ì¥ì¹˜\n",
    "            raise last_exception\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def monitor_performance(log_threshold: float = 1.0):\n",
    "    \"\"\"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°\n",
    "    \n",
    "    Args:\n",
    "        log_threshold: ë¡œê¹… ì„ê³„ê°’ (ì´ˆ)\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # ì‹¤í–‰ ì „ ì‹œìŠ¤í…œ ìƒíƒœ\n",
    "            start_time = time.time()\n",
    "            start_memory = psutil.virtual_memory().percent\n",
    "            start_cpu = psutil.cpu_percent()\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                start_gpu_memory = torch.cuda.memory_allocated()\n",
    "            else:\n",
    "                start_gpu_memory = 0\n",
    "            \n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                \n",
    "                # ì‹¤í–‰ í›„ ì¸¡ì •\n",
    "                execution_time = time.time() - start_time\n",
    "                end_memory = psutil.virtual_memory().percent\n",
    "                end_cpu = psutil.cpu_percent()\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    end_gpu_memory = torch.cuda.memory_allocated()\n",
    "                    gpu_memory_delta = end_gpu_memory - start_gpu_memory\n",
    "                else:\n",
    "                    gpu_memory_delta = 0\n",
    "                \n",
    "                # ì„±ëŠ¥ ë°ì´í„°\n",
    "                perf_data = {\n",
    "                    'function': func.__name__,\n",
    "                    'execution_time': execution_time,\n",
    "                    'memory_delta': end_memory - start_memory,\n",
    "                    'cpu_usage': end_cpu,\n",
    "                    'gpu_memory_delta': gpu_memory_delta / 1024**3 if gpu_memory_delta else 0\n",
    "                }\n",
    "                \n",
    "                # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ë¡œê¹…\n",
    "                if execution_time > log_threshold:\n",
    "                    system_logger.warning(f\"ì„±ëŠ¥ ì„ê³„ê°’ ì´ˆê³¼: {func.__name__}\", **perf_data)\n",
    "                else:\n",
    "                    system_logger.debug(f\"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: {func.__name__}\", **perf_data)\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                execution_time = time.time() - start_time\n",
    "                system_logger.error(f\"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ ì—ëŸ¬: {func.__name__}\", \n",
    "                                   execution_time=execution_time,\n",
    "                                   error=str(e))\n",
    "                raise\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "print(\"âœ… ë°ì½”ë ˆì´í„° ê¸°ë°˜ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° í—¬ìŠ¤ì²´í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemMonitor:\n",
    "    \"\"\"ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° í—¬ìŠ¤ì²´í¬\"\"\"\n",
    "    \n",
    "    def __init__(self, logger: StructuredLogger, check_interval: float = 30.0):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤\n",
    "            check_interval: ì²´í¬ ê°„ê²© (ì´ˆ)\n",
    "        \"\"\"\n",
    "        self.logger = logger\n",
    "        self.check_interval = check_interval\n",
    "        self.monitoring = False\n",
    "        self.monitor_thread = None\n",
    "        \n",
    "        # ì„ê³„ê°’ ì„¤ì •\n",
    "        self.thresholds = {\n",
    "            'cpu_usage': 80.0,      # CPU ì‚¬ìš©ë¥  (í¼ì„¼íŠ¸)\n",
    "            'memory_usage': 85.0,   # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (í¼ì„¼íŠ¸)\n",
    "            'gpu_memory': 90.0,     # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (í¼ì„¼íŠ¸)\n",
    "            'disk_usage': 90.0,     # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (í¼ì„¼íŠ¸)\n",
    "            'temperature': 80.0     # CPU ì˜¨ë„ (ì„­ì”¨)\n",
    "        }\n",
    "        \n",
    "        # ì•Œë¦¼ ê¸°ë¡\n",
    "        self.alert_history = deque(maxlen=100)\n",
    "        self.last_alerts = {}\n",
    "        \n",
    "        print(\"ğŸ“Š SystemMonitor ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ì‹œì‘\"\"\"\n",
    "        if self.monitoring:\n",
    "            self.logger.warning(\"ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤\")\n",
    "            return\n",
    "        \n",
    "        self.monitoring = True\n",
    "        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)\n",
    "        self.monitor_thread.start()\n",
    "        \n",
    "        self.logger.info(\"ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘\", interval=self.check_interval)\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\"\"\"\n",
    "        self.monitoring = False\n",
    "        if self.monitor_thread:\n",
    "            self.monitor_thread.join(timeout=5)\n",
    "        \n",
    "        self.logger.info(\"ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\")\n",
    "    \n",
    "    def _monitoring_loop(self):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ë£¨í”„\"\"\"\n",
    "        while self.monitoring:\n",
    "            try:\n",
    "                health_status = self.get_system_health()\n",
    "                self._check_thresholds(health_status)\n",
    "                \n",
    "                # ì£¼ê¸°ì  ìƒíƒœ ë¡œê¹…\n",
    "                self.logger.debug(\"ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬\", **health_status)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {e}\", error=str(e))\n",
    "            \n",
    "            time.sleep(self.check_interval)\n",
    "    \n",
    "    def get_system_health(self) -> Dict:\n",
    "        \"\"\"ì‹œìŠ¤í…œ í—¬ìŠ¤ ìƒíƒœ ì¡°íšŒ\n",
    "        \n",
    "        Returns:\n",
    "            health_status: ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´\n",
    "        \"\"\"\n",
    "        health_status = {\n",
    "            'timestamp': time.time(),\n",
    "            'uptime': time.time() - psutil.boot_time()\n",
    "        }\n",
    "        \n",
    "        # CPU ì •ë³´\n",
    "        health_status.update({\n",
    "            'cpu_usage': psutil.cpu_percent(interval=1),\n",
    "            'cpu_count': psutil.cpu_count(),\n",
    "            'cpu_freq': psutil.cpu_freq().current if psutil.cpu_freq() else 0\n",
    "        })\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë³´\n",
    "        memory = psutil.virtual_memory()\n",
    "        health_status.update({\n",
    "            'memory_usage': memory.percent,\n",
    "            'memory_total': memory.total / 1024**3,  # GB\n",
    "            'memory_available': memory.available / 1024**3  # GB\n",
    "        })\n",
    "        \n",
    "        # ë””ìŠ¤í¬ ì •ë³´\n",
    "        disk = psutil.disk_usage('/')\n",
    "        health_status.update({\n",
    "            'disk_usage': (disk.used / disk.total) * 100,\n",
    "            'disk_total': disk.total / 1024**3,  # GB\n",
    "            'disk_free': disk.free / 1024**3     # GB\n",
    "        })\n",
    "        \n",
    "        # GPU ì •ë³´ (CUDA ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                gpu_memory_allocated = torch.cuda.memory_allocated()\n",
    "                gpu_memory_reserved = torch.cuda.memory_reserved()\n",
    "                gpu_memory_total = torch.cuda.get_device_properties(0).total_memory\n",
    "                \n",
    "                health_status.update({\n",
    "                    'gpu_available': True,\n",
    "                    'gpu_memory_usage': (gpu_memory_allocated / gpu_memory_total) * 100,\n",
    "                    'gpu_memory_allocated': gpu_memory_allocated / 1024**3,  # GB\n",
    "                    'gpu_memory_reserved': gpu_memory_reserved / 1024**3,    # GB\n",
    "                    'gpu_memory_total': gpu_memory_total / 1024**3,          # GB\n",
    "                    'gpu_name': torch.cuda.get_device_name(0)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                health_status.update({\n",
    "                    'gpu_available': True,\n",
    "                    'gpu_error': str(e)\n",
    "                })\n",
    "        else:\n",
    "            health_status['gpu_available'] = False\n",
    "        \n",
    "        # ë„¤íŠ¸ì›Œí¬ ì •ë³´\n",
    "        try:\n",
    "            net_io = psutil.net_io_counters()\n",
    "            health_status.update({\n",
    "                'network_bytes_sent': net_io.bytes_sent,\n",
    "                'network_bytes_recv': net_io.bytes_recv,\n",
    "                'network_packets_sent': net_io.packets_sent,\n",
    "                'network_packets_recv': net_io.packets_recv\n",
    "            })\n",
    "        except Exception:\n",
    "            health_status['network_error'] = \"ë„¤íŠ¸ì›Œí¬ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨\"\n",
    "        \n",
    "        # í”„ë¡œì„¸ìŠ¤ ì •ë³´\n",
    "        current_process = psutil.Process()\n",
    "        health_status.update({\n",
    "            'process_cpu': current_process.cpu_percent(),\n",
    "            'process_memory': current_process.memory_info().rss / 1024**2,  # MB\n",
    "            'process_threads': current_process.num_threads(),\n",
    "            'process_handles': getattr(current_process, 'num_handles', lambda: 0)()\n",
    "        })\n",
    "        \n",
    "        return health_status\n",
    "    \n",
    "    def _check_thresholds(self, health_status: Dict):\n",
    "        \"\"\"ì„ê³„ê°’ ì²´í¬ ë° ì•Œë¦¼\n",
    "        \n",
    "        Args:\n",
    "            health_status: ì‹œìŠ¤í…œ ìƒíƒœ\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        alerts = []\n",
    "        \n",
    "        # CPU ì‚¬ìš©ë¥  ì²´í¬\n",
    "        if health_status.get('cpu_usage', 0) > self.thresholds['cpu_usage']:\n",
    "            alerts.append({\n",
    "                'type': 'cpu_high',\n",
    "                'message': f\"CPU ì‚¬ìš©ë¥  ë†’ìŒ: {health_status['cpu_usage']:.1f}%\",\n",
    "                'value': health_status['cpu_usage'],\n",
    "                'threshold': self.thresholds['cpu_usage']\n",
    "            })\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì²´í¬\n",
    "        if health_status.get('memory_usage', 0) > self.thresholds['memory_usage']:\n",
    "            alerts.append({\n",
    "                'type': 'memory_high',\n",
    "                'message': f\"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {health_status['memory_usage']:.1f}%\",\n",
    "                'value': health_status['memory_usage'],\n",
    "                'threshold': self.thresholds['memory_usage']\n",
    "            })\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì²´í¬\n",
    "        if health_status.get('gpu_memory_usage', 0) > self.thresholds['gpu_memory']:\n",
    "            alerts.append({\n",
    "                'type': 'gpu_memory_high',\n",
    "                'message': f\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {health_status['gpu_memory_usage']:.1f}%\",\n",
    "                'value': health_status['gpu_memory_usage'],\n",
    "                'threshold': self.thresholds['gpu_memory']\n",
    "            })\n",
    "        \n",
    "        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ì²´í¬\n",
    "        if health_status.get('disk_usage', 0) > self.thresholds['disk_usage']:\n",
    "            alerts.append({\n",
    "                'type': 'disk_high',\n",
    "                'message': f\"ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ë†’ìŒ: {health_status['disk_usage']:.1f}%\",\n",
    "                'value': health_status['disk_usage'],\n",
    "                'threshold': self.thresholds['disk_usage']\n",
    "            })\n",
    "        \n",
    "        # ì•Œë¦¼ ì²˜ë¦¬\n",
    "        for alert in alerts:\n",
    "            alert_key = alert['type']\n",
    "            \n",
    "            # ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (5ë¶„ ê°„ê²©)\n",
    "            if alert_key in self.last_alerts:\n",
    "                if current_time - self.last_alerts[alert_key] < 300:  # 5ë¶„\n",
    "                    continue\n",
    "            \n",
    "            # ì•Œë¦¼ ë°œì†¡\n",
    "            self._send_alert(alert)\n",
    "            self.last_alerts[alert_key] = current_time\n",
    "    \n",
    "    def _send_alert(self, alert: Dict):\n",
    "        \"\"\"ì•Œë¦¼ ë°œì†¡\n",
    "        \n",
    "        Args:\n",
    "            alert: ì•Œë¦¼ ì •ë³´\n",
    "        \"\"\"\n",
    "        alert['timestamp'] = time.time()\n",
    "        alert['id'] = f\"{alert['type']}_{int(alert['timestamp'])}\"\n",
    "        \n",
    "        self.alert_history.append(alert)\n",
    "        \n",
    "        # ë¡œê¹…\n",
    "        self.logger.warning(alert['message'], \n",
    "                          alert_type=alert['type'],\n",
    "                          value=alert['value'],\n",
    "                          threshold=alert['threshold'])\n",
    "        \n",
    "        # ì¶”ê°€ ì•Œë¦¼ ì±„ë„ (ì´ë©”ì¼, ìŠ¬ë™ ë“±) êµ¬í˜„ ê°€ëŠ¥\n",
    "    \n",
    "    def get_alert_summary(self) -> Dict:\n",
    "        \"\"\"ì•Œë¦¼ ìš”ì•½ ì •ë³´\n",
    "        \n",
    "        Returns:\n",
    "            summary: ì•Œë¦¼ ìš”ì•½\n",
    "        \"\"\"\n",
    "        if not self.alert_history:\n",
    "            return {'total_alerts': 0, 'alert_types': {}}\n",
    "        \n",
    "        alert_types = {}\n",
    "        recent_alerts = []\n",
    "        \n",
    "        current_time = time.time()\n",
    "        \n",
    "        for alert in self.alert_history:\n",
    "            alert_type = alert['type']\n",
    "            alert_types[alert_type] = alert_types.get(alert_type, 0) + 1\n",
    "            \n",
    "            # ìµœê·¼ 1ì‹œê°„ ì•Œë¦¼\n",
    "            if current_time - alert['timestamp'] < 3600:\n",
    "                recent_alerts.append(alert)\n",
    "        \n",
    "        return {\n",
    "            'total_alerts': len(self.alert_history),\n",
    "            'alert_types': alert_types,\n",
    "            'recent_alerts_1h': len(recent_alerts),\n",
    "            'recent_alerts': recent_alerts[-5:]  # ìµœê·¼ 5ê°œ\n",
    "        }\n",
    "    \n",
    "    def set_threshold(self, metric: str, value: float):\n",
    "        \"\"\"ì„ê³„ê°’ ì„¤ì •\n",
    "        \n",
    "        Args:\n",
    "            metric: ë©”íŠ¸ë¦­ ì´ë¦„\n",
    "            value: ì„ê³„ê°’\n",
    "        \"\"\"\n",
    "        if metric in self.thresholds:\n",
    "            old_value = self.thresholds[metric]\n",
    "            self.thresholds[metric] = value\n",
    "            self.logger.info(f\"ì„ê³„ê°’ ë³€ê²½: {metric}\", \n",
    "                           metric=metric, old_value=old_value, new_value=value)\n",
    "        else:\n",
    "            self.logger.warning(f\"ì•Œ ìˆ˜ ì—†ëŠ” ë©”íŠ¸ë¦­: {metric}\", metric=metric)\n",
    "\n",
    "# ì‹œìŠ¤í…œ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤\n",
    "system_monitor = SystemMonitor(system_logger, check_interval=30.0)\n",
    "print(\"âœ… SystemMonitor ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì•ˆì •ì„± í–¥ìƒëœ ë“œë¡  íƒì§€ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustDroneDetector:\n",
    "    \"\"\"ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…ì´ í†µí•©ëœ ì•ˆì •ì ì¸ ë“œë¡  íƒì§€ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_path: str = 'yolo11n.pt',\n",
    "                 enable_monitoring: bool = True,\n",
    "                 log_level: str = 'INFO'):\n",
    "        \"\"\"ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            model_path: YOLO ëª¨ë¸ ê²½ë¡œ\n",
    "            enable_monitoring: ëª¨ë‹ˆí„°ë§ í™œì„±í™” ì—¬ë¶€\n",
    "            log_level: ë¡œê·¸ ë ˆë²¨\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # ë¡œê¹… ë° ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ\n",
    "        self.logger = system_logger\n",
    "        self.error_handler = error_handler\n",
    "        \n",
    "        # ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ\n",
    "        if enable_monitoring:\n",
    "            self.monitor = system_monitor\n",
    "            self.monitor.start_monitoring()\n",
    "        else:\n",
    "            self.monitor = None\n",
    "        \n",
    "        # ì„±ëŠ¥ í†µê³„\n",
    "        self.stats = {\n",
    "            'total_detections': 0,\n",
    "            'successful_detections': 0,\n",
    "            'failed_detections': 0,\n",
    "            'average_processing_time': 0,\n",
    "            'last_detection_time': 0\n",
    "        }\n",
    "        \n",
    "        # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        self._initialize_model()\n",
    "        \n",
    "        self.logger.info(\"RobustDroneDetector ì´ˆê¸°í™” ì™„ë£Œ\", \n",
    "                        model_path=model_path,\n",
    "                        device=self.device,\n",
    "                        monitoring_enabled=enable_monitoring)\n",
    "    \n",
    "    @error_handler_decorator(category=ErrorCategory.MODEL, severity=ErrorSeverity.HIGH)\n",
    "    @retry_on_error(max_retries=3, delay=2.0)\n",
    "    def _initialize_model(self):\n",
    "        \"\"\"ëª¨ë¸ ì´ˆê¸°í™”\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"YOLO ëª¨ë¸ ë¡œë”© ì‹œì‘\", model_path=self.model_path)\n",
    "            \n",
    "            self.model = YOLO(self.model_path)\n",
    "            \n",
    "            # ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "            test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "            _ = self.model(test_image, device=self.device, verbose=False)\n",
    "            \n",
    "            self.logger.info(\"YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ\", \n",
    "                           model_classes=len(self.model.names),\n",
    "                           device=self.device)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\", model_path=self.model_path)\n",
    "            raise ModelError(f\"Failed to initialize model: {e}\")\n",
    "    \n",
    "    @error_handler_decorator(category=ErrorCategory.INPUT, severity=ErrorSeverity.LOW, \n",
    "                           reraise=False, default_return=None)\n",
    "    @monitor_performance(log_threshold=2.0)\n",
    "    def detect_objects(self, image_source, **kwargs) -> Optional[Dict]:\n",
    "        \"\"\"ê°ì²´ íƒì§€ ì‹¤í–‰\n",
    "        \n",
    "        Args:\n",
    "            image_source: ì´ë¯¸ì§€ ì†ŒìŠ¤ (íŒŒì¼ ê²½ë¡œ, URL, numpy array)\n",
    "            **kwargs: ì¶”ê°€ YOLO íŒŒë¼ë¯¸í„°\n",
    "            \n",
    "        Returns:\n",
    "            detection_result: íƒì§€ ê²°ê³¼ ë˜ëŠ” None\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ModelError(\"Model not initialized\")\n",
    "        \n",
    "        self.stats['total_detections'] += 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # ì…ë ¥ ê²€ì¦\n",
    "            self._validate_input(image_source)\n",
    "            \n",
    "            # YOLO ì¶”ë¡ \n",
    "            self.logger.debug(\"ê°ì²´ íƒì§€ ì‹œì‘\", \n",
    "                            input_type=type(image_source).__name__,\n",
    "                            device=self.device)\n",
    "            \n",
    "            results = self.model(\n",
    "                image_source,\n",
    "                device=self.device,\n",
    "                verbose=False,\n",
    "                **kwargs\n",
    "            )\n",
    "            \n",
    "            # ê²°ê³¼ ì²˜ë¦¬\n",
    "            detection_result = self._process_results(results, start_time)\n",
    "            \n",
    "            # í†µê³„ ì—…ë°ì´íŠ¸\n",
    "            self.stats['successful_detections'] += 1\n",
    "            processing_time = time.time() - start_time\n",
    "            self._update_processing_time(processing_time)\n",
    "            self.stats['last_detection_time'] = time.time()\n",
    "            \n",
    "            self.logger.info(\"ê°ì²´ íƒì§€ ì™„ë£Œ\", \n",
    "                           detection_count=detection_result['detection_count'],\n",
    "                           processing_time=processing_time,\n",
    "                           success=True)\n",
    "            \n",
    "            return detection_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.stats['failed_detections'] += 1\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            self.logger.error(f\"ê°ì²´ íƒì§€ ì‹¤íŒ¨: {e}\", \n",
    "                            processing_time=processing_time,\n",
    "                            error_type=type(e).__name__)\n",
    "            \n",
    "            # ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬\n",
    "            if \"CUDA\" in str(e) or \"memory\" in str(e).lower():\n",
    "                raise GPUError(f\"GPU/Memory error during detection: {e}\")\n",
    "            elif \"file\" in str(e).lower() or \"path\" in str(e).lower():\n",
    "                raise FileIOError(f\"File access error: {e}\")\n",
    "            else:\n",
    "                raise InputError(f\"Detection error: {e}\")\n",
    "    \n",
    "    def _validate_input(self, image_source):\n",
    "        \"\"\"ì…ë ¥ ê²€ì¦\n",
    "        \n",
    "        Args:\n",
    "            image_source: ì´ë¯¸ì§€ ì†ŒìŠ¤\n",
    "        \"\"\"\n",
    "        if image_source is None:\n",
    "            raise InputError(\"Image source cannot be None\")\n",
    "        \n",
    "        # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°\n",
    "        if isinstance(image_source, (str, Path)):\n",
    "            if not Path(image_source).exists():\n",
    "                raise FileIOError(f\"Image file not found: {image_source}\")\n",
    "        \n",
    "        # numpy ë°°ì—´ì¸ ê²½ìš°\n",
    "        elif isinstance(image_source, np.ndarray):\n",
    "            if image_source.size == 0:\n",
    "                raise InputError(\"Empty image array\")\n",
    "            if len(image_source.shape) != 3:\n",
    "                raise InputError(f\"Invalid image shape: {image_source.shape}\")\n",
    "    \n",
    "    def _process_results(self, results, start_time: float) -> Dict:\n",
    "        \"\"\"ê²°ê³¼ ì²˜ë¦¬\n",
    "        \n",
    "        Args:\n",
    "            results: YOLO ê²°ê³¼\n",
    "            start_time: ì‹œì‘ ì‹œê°„\n",
    "            \n",
    "        Returns:\n",
    "            processed_result: ì²˜ë¦¬ëœ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        detections = []\n",
    "        annotated_image = None\n",
    "        \n",
    "        for result in results:\n",
    "            # ì£¼ì„ì´ ì¶”ê°€ëœ ì´ë¯¸ì§€\n",
    "            if annotated_image is None:\n",
    "                annotated_image = result.plot()\n",
    "            \n",
    "            # íƒì§€ ê²°ê³¼ ì¶”ì¶œ\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    try:\n",
    "                        cls_id = int(box.cls)\n",
    "                        confidence = float(box.conf)\n",
    "                        bbox = box.xyxy[0].cpu().numpy()\n",
    "                        class_name = self.model.names[cls_id]\n",
    "                        \n",
    "                        detections.append({\n",
    "                            'class_id': cls_id,\n",
    "                            'class_name': class_name,\n",
    "                            'confidence': confidence,\n",
    "                            'bbox': bbox.tolist(),\n",
    "                            'bbox_area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"ë°•ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\", box_index=len(detections))\n",
    "                        continue\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            'detections': detections,\n",
    "            'detection_count': len(detections),\n",
    "            'annotated_image': annotated_image,\n",
    "            'processing_time': processing_time,\n",
    "            'timestamp': time.time(),\n",
    "            'device_used': self.device,\n",
    "            'model_path': self.model_path\n",
    "        }\n",
    "    \n",
    "    def _update_processing_time(self, new_time: float):\n",
    "        \"\"\"í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸\n",
    "        \n",
    "        Args:\n",
    "            new_time: ìƒˆë¡œìš´ ì²˜ë¦¬ ì‹œê°„\n",
    "        \"\"\"\n",
    "        if self.stats['average_processing_time'] == 0:\n",
    "            self.stats['average_processing_time'] = new_time\n",
    "        else:\n",
    "            # ì§€ìˆ˜ ì´ë™ í‰ê· \n",
    "            alpha = 0.1\n",
    "            self.stats['average_processing_time'] = (\n",
    "                alpha * new_time + (1 - alpha) * self.stats['average_processing_time']\n",
    "            )\n",
    "    \n",
    "    @error_handler_decorator(category=ErrorCategory.MODEL, severity=ErrorSeverity.MEDIUM)\n",
    "    def reload_model(self):\n",
    "        \"\"\"ëª¨ë¸ ì¬ë¡œë“œ\"\"\"\n",
    "        self.logger.info(\"ëª¨ë¸ ì¬ë¡œë“œ ì‹œì‘\")\n",
    "        \n",
    "        # ê¸°ì¡´ ëª¨ë¸ ì •ë¦¬\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # ëª¨ë¸ ì¬ì´ˆê¸°í™”\n",
    "        self._initialize_model()\n",
    "        \n",
    "        self.logger.info(\"ëª¨ë¸ ì¬ë¡œë“œ ì™„ë£Œ\")\n",
    "    \n",
    "    def get_system_status(self) -> Dict:\n",
    "        \"\"\"ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ\n",
    "        \n",
    "        Returns:\n",
    "            status: ì‹œìŠ¤í…œ ìƒíƒœ\n",
    "        \"\"\"\n",
    "        status = {\n",
    "            'model_loaded': self.model is not None,\n",
    "            'device': self.device,\n",
    "            'statistics': self.stats.copy(),\n",
    "            'error_statistics': self.error_handler.get_error_statistics(),\n",
    "            'logging_statistics': self.logger.get_statistics()\n",
    "        }\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ í—¬ìŠ¤ ì¶”ê°€\n",
    "        if self.monitor:\n",
    "            status['system_health'] = self.monitor.get_system_health()\n",
    "            status['alert_summary'] = self.monitor.get_alert_summary()\n",
    "        \n",
    "        return status\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"ë¦¬ì†ŒìŠ¤ ì •ë¦¬\"\"\"\n",
    "        self.logger.info(\"ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘\")\n",
    "        \n",
    "        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€\n",
    "        if self.monitor:\n",
    "            self.monitor.stop_monitoring()\n",
    "        \n",
    "        # ëª¨ë¸ ì •ë¦¬\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        self.logger.info(\"ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.cleanup()\n",
    "        \n",
    "        if exc_type is not None:\n",
    "            self.logger.error(f\"Context manager exit with exception: {exc_type.__name__}: {exc_val}\")\n",
    "            self.error_handler.handle_error(exc_val or Exception(f\"{exc_type.__name__}\"))\n",
    "\n",
    "print(\"âœ… RobustDroneDetector í´ë˜ìŠ¤ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì¢…í•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_error_handling_test():\n",
    "    \"\"\"ì¢…í•© ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ¯ ì¢…í•© ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    \n",
    "    # 1. ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "    print(\"ğŸ“ ë¡œê¹… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\")\n",
    "    \n",
    "    system_logger.debug(\"ë””ë²„ê·¸ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸\", test_data=\"debug_value\")\n",
    "    system_logger.info(\"ì •ë³´ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸\", test_data=\"info_value\")\n",
    "    system_logger.warning(\"ê²½ê³  ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸\", test_data=\"warning_value\")\n",
    "    system_logger.error(\"ì—ëŸ¬ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸\", test_data=\"error_value\")\n",
    "    \n",
    "    logging_stats = system_logger.get_statistics()\n",
    "    print(f\"   ë¡œê·¸ í†µê³„: {logging_stats}\")\n",
    "    \n",
    "    # 2. ì—ëŸ¬ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸ›¡ï¸ ì—ëŸ¬ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸:\")\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ íƒ€ì…ì˜ ì—ëŸ¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "    test_errors = [\n",
    "        ValueError(\"ì˜ëª»ëœ ì…ë ¥ ê°’\"),\n",
    "        FileNotFoundError(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ\"),\n",
    "        RuntimeError(\"CUDA out of memory\"),\n",
    "        ModelError(\"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨\", severity=ErrorSeverity.HIGH),\n",
    "        GPUError(\"GPU ë©”ëª¨ë¦¬ ë¶€ì¡±\", severity=ErrorSeverity.CRITICAL)\n",
    "    ]\n",
    "    \n",
    "    for i, error in enumerate(test_errors):\n",
    "        print(f\"   í…ŒìŠ¤íŠ¸ {i+1}: {type(error).__name__}\")\n",
    "        \n",
    "        context = {\n",
    "            'test_number': i+1,\n",
    "            'error_type': type(error).__name__,\n",
    "            'simulation': True\n",
    "        }\n",
    "        \n",
    "        error_info = error_handler.handle_error(error, context)\n",
    "        print(f\"     ì—ëŸ¬ ID: {error_info.error_id}\")\n",
    "        print(f\"     ì¹´í…Œê³ ë¦¬: {error_info.category.value}\")\n",
    "        print(f\"     ì‹¬ê°ë„: {error_info.severity.value}\")\n",
    "        print(f\"     ë³µêµ¬ ì‹œë„: {error_info.recovery_attempted}\")\n",
    "        print(f\"     ë³µêµ¬ ì„±ê³µ: {error_info.recovery_successful}\")\n",
    "    \n",
    "    error_stats = error_handler.get_error_statistics()\n",
    "    print(f\"\\n   ì—ëŸ¬ í†µê³„: {error_stats}\")\n",
    "    \n",
    "    # 3. ë°ì½”ë ˆì´í„° í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸ­ ë°ì½”ë ˆì´í„° í…ŒìŠ¤íŠ¸:\")\n",
    "    \n",
    "    @error_handler_decorator(category=ErrorCategory.INPUT, reraise=False, default_return=\"ì—ëŸ¬ ë°œìƒ\")\n",
    "    def test_function_with_error():\n",
    "        \"\"\"ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\"\"\"\n",
    "        raise ValueError(\"í…ŒìŠ¤íŠ¸ ì—ëŸ¬\")\n",
    "    \n",
    "    @retry_on_error(max_retries=2, delay=0.1)\n",
    "    def test_function_with_retry():\n",
    "        \"\"\"ì¬ì‹œë„ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\"\"\"\n",
    "        import random\n",
    "        if random.random() < 0.7:  # 70% í™•ë¥ ë¡œ ì‹¤íŒ¨\n",
    "            raise NetworkError(\"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨\")\n",
    "        return \"ì„±ê³µ!\"\n",
    "    \n",
    "    @monitor_performance(log_threshold=0.01)\n",
    "    def test_performance_monitoring():\n",
    "        \"\"\"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\"\"\"\n",
    "        time.sleep(0.02)  # ì¸ìœ„ì  ì§€ì—°\n",
    "        return \"ì™„ë£Œ\"\n",
    "    \n",
    "    # ë°ì½”ë ˆì´í„° í•¨ìˆ˜ ì‹¤í–‰\n",
    "    result1 = test_function_with_error()\n",
    "    print(f\"   ì—ëŸ¬ ì²˜ë¦¬ ê²°ê³¼: {result1}\")\n",
    "    \n",
    "    try:\n",
    "        result2 = test_function_with_retry()\n",
    "        print(f\"   ì¬ì‹œë„ ê²°ê³¼: {result2}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ì¬ì‹œë„ ìµœì¢… ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    result3 = test_performance_monitoring()\n",
    "    print(f\"   ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê²°ê³¼: {result3}\")\n",
    "    \n",
    "    # 4. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸ“Š ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸:\")\n",
    "    \n",
    "    health_status = system_monitor.get_system_health()\n",
    "    print(f\"   CPU ì‚¬ìš©ë¥ : {health_status.get('cpu_usage', 0):.1f}%\")\n",
    "    print(f\"   ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {health_status.get('memory_usage', 0):.1f}%\")\n",
    "    print(f\"   ë””ìŠ¤í¬ ì‚¬ìš©ë¥ : {health_status.get('disk_usage', 0):.1f}%\")\n",
    "    \n",
    "    if health_status.get('gpu_available', False):\n",
    "        print(f\"   GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {health_status.get('gpu_memory_usage', 0):.1f}%\")\n",
    "    \n",
    "    # ì„ê³„ê°’ í…ŒìŠ¤íŠ¸ (ì¼ì‹œì ìœ¼ë¡œ ë‚®ê²Œ ì„¤ì •)\n",
    "    original_cpu_threshold = system_monitor.thresholds['cpu_usage']\n",
    "    system_monitor.set_threshold('cpu_usage', 0.1)  # ë§¤ìš° ë‚®ê²Œ ì„¤ì •\n",
    "    \n",
    "    # ê°•ì œë¡œ ì•Œë¦¼ ë°œìƒ\n",
    "    system_monitor._check_thresholds(health_status)\n",
    "    \n",
    "    # ì›ë˜ ì„ê³„ê°’ìœ¼ë¡œ ë³µêµ¬\n",
    "    system_monitor.set_threshold('cpu_usage', original_cpu_threshold)\n",
    "    \n",
    "    alert_summary = system_monitor.get_alert_summary()\n",
    "    print(f\"   ì´ ì•Œë¦¼ ìˆ˜: {alert_summary['total_alerts']}\")\n",
    "    \n",
    "    # 5. RobustDroneDetector í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸš RobustDroneDetector í…ŒìŠ¤íŠ¸:\")\n",
    "    \n",
    "    try:\n",
    "        with RobustDroneDetector(enable_monitoring=False) as detector:\n",
    "            # ì •ìƒ íƒì§€ í…ŒìŠ¤íŠ¸\n",
    "            test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "            result = detector.detect_objects(test_image)\n",
    "            \n",
    "            if result:\n",
    "                print(f\"   ì •ìƒ íƒì§€ ì™„ë£Œ: {result['detection_count']}ê°œ ê°ì²´\")\n",
    "                print(f\"   ì²˜ë¦¬ ì‹œê°„: {result['processing_time']*1000:.1f}ms\")\n",
    "            \n",
    "            # ì—ëŸ¬ ìƒí™© í…ŒìŠ¤íŠ¸\n",
    "            try:\n",
    "                detector.detect_objects(None)  # None ì…ë ¥\n",
    "            except Exception as e:\n",
    "                print(f\"   ì˜ˆìƒëœ ì—ëŸ¬ ì²˜ë¦¬ë¨: {type(e).__name__}\")\n",
    "            \n",
    "            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸\n",
    "            status = detector.get_system_status()\n",
    "            print(f\"   ì´ íƒì§€ ì‹œë„: {status['statistics']['total_detections']}\")\n",
    "            print(f\"   ì„±ê³µí•œ íƒì§€: {status['statistics']['successful_detections']}\")\n",
    "            print(f\"   ì‹¤íŒ¨í•œ íƒì§€: {status['statistics']['failed_detections']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   RobustDroneDetector í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 6. ìµœì¢… í†µê³„\n",
    "    print(\"\\nğŸ“Š ìµœì¢… í†µê³„:\")\n",
    "    \n",
    "    final_logging_stats = system_logger.get_statistics()\n",
    "    final_error_stats = error_handler.get_error_statistics()\n",
    "    \n",
    "    print(f\"   ì´ ë¡œê·¸ ìˆ˜: {final_logging_stats['total_logs']}\")\n",
    "    print(f\"   ì—ëŸ¬ìœ¨: {final_logging_stats['log_rates']['ERROR']*100:.1f}%\")\n",
    "    print(f\"   ì´ ì—ëŸ¬ ìˆ˜: {final_error_stats['total_errors']}\")\n",
    "    print(f\"   ë³µêµ¬ ì„±ê³µë¥ : {final_error_stats['recovery_rate']*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ Todo 10 ì™„ë£Œ!\")\n",
    "    print(\"\\nğŸ“‹ êµ¬í˜„ëœ ê¸°ëŠ¥:\")\n",
    "    print(\"   âœ… ê³„ì¸µì  ì˜ˆì™¸ í´ë˜ìŠ¤ ì‹œìŠ¤í…œ\")\n",
    "    print(\"   âœ… êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ (íŒŒì¼, ì½˜ì†”, JSON)\")\n",
    "    print(\"   âœ… ìë™ ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜\")\n",
    "    print(\"   âœ… ë°ì½”ë ˆì´í„° ê¸°ë°˜ ì—ëŸ¬ ì²˜ë¦¬\")\n",
    "    print(\"   âœ… ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§\")\n",
    "    print(\"   âœ… ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ ì‹œìŠ¤í…œ\")\n",
    "    print(\"   âœ… í†µí•©ëœ ì•ˆì •ì  íƒì§€ ì‹œìŠ¤í…œ\")\n",
    "    print(\"   âœ… ì„±ëŠ¥ ë° ì—ëŸ¬ í†µê³„ ì¶”ì \")\n",
    "    \n",
    "    return {\n",
    "        'logging_stats': final_logging_stats,\n",
    "        'error_stats': final_error_stats,\n",
    "        'alert_summary': alert_summary,\n",
    "        'system_health': health_status\n",
    "    }\n",
    "\n",
    "# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_results = comprehensive_error_handling_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Todo 10 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "\n",
    "1. **í¬ê´„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ**\n",
    "   - [x] ErrorSeverity, ErrorCategory ì—´ê±°í˜• ì •ì˜\n",
    "   - [x] ErrorInfo ë°ì´í„° í´ë˜ìŠ¤ êµ¬ì¡°í™”\n",
    "   - [x] ê³„ì¸µì  ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤\n",
    "   - [x] ErrorHandler í´ë˜ìŠ¤ (ìë™ ë¶„ë¥˜, ë³µêµ¬ ì „ëµ)\n",
    "   - [x] ë³µêµ¬ ì‹œë„ íšŸìˆ˜ ì œí•œ ë° ì¶”ì \n",
    "\n",
    "2. **êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ**\n",
    "   - [x] StructuredLogger í´ë˜ìŠ¤\n",
    "   - [x] ë‹¤ì¤‘ ì¶œë ¥ (íŒŒì¼, ì½˜ì†”, JSON)\n",
    "   - [x] ë¡œê·¸ íšŒì „ ë° ë°±ì—…\n",
    "   - [x] ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¡œê¹…\n",
    "   - [x] ì»¬ëŸ¬ ì¶œë ¥ ì§€ì›\n",
    "   - [x] ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìë™ í¬í•¨\n",
    "\n",
    "3. **ë°ì½”ë ˆì´í„° ê¸°ë°˜ ì—ëŸ¬ ì²˜ë¦¬**\n",
    "   - [x] @error_handler_decorator (ìë™ ì—ëŸ¬ ì²˜ë¦¬)\n",
    "   - [x] @retry_on_error (ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜)\n",
    "   - [x] @monitor_performance (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§)\n",
    "   - [x] ë°±ì˜¤í”„ ë° ì§€ì—° ì‹œê°„ ì„¤ì •\n",
    "   - [x] ì„ íƒì  ì˜ˆì™¸ ì¬ë°œìƒ\n",
    "\n",
    "4. **ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° í—¬ìŠ¤ì²´í¬**\n",
    "   - [x] SystemMonitor í´ë˜ìŠ¤\n",
    "   - [x] ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§\n",
    "   - [x] ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ ì‹œìŠ¤í…œ\n",
    "   - [x] GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§\n",
    "   - [x] ë„¤íŠ¸ì›Œí¬ ë° í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§\n",
    "   - [x] ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€\n",
    "\n",
    "5. **í†µí•© ì•ˆì •ì„± ì‹œìŠ¤í…œ**\n",
    "   - [x] RobustDroneDetector í´ë˜ìŠ¤\n",
    "   - [x] ëª¨ë“  ì—ëŸ¬ ì²˜ë¦¬ ê¸°ëŠ¥ í†µí•©\n",
    "   - [x] Context manager ì§€ì›\n",
    "   - [x] ìë™ ë¦¬ì†ŒìŠ¤ ì •ë¦¬\n",
    "   - [x] ì‹¤ì‹œê°„ í†µê³„ ì¶”ì \n",
    "\n",
    "6. **ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜**\n",
    "   - [x] GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ë³µêµ¬\n",
    "   - [x] ëª¨ë¸ ì¬ë¡œë“œ ë³µêµ¬\n",
    "   - [x] ë„¤íŠ¸ì›Œí¬ ì¬ì‹œë„ ë³µêµ¬\n",
    "   - [x] íŒŒì¼ ê¶Œí•œ ìš°íšŒ ë³µêµ¬\n",
    "   - [x] ë³µêµ¬ ì „ëµ ë™ì  ë“±ë¡\n",
    "\n",
    "### ğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ ê¸°ëŠ¥\n",
    "\n",
    "- **ê³„ì¸µì  ì˜ˆì™¸ ì‹œìŠ¤í…œ**: ë„ë©”ì¸ë³„ ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤\n",
    "- **ìë™ ì—ëŸ¬ ë¶„ë¥˜**: ì˜ˆì™¸ íƒ€ì…ê³¼ ë©”ì‹œì§€ ê¸°ë°˜ ìë™ ë¶„ë¥˜\n",
    "- **ë³µêµ¬ ì „ëµ**: ì—ëŸ¬ ì¹´í…Œê³ ë¦¬ë³„ ìë™ ë³µêµ¬ ì‹œë„\n",
    "- **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜**: ë°±ì˜¤í”„ì™€ í•¨ê»˜ ì§€ëŠ¥ì  ì¬ì‹œë„\n",
    "- **ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´**: ì—ëŸ¬ ë°œìƒ ì‹œì ì˜ ì‹œìŠ¤í…œ ìƒíƒœ ë³´ì¡´\n",
    "\n",
    "### ğŸ“ ë¡œê¹… ê¸°ëŠ¥\n",
    "\n",
    "- **êµ¬ì¡°í™”ëœ ë¡œê·¸**: JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¡œê·¸ ë°ì´í„°\n",
    "- **ë‹¤ì¤‘ ì¶œë ¥**: íŒŒì¼, ì½˜ì†”, JSON íŒŒì¼ ë™ì‹œ ì¶œë ¥\n",
    "- **ìë™ íšŒì „**: íŒŒì¼ í¬ê¸° ê¸°ë°˜ ë¡œê·¸ íšŒì „\n",
    "- **ì»¬ëŸ¬ ì¶œë ¥**: ë¡œê·¸ ë ˆë²¨ë³„ ì»¬ëŸ¬ êµ¬ë¶„\n",
    "- **ì„±ëŠ¥ ì¶”ì **: CPU, ë©”ëª¨ë¦¬, GPU ì‚¬ìš©ëŸ‰ ìë™ ê¸°ë¡\n",
    "\n",
    "### ğŸ“Š ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥\n",
    "\n",
    "- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‹¤ì‹œê°„ ì¶”ì \n",
    "- **ì„ê³„ê°’ ì•Œë¦¼**: ì„¤ì • ê°€ëŠ¥í•œ ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼\n",
    "- **í—¬ìŠ¤ì²´í¬**: ì¢…í•©ì ì¸ ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€\n",
    "- **ì•Œë¦¼ ê´€ë¦¬**: ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ ë° ì´ë ¥ ê´€ë¦¬\n",
    "- **GPU ì§€ì›**: CUDA ë©”ëª¨ë¦¬ ë° ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "### ğŸš€ ì•ˆì •ì„± í–¥ìƒ íš¨ê³¼\n",
    "\n",
    "- **ë¬´ì¤‘ë‹¨ ìš´ì˜**: ìë™ ë³µêµ¬ë¡œ ì‹œìŠ¤í…œ ì—°ì†ì„± í™•ë³´\n",
    "- **ì‹ ì†í•œ ë””ë²„ê¹…**: ìƒì„¸í•œ ë¡œê·¸ì™€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´\n",
    "- **ì˜ˆë°©ì  ê´€ë¦¬**: ì„ê³„ê°’ ê¸°ë°˜ ì‚¬ì „ ê²½ê³ \n",
    "- **íˆ¬ëª…í•œ ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ìƒíƒœ ê°€ì‹œì„±\n",
    "- **ê°œë°œì ì¹œí™”ì **: ë°ì½”ë ˆì´í„°ë¡œ ê°„í¸í•œ ì ìš©\n",
    "\n",
    "### ğŸ“ ìƒì„±ëœ ë¡œê·¸ íŒŒì¼\n",
    "\n",
    "- `logs/DroneDetectionSystem.log` - ì¼ë°˜ ë¡œê·¸\n",
    "- `logs/DroneDetectionSystem_errors.log` - ì—ëŸ¬ ì „ìš© ë¡œê·¸\n",
    "- `logs/DroneDetectionSystem_structured.jsonl` - êµ¬ì¡°í™”ëœ JSON ë¡œê·¸\n",
    "\n",
    "Todo 10 ì™„ë£Œ! ì´ì œ Sonnetì´ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤. \n",
    "ì•ˆì •ì ì´ê³  ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ë“œë¡  ì‘ë¬¼ íƒì§€ ì‹œìŠ¤í…œì˜ ê¸°ë°˜ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}